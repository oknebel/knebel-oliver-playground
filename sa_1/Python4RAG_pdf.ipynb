{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG ror PDF written purely in Python\n",
    "\n",
    "First install a library to read pdf-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pymupdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the vector store\n",
    "\n",
    "First we build the vector store based on our main document. Here we downloaded some paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_document_path = \"./data/2205.13147v4.pdf\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py4ragTools.database import Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructor here\n"
     ]
    }
   ],
   "source": [
    "# embedding_model = 'all-minilm'  # 384\n",
    "embedding_model='nomic-embed-text'  # 768\n",
    "db = Database(embedding_model=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from py4ragTools.text_tools import TextHelper, CharacterTextSplitter\n",
    "th = TextHelper()\n",
    "\n",
    "# load the document\n",
    "doc = th.load(the_document_path)\n",
    "\n",
    "# split the text into chunks\n",
    "splitter = CharacterTextSplitter(chunk_size=800,chunk_overlap=200)\n",
    "chunks = splitter.split(doc)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212 entries in db\n"
     ]
    }
   ],
   "source": [
    "# now we build the 'vector store' converting each chunk into a vector\n",
    "count = 0\n",
    "for chunk in chunks:\n",
    "    # Bei Texten der Länge 0 bleibt ollama stehen\n",
    "    # Sehr kurze Texte sind unbrauchbar für's anschliessende Generieren\n",
    "    if len(chunk) > 10:\n",
    "        # print(count)\n",
    "        # print(entry)\n",
    "        db.add(chunk)\n",
    "        count += 1\n",
    "print(f'{count} entries in db')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval\n",
    "\n",
    "We have built our vector store let us retrieve a context for a user-query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a query regarding today's topics on the newspaper's front page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# okn: Task 2/3 trying some prompt pattern and test some specific user prompts\n",
    "# okn: observ: sentance 'it is often the case...' available in context, but not in response\n",
    "\n",
    "\n",
    "# okn: text passage 'constaint not known in advance' im context, aber nicht im nicht im response erwähnt\n",
    "USER_PROMPT_0 = \"\"\"\n",
    "Are there computational and statistical constraints?\n",
    "\"\"\"\n",
    "\n",
    "# okn: observ: context has complete sub points, response only returns first\n",
    "USER_PROMPT_1 = \"\"\" \\\n",
    "What does the Checklist say, if you are using existing assets?\n",
    "\"\"\"\n",
    "\n",
    "# audience prompt pattern\n",
    "# okn: observ: response sounds well, though hard to say if it fully makes sense\n",
    "USER_PROMPT_2 = \"\"\" \\\n",
    "What is Matryoshka Representation Learning? Explain to me like I’m 11 years old.\n",
    "\"\"\"\n",
    "\n",
    "# persona  pattern\n",
    "# okn: observ: response sounds well, though hard to say if it fully makes sense\n",
    "USER_PROMPT_3 = \"\"\" \\\n",
    "What is Matryoshka Representation Learning? Act as a oriental story teller.\n",
    "\"\"\"\n",
    "\n",
    "# response template pattern\n",
    "# okn: observ: works well\n",
    "USER_PROMPT_4 = \"\"\" \\\n",
    "What is Matryoshka Representation Learning?\n",
    "Format your answer as follows:\n",
    "#Question: [The question being asked by User]\n",
    "## Summary \n",
    "[a one paragraph summary of the answer]\n",
    "## Details \n",
    "[a detailed answer]\n",
    "\"\"\"\n",
    "\n",
    "# question refinement pattern\n",
    "# okn: works as long as there is some context returned by the vector store\n",
    "USER_PROMPT_5 = \"\"\" \\\n",
    "Is Matryoshka Representation usefull at all?\n",
    "If question is not clearly formulated, suggest a better version of the question and ask user if he would like to use it instead.\n",
    "\"\"\"\n",
    "\n",
    "user_query = USER_PROMPT_0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# okn: observ: have adjustet the parameter until it returned the document text in Task 3\n",
    "context = db.query_database(user_query, 0.5 )\n",
    "len(context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5845468924444428,\n",
       "  ' Mu, S. Kadavath, F. Wang, E. Dorundo, R. Desai, T. Zhu,\\nS. Parajuli, M. Guo, et al. The many faces of robustness: A critical analysis of out-of-\\ndistribution generalization. In Proceedings of the IEEE/CVF International Conference on\\nComputer Vision, pages 8340–8349, 2021.\\n12\\n[35] D. Hendrycks, K. Zhao, S. Basart, J. Steinhardt, and D. Song. Natural adversarial examples.\\nIn Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,\\npages 15262–15271, 2021.\\n[36] S. Hooker, A. Courville, G. Clark, Y. Dauphin, and A. Frome. What do compressed deep\\nneural networks forget? arXiv preprint arXiv:1911.05248, 2019.\\n[37] S. Hooker, N. Moorosi, G. Clark, S. Bengio, and E. Denton. Characterising bias in compressed\\nmodels. arXiv preprint arXiv:2010.03058, 2020.\\n[38] H. Hotelling'),\n",
       " (0.5442247528071253,\n",
       "  'Lab/robustness.\\n[25] A. Gholami, S. Kim, Z. Dong, Z. Yao, M. W. Mahoney, and K. Keutzer. A survey of\\nquantization methods for efficient neural network inference. arXiv preprint arXiv:2103.13630,\\n2021.\\n[26] S. Gong, V. N. Boddeti, and A. K. Jain. On the intrinsic dimensionality of image representations.\\nIn Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,\\npages 3987–3996, 2019.\\n[27] M. Gutmann and A. Hyvärinen. Noise-contrastive estimation: A new estimation principle for\\nunnormalized statistical models. In Proceedings of the thirteenth international conference\\non artificial intelligence and statistics, pages 297–304. JMLR Workshop and Conference\\nProceedings, 2010.\\n[28] M. G. Harris and C. D. Giachritsis. Coarse-grained information dominates fine-grained\\ninfo'),\n",
       " (0.5430886869072462,\n",
       "  'Matryoshka Representation Learning\\nAditya Kusupati∗†⋄, Gantavya Bhatt∗†, Aniket Rege∗†,\\nMatthew Wallingford†, Aditya Sinha⋄, Vivek Ramanujan†, William Howard-Snyder†,\\nKaifeng Chen⋄, Sham Kakade‡, Prateek Jain⋄and Ali Farhadi†\\n†University of Washington, ⋄Google Research, ‡Harvard University\\n{kusupati,ali}@cs.washington.edu, prajain@google.com\\nAbstract\\nLearned representations are a central component in modern ML systems, serv-\\ning a multitude of downstream tasks. When training such representations, it\\nis often the case that computational and statistical constraints for each down-\\nstream task are unknown. In this context, rigid fixed-capacity representations\\ncan be either over or under-accommodating to the task at hand. This leads us\\nto ask: can we design a flexible representation that can ad'),\n",
       " (0.5428064866847161,\n",
       "  '= {12, 24, 48, 96, 192, 384, 768} as\\nthe explicitly optimized nested dimensions respectively. Lastly, we extensively compare the MRL\\nand MRL–E models to independently trained low-dimensional (fixed feature) representations (FF),\\ndimensionality reduction (SVD), sub-net method (slimmable networks [100]) and randomly selected\\nfeatures of the highest capacity FF model.\\nIn section 4.2, we evaluate the quality and capacity of the learned representations through linear\\nclassification/probe (LP) and 1-nearest neighbour (1-NN) accuracy. Experiments show that MRL\\nmodels remove the dependence on |M| resource-intensive independently trained models for the\\ncoarse-to-fine representations while being as accurate. Lastly, we show that despite optimizing only\\nfor |M| dimensions, MRL models diffuse the info'),\n",
       " (0.5378890260313044,\n",
       "  ' unknown. In this context, rigid fixed-capacity representations\\ncan be either over or under-accommodating to the task at hand. This leads us\\nto ask: can we design a flexible representation that can adapt to multiple down-\\nstream tasks with varying computational resources? Our main contribution is\\nMatryoshka Representation Learning (MRL) which encodes information at\\ndifferent granularities and allows a single embedding to adapt to the computational\\nconstraints of downstream tasks. MRL minimally modifies existing representation\\nlearning pipelines and imposes no additional cost during inference and deployment.\\nMRL learns coarse-to-fine representations that are at least as accurate and rich as\\nindependently trained low-dimensional representations. The flexibility within the\\nlearned Matryoshka '),\n",
       " (0.5372156940681374,\n",
       "  'rXiv preprint arXiv:1911.05248, 2019.\\n[37] S. Hooker, N. Moorosi, G. Clark, S. Bengio, and E. Denton. Characterising bias in compressed\\nmodels. arXiv preprint arXiv:2010.03058, 2020.\\n[38] H. Hotelling. Analysis of a complex of statistical variables into principal components. Journal\\nof educational psychology, 24(6):417, 1933.\\n[39] A. G. Howard, M. Zhu, B. Chen, D. Kalenichenko, W. Wang, T. Weyand, M. Andreetto, and\\nH. Adam. Mobilenets: Efficient convolutional neural networks for mobile vision applications.\\narXiv preprint arXiv:1704.04861, 2017.\\n[40] J. Howard and S. Ruder. Universal language model fine-tuning for text classification. arXiv\\npreprint arXiv:1801.06146, 2018.\\n[41] H. Hu, D. Dey, M. Hebert, and J. A. Bagnell. Learning anytime predictions in neural networks\\nvia adaptive loss bal'),\n",
       " (0.5354382135721805,\n",
       "  'xperiments...\\n(a) Did you include the code, data, and instructions needed to reproduce the main ex-\\nperimental results (either in the supplemental material or as a URL)? [Yes] See sup-\\nplemental material and Appendix A. All the code and public models will be open\\nsourced.\\n(b) Did you specify all the training details (e.g., data splits, hyperparameters, how they\\nwere chosen)? [Yes] See Section 4 and Appendix C.\\n(c) Did you report error bars (e.g., with respect to the random seed after running experi-\\nments multiple times)? [No] We benchmarked on large-scale datasets like ImageNet-\\n1K, JFT-300M and ALIGN data with models like ResNet and ViT making it extremely\\nexpensive to run things multiple times.\\n(d) Did you include the total amount of compute and the type of resources used (e.g., type\\nof'),\n",
       " (0.533701395549385,\n",
       "  'd K. Grauman. Fast similarity search for learned metrics. IEEE Transactions\\non Pattern Analysis and Machine Intelligence, 31(12):2143–2157, 2009.\\n13\\n[53] A. Kusupati, M. Singh, K. Bhatia, A. Kumar, P. Jain, and M. Varma. Fastgrnn: A fast, accurate,\\nstable and tiny kilobyte sized gated recurrent neural network. Advances in Neural Information\\nProcessing Systems, 31, 2018.\\n[54] A. Kusupati, V. Ramanujan, R. Somani, M. Wortsman, P. Jain, S. Kakade, and A. Farhadi.\\nSoft threshold weight reparameterization for learnable sparsity. In International Conference\\non Machine Learning, pages 5544–5555. PMLR, 2020.\\n[55] A. Kusupati, M. Wallingford, V. Ramanujan, R. Somani, J. S. Park, K. Pillutla, P. Jain,\\nS. Kakade, and A. Farhadi. Llc: Accurate, multi-purpose learnt low-dimensional binary codes.\\nAdvanc'),\n",
       " (0.530638935391698,\n",
       "  'ce of MRL model on 31-way classification (1 extra class is for reject token) on\\nImageNet-1K superclasses.\\nRep. Size\\n8\\n16\\n32\\n64\\n128\\n256\\n512\\n1024\\n2048\\nMRL\\n85.57\\n88.67\\n89.48\\n89.82\\n89.97\\n90.11\\n90.18\\n90.22\\n90.21\\nMatryoshka Representations at Arbitrary Granularities.\\nTo train MRL, we used nested di-\\nmensions at logarithmic granularities M = {8, 16, . . . , 1024, 2048} as detailed in Section 3. We\\nmade this choice for two empirically-driven reasons: a) The accuracy improvement with increasing\\nrepresentation size was more logarithmic than linear (as shown by FF models in Figure 2). This indi-\\ncated that optimizing for granularities increasing in a non-logarithmic fashion would be sub-optimal\\nboth for maximum performance and expected efficiency; b) If we have m arbitrary granularities,\\nthe expected'),\n",
       " (0.5305623248434223,\n",
       "  'an one: Fast and accurate models via ensembles and cascades. arXiv\\npreprint arXiv:2012.01988, 2020.\\n[96] M. Wortsman, G. Ilharco, M. Li, J. W. Kim, H. Hajishirzi, A. Farhadi, H. Namkoong, and\\nL. Schmidt. Robust fine-tuning of zero-shot models. arXiv preprint arXiv:2109.01903, 2021.\\n[97] Z. Wu, Y. Xiong, S. Yu, and D. Lin. Unsupervised feature learning via non-parametric\\ninstance-level discrimination. arXiv preprint arXiv:1805.01978, 2018.\\n[98] J. Yosinski, J. Clune, Y. Bengio, and H. Lipson. How transferable are features in deep neural\\nnetworks? Advances in neural information processing systems, 27, 2014.\\n[99] H.-F. Yu, K. Zhong, J. Zhang, W.-C. Chang, and I. S. Dhillon. Pecos: Prediction for enormous\\nand correlated output spaces. Journal of Machine Learning Research, 23(98):1–32, 2022.\\n[1'),\n",
       " (0.5287280757915527,\n",
       "  '\\nThese experiments show that MRL seamlessly scales to large-scale models and web-scale datasets\\nwhile providing the otherwise prohibitively expensive multi-granularity in the process. We also\\nhave similar observations when pretraining BERT; please see Appendix D.2 for more details. Our\\nexperiments also show that post-hoc compression (SVD), linear probe on random features, and\\nsub-net style slimmable networks drastically lose accuracy compared to MRL as the representation\\nsize decreases. Finally, Figure 5 shows that, while MRL explicitly optimizes O(log(d)) nested\\nrepresentations – removing the O(d) dependence [73] –, the coarse-to-fine grained information is\\ninterpolated across all d dimensions providing highest flexibility for adaptive deployment.\\n5\\n12\\n24\\n48\\n96\\n192\\n384\\n768\\nRepresentation '),\n",
       " (0.528044842755405,\n",
       "  ' on top of the existing impact of\\nrepresentation learning. However, a study on the trade-off between representation size\\nand the tendency to encode biases is an interesting future direction along the lines of\\nexisting literature [36, 37]. A part of this is already presented in Section 5.\\n(d) Have you read the ethics review guidelines and ensured that your paper conforms to\\nthem? [Yes]\\n2. If you are including theoretical results...\\n(a) Did you state the full set of assumptions of all theoretical results? [N/A]\\n(b) Did you include complete proofs of all theoretical results? [N/A]\\n3. If you ran experiments...\\n(a) Did you include the code, data, and instructions needed to reproduce the main ex-\\nperimental results (either in the supplemental material or as a URL)? [Yes] See sup-\\nplemental mater'),\n",
       " (0.5277079198939316,\n",
       "  'at optimizing for granularities increasing in a non-logarithmic fashion would be sub-optimal\\nboth for maximum performance and expected efficiency; b) If we have m arbitrary granularities,\\nthe expected cost of the linear classifier to train MRL scales as O(L ∗(m2)) while logarithmic\\ngranularities result in O(L ∗2log(d)) space and compute costs.\\nTo demonstrate this effect, we learned Matryoshka Representations with uniform (MRL-Uniform)\\nnesting dimensions m\\n∈\\nM\\n=\\n{8, 212, 416, 620, 824, 1028, 1232, 1436, 1640, 1844, 2048}.\\nWe\\nevaluated\\nthis\\nmodel\\nat\\nthe\\nstandard\\n(MRL-log)\\ndimensions\\nm\\n∈\\nM\\n=\\n{8, 16, 32, 64, 128, 256, 512, 1024, 2048} for ease of comparison to reported numbers using 1-NN ac-\\ncuracy (%). As shown in Table 29, we observed that while performance interpolated, MRL-Uniform\\nsuffered'),\n",
       " (0.5269286588136607,\n",
       "  ', 32, 64, . . . , 2048}}. To improve reliability of threshold\\nbased greedy policy, we use test time augmentation which has been used successfully in the past [82].\\nFor inference, we used the remaining held-out 40K samples from the ImageNet-1K validation set. We\\nbegan with smallest sized representation (m = 8) and compared the computed prediction confidence\\np8 to learned optimal threshold t∗\\n8. If p8 ≤t∗\\n8, then we increased m = 16, and repeated this\\nprocedure until m = d = 2048. To compute the expected dimensions, we performed early stopping\\nat m = {16, 32, 64, . . . 2048} and computed the expectation using the distribution of representation\\nsizes. As shown in Table 3 and Figure 6, we observed that in expectation, we only needed a ∼37\\nsized representation to achieve 76.3% classification ac'),\n",
       " (0.5264420861990041,\n",
       "  'fitting to experimental setups in recognition? arXiv preprint arXiv:2007.02519,\\n2020.\\n[93] M. Wallingford, H. Li, A. Achille, A. Ravichandran, C. Fowlkes, R. Bhotika, and S. Soatto.\\nTask adaptive parameter sharing for multi-task learning. arXiv preprint arXiv:2203.16708,\\n2022.\\n[94] H. Wang, S. Ge, Z. Lipton, and E. P. Xing. Learning robust global representations by penalizing\\nlocal predictive power. In Advances in Neural Information Processing Systems, pages 10506–\\n10518, 2019.\\n[95] X. Wang, D. Kondratyuk, K. M. Kitani, Y. Movshovitz-Attias, and E. Eban. Multiple networks\\nare more efficient than one: Fast and accurate models via ensembles and cascades. arXiv\\npreprint arXiv:2012.01988, 2020.\\n[96] M. Wortsman, G. Ilharco, M. Li, J. W. Kim, H. Hajishirzi, A. Farhadi, H. Namkoong, and\\nL. Schmi'),\n",
       " (0.5237973458122428,\n",
       "  'Table 31. We observed that using a larger shortlist k saturated\\nImageNet-1K performance at k=200. But using larger shortlists until k = 2048, the maximum value\\n33\\nTable 26: Top-1 classification accuracy (%) on ImageNet-1K of various ResNet50 models which\\nare finetuned on pretrained FF-2048 model. We observed that adding more non-linearities is able to\\ninduce nesting to a reasonable extent even if the model was not pretrained with nesting in mind.\\nRep. Size\\nfc\\n4.2 conv3,\\nfc\\n4.2 conv2,\\nconv3, fc\\n4.2 full,\\nfc\\nAll (MRL)\\n8\\n5.15\\n36.11\\n54.78\\n60.02\\n66.63\\n16\\n13.79\\n58.42\\n67.26\\n70.10\\n73.53\\n32\\n32.52\\n67.81\\n71.62\\n72.84\\n75.03\\n64\\n52.66\\n72.42\\n73.61\\n74.29\\n75.82\\n128\\n64.60\\n74.41\\n74.67\\n75.03\\n76.30\\n256\\n69.29\\n75.30\\n75.23\\n75.38\\n76.47\\n512\\n70.51\\n75.96\\n75.47\\n75.64\\n76.65\\n1024\\n70.19\\n76.18\\n75.70\\n75.75\\n76.76\\n2048\\n69.72\\n'),\n",
       " (0.5231518069037007,\n",
       "  'ion set. This policy is based on whether the\\nprediction confidence pi using representation size mi exceeds a learned threshold t∗\\ni . If pi ≥t∗\\ni , we\\nused predictions from representation size mi otherwise, we increased to representation size mi+1. To\\nlearn the optimal threshold t∗\\ni , we performed a grid search between 0 and 1 (100 samples). For each\\nthreshold tk, we computed the classification accuracy over our 10K image subset. We set t∗\\ni equal\\nto the smallest threshold tk that gave the best accuracy. We use this procedure to obtain thresholds\\nfor successive models, i.e., {t∗\\nj | j ∈{8, 16, 32, 64, . . . , 2048}}. To improve reliability of threshold\\nbased greedy policy, we use test time augmentation which has been used successfully in the past [82].\\nFor inference, we used the remaining'),\n",
       " (0.523091335646729,\n",
       "  'odel fine-tuning for text classification. arXiv\\npreprint arXiv:1801.06146, 2018.\\n[41] H. Hu, D. Dey, M. Hebert, and J. A. Bagnell. Learning anytime predictions in neural networks\\nvia adaptive loss balancing. In Proceedings of the AAAI Conference on Artificial Intelligence,\\nvolume 33, pages 3812–3821, 2019.\\n[42] P. Indyk and R. Motwani. Approximate nearest neighbors: towards removing the curse\\nof dimensionality. In Proceedings of the thirtieth annual ACM symposium on Theory of\\ncomputing, pages 604–613, 1998.\\n[43] H. Jain, V. Balasubramanian, B. Chunduri, and M. Varma. Slice: Scalable linear extreme\\nclassifiers trained on 100 million labels for related searches. In Proceedings of the Twelfth\\nACM International Conference on Web Search and Data Mining, pages 528–536, 2019.\\n[44] S. Jayaram Subr'),\n",
       " (0.5216890020309352,\n",
       "  'ch\\nusing hierarchical navigable small world graphs. IEEE transactions on pattern analysis and\\nmachine intelligence, 42(4):824–836, 2018.\\n[63] J. Masci, U. Meier, D. Cire¸san, and J. Schmidhuber. Stacked convolutional auto-encoders for\\nhierarchical feature extraction. In International conference on artificial neural networks, pages\\n52–59. Springer, 2011.\\n[64] P. Mitra, C. Murthy, and S. K. Pal. Unsupervised feature selection using feature similarity.\\nIEEE transactions on pattern analysis and machine intelligence, 24(3):301–312, 2002.\\n[65] V. Nanda, T. Speicher, J. P. Dickerson, S. Feizi, K. P. Gummadi, and A. Weller. Diffused\\nredundancy in pre-trained representations. arXiv preprint arXiv:2306.00183, 2023.\\n[66] P. Nayak. Understanding searches better than ever before. Google AI Blog, 2019. '),\n",
       " (0.5213640596628626,\n",
       "  'n artificial intelligence and statistics, pages 297–304. JMLR Workshop and Conference\\nProceedings, 2010.\\n[28] M. G. Harris and C. D. Giachritsis. Coarse-grained information dominates fine-grained\\ninformation in judgments of time-to-contact from retinal flow. Vision research, 40(6):601–611,\\n2000.\\n[29] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In\\nProceedings of the IEEE conference on computer vision and pattern recognition, pages 770–\\n778, 2016.\\n[30] K. He, H. Fan, Y. Wu, S. Xie, and R. Girshick. Momentum contrast for unsupervised visual\\nrepresentation learning. In Proceedings of the IEEE/CVF conference on computer vision and\\npattern recognition, pages 9729–9738, 2020.\\n[31] K. He, X. Chen, S. Xie, Y. Li, P. Dollár, and R. Girshick. Masked autoencoders'),\n",
       " (0.5206716571136055,\n",
       "  'e distribution, without sacrificing accuracy on other classes (Table 16 in\\nAppendix G). Additionally we find the accuracy between low-dimensional and high-dimensional\\nrepresentations is marginal for pretrain classes. We hypothesize that the higher-dimensional represen-\\ntations are required to differentiate the classes when few training examples of each are known. This\\nresults provides further evidence that different tasks require varying capacity based on their difficulty.\\nDisagreement across Dimensions.\\nThe information packing in Matryoshka Representations\\noften results in gradual increase of accuracy with increase in capacity. However, we observed that\\n8\\n(a)\\n(b)\\n(c)\\nFigure 9: Grad-CAM [80] progression of predictions in MRL model across 8, 16, 32 and 2048\\ndimensions. (a) 8-dimensional rep'),\n",
       " (0.5191697461376756,\n",
       "  'ations of the ACM, 62(11):44–45, 2019.\\n15\\n[90] P. Viola and M. Jones. Rapid object detection using a boosted cascade of simple features. In\\nProceedings of the 2001 IEEE computer society conference on computer vision and pattern\\nrecognition. CVPR 2001, volume 1, pages I–I. Ieee, 2001.\\n[91] C. Waldburger. As search needs evolve, microsoft makes ai tools for better search available\\nto researchers and developers. Microsoft AI Blog, 2019. URL https://blogs.microsoft.\\ncom/ai/bing-vector-search/.\\n[92] M. Wallingford, A. Kusupati, K. Alizadeh-Vahid, A. Walsman, A. Kembhavi, and A. Farhadi.\\nAre we overfitting to experimental setups in recognition? arXiv preprint arXiv:2007.02519,\\n2020.\\n[93] M. Wallingford, H. Li, A. Achille, A. Ravichandran, C. Fowlkes, R. Bhotika, and S. Soatto.\\nTask adaptive para'),\n",
       " (0.5179236537344254,\n",
       "  'irst m dimensions of FF-2048 for NN lookup, and 2) FF+SVD: performing SVD\\non the FF-2048 representations at the specified representation size, 3) FF+JL: performing random\\nprojection according to the Johnson-Lindenstrauss lemma [48] on the FF-2048 representations at\\nthe specified representation size. We also compared against the 1-NN accuracy of slimmable neural\\nnets [100] as an additional baseline. We observed these baseline models to perform very poorly at\\nlower dimensions, as they were not explicitly trained to learn Matryoshka Representations.\\nTable 2: 1-NN accuracy (%) on ImageNet-1K for various ResNet50 models.\\nRep. Size\\nRand. FS\\nSVD\\nJL\\nFF\\nSlimmable\\nMRL\\nMRL–E\\n8\\n2.36\\n19.14\\n0.11\\n58.93\\n1.00\\n62.19\\n57.45\\n16\\n12.06\\n46.02\\n0.09\\n66.77\\n5.12\\n67.91\\n67.05\\n32\\n32.91\\n60.78\\n0.06\\n68.84\\n16.95\\n69.46\\n68.6\\n'),\n",
       " (0.5176020132725798,\n",
       "  'rs.\\nWe also found that for both MRL and FF, as the shot number decreased, the required representa-\\ntion size to reach optimal accuracy decreased (Table 15). For example, we observed that 1-shot\\nperformance at 32 representation size had equal accuracy to 2048 representation size.\\nFLUID.\\nFor the long-tailed setting we evaluated MRL on the FLUID benchmark [92] which\\ncontains a mixture of pretrain and new classes. Table 16 shows the evaluation of the learned\\nrepresentation on FLUID. We observed that MRL provided up to 2% higher accuracy on novel\\nclasses in the tail of the distribution, without sacrificing accuracy on other classes. Additionally we\\nfound the accuracy between low-dimensional and high-dimensional representations was marginal for\\npretrain classes. For example, the 64-dimensional M'),\n",
       " (0.517251274869763,\n",
       "  'hoice learning for training diverse deep ensembles. Advances in Neural\\nInformation Processing Systems, 29, 2016.\\n[59] C. Li, H. Farkhoor, R. Liu, and J. Yosinski. Measuring the intrinsic dimension of objective\\nlandscapes. arXiv preprint arXiv:1804.08838, 2018.\\n[60] Y. Linde, A. Buzo, and R. Gray. An algorithm for vector quantizer design. IEEE Transactions\\non communications, 28(1):84–95, 1980.\\n[61] I. Loshchilov and F. Hutter.\\nDecoupled weight decay regularization.\\narXiv preprint\\narXiv:1711.05101, 2017.\\n[62] Y. A. Malkov and D. A. Yashunin. Efficient and robust approximate nearest neighbor search\\nusing hierarchical navigable small world graphs. IEEE transactions on pattern analysis and\\nmachine intelligence, 42(4):824–836, 2018.\\n[63] J. Masci, U. Meier, D. Cire¸san, and J. Schmidhuber. Stack'),\n",
       " (0.5166656689671904,\n",
       "  '000-way classification layer of FF-2048,\\nwith rank = 1000.\\n• Rand. LP: We compared against a linear classifier fit on randomly selected features [30].\\n• Slim. Net: We take pretrained slimmable neural networks [100] which are trained with a flexible\\nwidth backbone (25%, 50%, 75% and full width). For each representation size, we consider the\\nfirst k dimensions for classification. Note that training of slimmable neural networks becomes\\nunstable when trained below 25% width due to the hardness in optimization and low complexity of\\nthe model.\\nAt lower dimensions ( d ≤128), MRL outperforms all baselines significantly, which indicates that\\npretrained models lack the multifidelity of Matryoshka Representations and are incapable of fitting\\nan accurate linear classifier at low representation sizes.\\n'),\n",
       " (0.5164669829635458,\n",
       "  ' due to the inductive bias of gradient-based training [84], deep learning models tend to diffuse\\n“information” across the entire representation vector. The desired elasticity is usually enabled in the\\nexisting flat and fixed representations either through training multiple low-dimensional models [29],\\njointly optimizing sub-networks of varying capacity [9, 100] or post-hoc compression [38, 60]. Each\\nof these techniques struggle to meet the requirements for adaptive large-scale deployment either\\n∗Equal contribution – AK led the project with extensive support from GB and AR for experimentation.\\n36th Conference on Neural Information Processing Systems (NeurIPS 2022).\\narXiv:2205.13147v4  [cs.LG]  8 Feb 2024\\ndue to training/maintenance overhead, numerous expensive forward passes through all of '),\n",
       " (0.5149583643860406,\n",
       "  ') utilization\\nof the representation for downstream applications [50, 89]. Compute costs for the latter part of the\\npipeline scale with the embedding dimensionality as well as the data size (N) and label space (L).\\nAt web-scale [15, 85] this utilization cost overshadows the feature computation cost. The rigidity in\\nthese representations forces the use of high-dimensional embedding vectors across multiple tasks\\ndespite the varying resource and accuracy constraints that require flexibility.\\nHuman perception of the natural world has a naturally coarse-to-fine granularity [28, 32]. However,\\nperhaps due to the inductive bias of gradient-based training [84], deep learning models tend to diffuse\\n“information” across the entire representation vector. The desired elasticity is usually enabled in the'),\n",
       " (0.5149378055857572,\n",
       "  'ng, pages 1597–1607.\\nPMLR, 2020.\\n[13] Y. Chen, Z. Liu, H. Xu, T. Darrell, and X. Wang. Meta-baseline: exploring simple meta-\\nlearning for few-shot learning. In Proceedings of the IEEE/CVF International Conference on\\nComputer Vision, pages 9062–9071, 2021.\\n[14] M. Datar, N. Immorlica, P. Indyk, and V. S. Mirrokni. Locality-sensitive hashing scheme based\\non p-stable distributions. In Proceedings of the twentieth annual symposium on Computational\\ngeometry, pages 253–262, 2004.\\n[15] J. Dean. Challenges in building large-scale information retrieval systems. In Keynote of the\\n2nd ACM International Conference on Web Search and Data Mining (WSDM), volume 10,\\n2009.\\n[16] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. Imagenet: A large-scale\\nhierarchical image database. In 2009 IEEE co'),\n",
       " (0.5143995780109396,\n",
       "  'ithin the same larger network. However, the weights for each progressively smaller\\nnetwork can be different and often require distinct forward passes to isolate the final representations.\\nThis is detrimental for adaptive inference due to the need for re-encoding the entire retrieval database\\nwith expensive sub-net forward passes of varying capacities. Several works [23, 26, 65, 59] investigate\\nthe notions of intrinsic dimensionality and redundancy of representations and objective spaces pointing\\nto minimum description length [74]. Finally, ordered representations proposed by Rippel et al. [73]\\nuse nested dropout in the context of autoencoders to learn nested representations. MRL differentiates\\nitself in formulation by optimizing only for O(log(d)) nesting dimensions instead of O(d). Despit'),\n",
       " (0.5126746784054812,\n",
       "  'e high yet constant deep featurization costs or the search cost which\\nscales with the size of the label space and data. Efficient neural networks address the first issue\\nthrough a variety of algorithms [25, 54] and design choices [39, 53, 87]. However, with a strong\\nfeaturizer, most of the issues with scale are due to the linear dependence on number of labels (L), size\\nof the data (N) and representation size (d), stressing RAM, disk and processor all at the same time.\\nThe sub-linear complexity dependence on number of labels has been well studied in context of\\ncompute [3, 43, 69] and memory [20] using Approximate Nearest Neighbor Search (ANNS) [62] or\\nleveraging the underlying hierarchy [17, 55]. In case of the representation size, often dimensionality\\nreduction [77, 88], hashing techniques'),\n",
       " (0.5123236527059911,\n",
       "  'ion size for MRL &\\nFF models showing the capture of underlying\\nhierarchy through tight information bottlenecks.\\n8\\n16\\n32\\n64\\n128\\n256\\n512\\n1024\\n2048\\nRepresentation Size\\n65\\n70\\n75\\n80\\n85\\n90\\n95\\nTop-1 Accuracy (%)\\nmeasuring device\\nbuilding\\ngarment\\ntool\\nnourishment\\nprotective covering\\nvessel\\noscine\\nFigure 11:\\nDiverse per-superclass accuracy\\ntrends across representation sizes for ResNet50-\\nMRL on ImageNet-1K.\\n9\\noccurs with both MRL and FF models; MRL is more accurate across dimensions. This shows that\\ntight information bottlenecks while not highly accurate for fine-grained classification, do capture\\nrequired semantic information for coarser classification that could be leveraged for adaptive routing\\nfor retrieval and classification. Mutifidelity of Matryoshka Representation naturally captures the\\nund'),\n",
       " (0.5116100171147839,\n",
       "  '\\n403\\n26.25\\n49.32\\n59.48\\n14.15\\n11.00\\n9.15\\n7.61\\n20.55\\n18.36\\n16.78\\n15.17\\n192\\n807\\n27.94\\n51.32\\n61.32\\n15.29\\n11.89\\n9.88\\n8.18\\n21.86\\n19.46\\n17.71\\n15.96\\n384\\n1614\\n29.03\\n52.53\\n62.45\\n15.99\\n12.46\\n10.35\\n8.56\\n22.64\\n20.14\\n18.29\\n16.47\\n768\\n3227\\n29.87\\n53.36\\n63.13\\n16.54\\n12.90\\n10.71\\n8.85\\n23.23\\n20.67\\n18.75\\n16.85\\n1536\\n6454\\n30.52\\n54.02\\n63.79\\n16.99\\n13.27\\n11.01\\n9.08\\n23.73\\n21.09\\n19.12\\n17.16\\nlarge-scale (1000-way) setting. We evaluate for n ∈1, 3, 5, 7, 9 with 9 being the maximum value for\\nn because there are 10 images per class.\\nWe observed that MRL had equal performance to FF across all representation sizes and shot numbers.\\nWe also found that for both MRL and FF, as the shot number decreased, the required representa-\\ntion size to reach optimal accuracy decreased (Table 15). For example, we observed that 1-shot\\nperfor'),\n",
       " (0.5115373526683877,\n",
       "  'th a fraction of the MFLOPs.\\nG\\nFew-shot and Sample Efficiency\\nWe compared MRL, MRL–E, and FF on various benchmarks to observe the effect of representation\\nsize on sample efficiency. We used Nearest Class Means [79] for classification which has been shown\\nto be effective in the few-shot regime [13].\\nImageNetV2.\\nRepresentations are evaluated on ImageNetV2 with the n-shot k-way setup. Ima-\\ngeNetV2 is a dataset traditionally used to evaluate the robustness of models to natural distribution\\nshifts. For our experiments we evaluate accuracy of the model given n examples from the Ima-\\ngeNetV2 distribution. We benchmark representations in the traditional small-scale (10-way) and\\n25\\nTable 9: Retrieve a shortlist of 200-NN with Ds sized representations on ImageNetV2 via exact\\nsearch with L2 distance '),\n",
       " (0.5096553559088843,\n",
       "  'Boden, A. Borchers, et al. In-datacenter performance analysis of a tensor processing unit.\\nIn Proceedings of the 44th annual international symposium on computer architecture, pages\\n1–12, 2017.\\n[50] T. C. Kaz Sato.\\nVertex ai matching engine.\\nMicrosoft AI Blog, 2021.\\nURL\\nhttps://cloud.google.com/blog/topics/developers-practitioners/\\nfind-anything-blazingly-fast-googles-vector-search-technology.\\n[51] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional\\nneural networks. Advances in neural information processing systems, 25, 2012.\\n[52] B. Kulis, P. Jain, and K. Grauman. Fast similarity search for learned metrics. IEEE Transactions\\non Pattern Analysis and Machine Intelligence, 31(12):2143–2157, 2009.\\n13\\n[53] A. Kusupati, M. Singh, K. Bhatia, A. Kumar, P.'),\n",
       " (0.5094090095201461,\n",
       "  'guage applications are built [40] on large language models [8] that are pretrained [68, 75]\\nin a un/self-supervised fashion with masked language modelling [19] or autoregressive training [70].\\nMatryoshka Representation Learning (MRL) is complementary to all these setups and can be\\nadapted with minimal overhead (Section 3). MRL equips representations with multifidelity at no\\nadditional cost which enables adaptive deployment based on the data and task (Section 4).\\nEfficient Classification and Retrieval.\\nEfficiency in classification and retrieval during inference\\ncan be studied with respect to the high yet constant deep featurization costs or the search cost which\\nscales with the size of the label space and data. Efficient neural networks address the first issue\\nthrough a variety of algorithm'),\n",
       " (0.5085071864918316,\n",
       "  'e, and L. Zettlemoyer.\\nDeep contextualized word representations. In Proceedings of the 2018 Conference of the\\nNorth American Chapter of the Association for Computational Linguistics: Human Language\\nTechnologies, Volume 1 (Long Papers), pages 2227–2237, New Orleans, Louisiana, June\\n2018. Association for Computational Linguistics. doi: 10.18653/v1/N18-1202. URL https:\\n//aclanthology.org/N18-1202.\\n[69] Y. Prabhu, A. Kusupati, N. Gupta, and M. Varma. Extreme regression for dynamic search\\nadvertising. In Proceedings of the 13th International Conference on Web Search and Data\\nMining, pages 456–464, 2020.\\n[70] A. Radford, K. Narasimhan, T. Salimans, and I. Sutskever. Improving language understand-\\ning by generative pre-training. OpenAI Blog, 2018. URL https://openai.com/blog/\\nlanguage-unsupervise'),\n",
       " (0.5079537571634651,\n",
       "  'rmance of ResNet50 representations on ImageNet-1K across\\ndimensionalities for MRL, MRL–E, FF, slimmable networks along with post-hoc compression\\nof vectors using SVD and random feature selection. Matryoshka Representations are often the\\nmost accurate while being up to 3% better than the FF baselines. Similar to classification, post-hoc\\ncompression and slimmable network baselines suffer from significant drop-off in retrieval mAP@10\\nwith ≤256 dimensions. Appendix E discusses the mAP@10 of the same models on ImageNet-4K.\\nMRL models are capable of performing accurate retrieval at various granularities without the\\nadditional expense of multiple model forward passes for the web-scale databases. FF models\\nalso generate independent databases which become prohibitively expense to store and switch i'),\n",
       " (0.5078063580208143,\n",
       "  '36th Conference on Neural Information Processing Systems (NeurIPS 2022).\\narXiv:2205.13147v4  [cs.LG]  8 Feb 2024\\ndue to training/maintenance overhead, numerous expensive forward passes through all of the data,\\nstorage and memory cost for multiple copies of encoded data, expensive on-the-fly feature selection\\nor a significant drop in accuracy. By encoding coarse-to-fine-grained representations, which are as\\naccurate as the independently trained counterparts, we learn with minimal overhead a representation\\nthat can be deployed adaptively at no additional cost during inference.\\nWe introduce\\nMatryoshka Representation Learning (MRL) to induce flexibility in the learned\\nrepresentation. MRL learns representations of varying capacities within the same high-dimensional\\nvector through explicit optim'),\n",
       " (0.5060295902517524,\n",
       "  ', and signif-\\nicantly for lower ones. This demonstrates that training to learn Matryoshka Representations\\nis feasible and extendable even for extremely large scale datasets.\\nWe also demonstrate that\\nMatryoshka Representations are learned at interpolated dimensions for both ALIGN and JFT-\\nViT, as shown in Table 5, despite not being trained explicitly at these dimensions. Lastly, Table 6\\nshows that MRL training leads to a increase in the cosine similarity span between positive and\\nrandom image-text pairs.\\nWe also evaluated the capability of Matryoshka Representations to extend to other natural language\\nprocessing via masked language modeling (MLM) with BERT [19], whose results are tabulated\\nin Table 7. Without any hyper-parameter tuning, we observed Matryoshka Representations to be\\nwithin 0.'),\n",
       " (0.5059144007284542,\n",
       "  ' are within 0.1% of the maximum value achievable without reranking on MRL representations,\\nas seen in Table 10, are bolded.\\nShortlist Length = 200\\nDs\\nDr\\nMFLOPs\\nTop-1\\nmAP@10\\nmAP@25\\nmAP@50\\nmAP@100\\nP@10\\nP@25\\nP@50\\nP@100\\n8\\n16\\n34\\n16.84\\n8.70\\n6.88\\n5.88\\n5.08\\n13.86\\n12.80\\n11.98\\n11.10\\n32\\n20.73\\n10.66\\n8.19\\n6.77\\n5.61\\n16.18\\n14.39\\n13.02\\n11.61\\n64\\n23.11\\n11.91\\n9.03\\n7.36\\n6.00\\n17.56\\n15.34\\n13.67\\n11.99\\n128\\n24.63\\n12.71\\n9.59\\n7.76\\n6.25\\n18.42\\n15.94\\n14.08\\n12.22\\n256\\n25.5\\n13.24\\n9.96\\n8.03\\n6.42\\n19.00\\n16.35\\n14.36\\n12.37\\n512\\n26.07\\n13.59\\n10.21\\n8.20\\n6.53\\n19.37\\n16.62\\n14.54\\n12.46\\n1024\\n26.52\\n13.85\\n10.40\\n8.34\\n6.61\\n19.65\\n16.80\\n14.68\\n12.53\\n2048\\n26.94\\n14.11\\n10.57\\n8.45\\n6.68\\n19.92\\n16.98\\n14.79\\n12.58\\n16\\n32\\n67\\n21.44\\n11.24\\n8.72\\n7.26\\n6.02\\n17.02\\n15.30\\n13.92\\n12.41\\n64\\n24.36\\n12.78\\n9.75\\n7.96\\n6.43\\n18.72\\n16.41\\n14.63\\n12.74\\n128\\n26.08\\n13.70\\n10.39\\n8.3'),\n",
       " (0.5054809569333812,\n",
       "  'Yang, Y. Xia, Y.-T. Chen, Z. Parekh, H. Pham, Q. Le, Y.-H. Sung, Z. Li, and T. Duerig.\\nScaling up visual and vision-language representation learning with noisy text supervision. In\\nInternational Conference on Machine Learning, pages 4904–4916. PMLR, 2021.\\n[47] J. Johnson, M. Douze, and H. Jégou. Billion-scale similarity search with GPUs. IEEE\\nTransactions on Big Data, 7(3):535–547, 2019.\\n[48] W. B. Johnson. Extensions of lipschitz mappings into a hilbert space. Contemp. Math., 26:\\n189–206, 1984.\\n[49] N. P. Jouppi, C. Young, N. Patil, D. Patterson, G. Agrawal, R. Bajwa, S. Bates, S. Bhatia,\\nN. Boden, A. Borchers, et al. In-datacenter performance analysis of a tensor processing unit.\\nIn Proceedings of the 44th annual international symposium on computer architecture, pages\\n1–12, 2017.\\n[50] T.'),\n",
       " (0.5051971478829935,\n",
       "  ', 2020.\\n[55] A. Kusupati, M. Wallingford, V. Ramanujan, R. Somani, J. S. Park, K. Pillutla, P. Jain,\\nS. Kakade, and A. Farhadi. Llc: Accurate, multi-purpose learnt low-dimensional binary codes.\\nAdvances in Neural Information Processing Systems, 34, 2021.\\n[56] G. Leclerc, A. Ilyas, L. Engstrom, S. M. Park, H. Salman, and A. Madry. ffcv. https:\\n//github.com/libffcv/ffcv/, 2022. commit 607d117.\\n[57] Y. LeCun, Y. Bengio, and G. Hinton. Deep learning. nature, 521(7553):436–444, 2015.\\n[58] S. Lee, S. Purushwalkam Shiva Prakash, M. Cogswell, V. Ranjan, D. Crandall, and D. Batra.\\nStochastic multiple choice learning for training diverse deep ensembles. Advances in Neural\\nInformation Processing Systems, 29, 2016.\\n[59] C. Li, H. Farkhoor, R. Liu, and J. Yosinski. Measuring the intrinsic dimension of '),\n",
       " (0.5046073217362259,\n",
       "  '16, 32, 64, 128, 256, 512, 1024, 2048} for ease of comparison to reported numbers using 1-NN ac-\\ncuracy (%). As shown in Table 29, we observed that while performance interpolated, MRL-Uniform\\nsuffered at low dimensions as the logarithmic spacing of MRL-log resulted in tighter packing of\\ninformation in these initial dimensions. The higher nesting dimensions of MRL-Uniform did not\\nhelp in significant accuracy improvement due to accuracy saturation, which is often logarithmic in\\nrepresentation size as shown by FF models. Note that the slight improvement at dimensions higher\\nthan 512 for MRL-Uniform is due to multiple granularities around them compared to just three for\\nMRL-log, which are not useful in practice for efficiency.\\nLower Dimensionality.\\nWe experimented with training MRL with smalle'),\n",
       " (0.5045427423510204,\n",
       "  'nts.\\nAcknowledgments\\nWe are grateful to Srinadh Bhojanapalli, Lovish Madaan, Raghav Somani, Ludwig Schmidt, and\\nVenkata Sailesh Sanampudi for helpful discussions and feedback. Aditya Kusupati also thanks Tom\\nDuerig and Rahul Sukthankar for their support. Part of the paper’s large-scale experimentation is\\nsupported through a research GCP credit award from Google Cloud and Google Research. Gantavya\\nBhatt is supported in part by the CONIX Research Center, one of six centers in JUMP, a Semicon-\\nductor Research Corporation (SRC) program sponsored by DARPA. Sham Kakade acknowledges\\nfunding from the NSF award CCF-1703574 and ONR N00014-22-1-2377. Ali Farhadi acknowledges\\nfunding from the NSF awards IIS 1652052, IIS 17303166, DARPA N66001-19-2-4031, DARPA\\nW911NF-15-1-0543 and gifts from Allen Inst'),\n",
       " (0.5044183849947055,\n",
       "  'Conference on Machine Learning, pages 5389–5400. PMLR,\\n2019.\\n[73] O. Rippel, M. Gelbart, and R. Adams. Learning ordered representations with nested dropout.\\nIn International Conference on Machine Learning, pages 1746–1754. PMLR, 2014.\\n[74] J. Rissanen. Modeling by shortest data description. Automatica, 14(5):465–471, 1978.\\n[75] S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf. Transfer learning in natural language\\nprocessing. In Proceedings of the 2019 conference of the North American chapter of the\\nassociation for computational linguistics: Tutorials, pages 15–18, 2019.\\n[76] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy,\\nA. Khosla, M. Bernstein, et al. Imagenet large scale visual recognition challenge. International\\njournal of computer vision, 115'),\n",
       " (0.5037880656558685,\n",
       "  'ines significantly, which indicates that\\npretrained models lack the multifidelity of Matryoshka Representations and are incapable of fitting\\nan accurate linear classifier at low representation sizes.\\nWe compared the performance of MRL models at various representation sizes via 1-nearest neighbors\\n(1-NN) image classification accuracy on ImageNet-1K in Table 2 and Figure 3. We provide detailed\\ninformation regarding the k-NN search pipeline in Appendix E. We compared against a baseline\\nof attempting to enforce nesting to a FF-2048 model by 1) Random Feature Selection (Rand. FS):\\nconsidering the first m dimensions of FF-2048 for NN lookup, and 2) FF+SVD: performing SVD\\non the FF-2048 representations at the specified representation size, 3) FF+JL: performing random\\nprojection according to the J'),\n",
       " (0.5037130038735128,\n",
       "  ',\\n(1)\\nwhere L: RL × [L] →R+ is the multi-class softmax cross-entropy loss function. This is a standard\\noptimization problem that can be solved using sub-gradient descent methods. We set all the impor-\\ntance scales, cm = 1 for all m ∈M; see Section 5 for ablations. Lastly, despite only optimizing\\nfor O(log(d)) nested dimensions, MRL results in accurate representations, that interpolate, for\\ndimensions that fall between the chosen granularity of the representations (Section 4.2).\\nWe call this formulation as Matryoshka Representation Learning (MRL). A natural way to make\\nthis efficient is through weight-tying across all the linear classifiers, i.e., by defining W(m) = W1:m\\nfor a set of common weights W ∈RL×d. This would reduce the memory cost due to the linear\\nclassifiers by almost half, whic'),\n",
       " (0.5032425511499022,\n",
       "  'n such scenarios, we\\nobserved that smaller representation size models would often get confused due to other objects and fail\\nto extract the object of interest which generated the correct label. We also observed a different nature\\n31\\nFigure 12: Progression of relative per-class accuracy vs MRL-2048. As the dimensionality increases,\\nthe spread shrinks while the class marked (x) (Madagascar cat) loses accuracy.\\nTable 22: Percentage of ImageNet-1K validation set that is first correctly predicted using each\\nrepresentation size d. We note that 18.46% of the samples cannot be correctly predicted by any\\nrepresentation size. The remaining 81.54% constitutes the oracle accuracy.\\nRep. Size\\n8\\n16\\n32\\n64\\n128\\n256\\n512\\n1024\\n2048\\nAlways\\nWrong\\nCorrectly\\nPredicted\\n67.46\\n8.78\\n2.58\\n1.35\\n0.64\\n0.31\\n0.20\\n0.12\\n0.06\\n'),\n",
       " (0.5030104028937578,\n",
       "  'reme\\nclassifiers trained on 100 million labels for related searches. In Proceedings of the Twelfth\\nACM International Conference on Web Search and Data Mining, pages 528–536, 2019.\\n[44] S. Jayaram Subramanya, F. Devvrit, H. V. Simhadri, R. Krishnawamy, and R. Kadekodi.\\nDiskann: Fast accurate billion-point nearest neighbor search on a single node. Advances in\\nNeural Information Processing Systems, 32, 2019.\\n[45] H. Jegou, M. Douze, and C. Schmid. Product quantization for nearest neighbor search. IEEE\\ntransactions on pattern analysis and machine intelligence, 33(1):117–128, 2010.\\n[46] C. Jia, Y. Yang, Y. Xia, Y.-T. Chen, Z. Parekh, H. Pham, Q. Le, Y.-H. Sung, Z. Li, and T. Duerig.\\nScaling up visual and vision-language representation learning with noisy text supervision. In\\nInternational Confe'),\n",
       " (0.5030004319830029,\n",
       "  ' results in Section 5.1 reveal interesting weaknesses of MRL that would be logical directions\\nfor future work. (1) Optimizing the weightings of the nested losses to obtain a Pareto optimal\\naccuracy-vs-efficiency trade-off – a potential solution could emerge from adaptive loss balancing\\naspects of anytime neural networks [41]. (2) Using different losses at various fidelities aimed at\\nsolving a specific aspect of adaptive deployment – e.g. high recall for 8-dimension and robustness\\nfor 2048-dimension. (3) Learning a search data-structure, like differentiable k-d tree, on top of\\nMatryoshka Representation to enable dataset and representation aware retrieval. (4) Finally, the\\njoint optimization of multi-objective MRL combined with end-to-end learnable search data-structure\\nto have data-driven a'),\n",
       " (0.5027509232665323,\n",
       "  ' Appendix C ablate over the choice of initial granularity and spacing of the\\ngranularites. Table 28 reaffirms the design choice to shun extremely low dimensions that have poor\\nclassification accuracy as initial granularity for MRL while Table 29 confirms the effectiveness of\\nlogarthmic granularity spacing inspired from the behaviour of accuracy saturation across dimensions\\nover uniform. Lastly, Tables 30 and 31 in Appendix K.2 show that the retrieval performance saturates\\nafter a certain shortlist dimension and length depending on the complexity of the dataset.\\n6\\nDiscussion and Conclusions\\nThe results in Section 5.1 reveal interesting weaknesses of MRL that would be logical directions\\nfor future work. (1) Optimizing the weightings of the nested losses to obtain a Pareto optimal\\naccuracy-vs'),\n",
       " (0.5022169655976187,\n",
       "  'computer vision,\\npages 843–852, 2017.\\n[86] I. Sutskever, J. Martens, G. Dahl, and G. Hinton. On the importance of initialization and\\nmomentum in deep learning. In International conference on machine learning, pages 1139–\\n1147. PMLR, 2013.\\n[87] M. Tan and Q. Le. Efficientnet: Rethinking model scaling for convolutional neural networks.\\nIn International conference on machine learning, pages 6105–6114. PMLR, 2019.\\n[88] L. Van Der Maaten, E. Postma, J. Van den Herik, et al. Dimensionality reduction: a comparative.\\nJ Mach Learn Res, 10(66-71):13, 2009.\\n[89] M. Varma. Extreme classification. Communications of the ACM, 62(11):44–45, 2019.\\n15\\n[90] P. Viola and M. Jones. Rapid object detection using a boosted cascade of simple features. In\\nProceedings of the 2001 IEEE computer society conference on '),\n",
       " (0.5012466428191285,\n",
       "  'arning. In Proceedings of the IEEE/CVF conference on computer vision and\\npattern recognition, pages 9729–9738, 2020.\\n[31] K. He, X. Chen, S. Xie, Y. Li, P. Dollár, and R. Girshick. Masked autoencoders are scalable\\nvision learners. arXiv preprint arXiv:2111.06377, 2021.\\n[32] J. Hegdé. Time course of visual perception: coarse-to-fine processing and beyond. Progress in\\nneurobiology, 84(4):405–439, 2008.\\n[33] D. Hendrycks and K. Gimpel. A baseline for detecting misclassified and out-of-distribution\\nexamples in neural networks. arXiv preprint arXiv:1610.02136, 2016.\\n[34] D. Hendrycks, S. Basart, N. Mu, S. Kadavath, F. Wang, E. Dorundo, R. Desai, T. Zhu,\\nS. Parajuli, M. Guo, et al. The many faces of robustness: A critical analysis of out-of-\\ndistribution generalization. In Proceedings of the IEE'),\n",
       " (0.5010086695028382,\n",
       "  'and ALIGN data with models like ResNet and ViT making it extremely\\nexpensive to run things multiple times.\\n(d) Did you include the total amount of compute and the type of resources used (e.g., type\\nof GPUs, internal cluster, or cloud provider)? [Yes] See Appendix C and Appendix I.\\n4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...\\n(a) If your work uses existing assets, did you cite the creators? [Yes]\\n(b) Did you mention the license of the assets? [No] All the non-proprietary datasets and\\ncode used are public under MIT, BSD or CC licenses.\\n(c) Did you include any new assets either in the supplemental material or as a URL? [Yes]\\nWe created a new subset of ImageNet-21K for downstream evaluation of retrieval\\nperformance at scale. See Section 4.3'),\n",
       " (0.5005361551848984,\n",
       "  'Appendix J put forward the potential for MRL\\nto be a systematic framework for analyzing the utility and efficiency of information bottlenecks.\\nSuperclass Accuracy.\\nAs the information bottleneck becomes smaller, the overall accuracy on\\nfine-grained classes decreases rapidly (Figure 3). However, the drop-off is not as significant when\\nevaluated at a superclass level (Table 24 in Appendix J). Figure 10 presents that this phenomenon\\n8\\n16\\n32\\n64\\n128\\n256\\n512\\n1024\\n2048\\nRepresentation Size\\n84\\n86\\n88\\n90\\nTop-1 Accuracy (%)\\nMRL\\nFF\\nFigure 10: 31-way ImageNet-1K superclass clas-\\nsification across representation size for MRL &\\nFF models showing the capture of underlying\\nhierarchy through tight information bottlenecks.\\n8\\n16\\n32\\n64\\n128\\n256\\n512\\n1024\\n2048\\nRepresentation Size\\n65\\n70\\n75\\n80\\n85\\n90\\n95\\nTop-1 Accuracy')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "okn: doument chunk found \"computational and statistical constraints\" for PROMPT_0\n",
    "- generally the context looks of low quality  (lots of numbers figures without semantics, broken sentences etc. )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation\n",
    "Now that we have built our \"vector database\" and retrieved our context, we do the inference part:\n",
    "\n",
    "First, we augment the prompt using the context we retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py4ragTools.prompt_tools import PromptTools\n",
    "\n",
    "pt = PromptTools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# okn: test some other system templates\n",
    "\n",
    "SYS_PROMPT_1 = \"\"\" \\\n",
    "Context:\n",
    "{context}\n",
    "Based on the context provided above, answer the following question. Do not use any external knowledge.\n",
    "If the answer is not present in the context, respond with \"I don't know.\"\n",
    "If the context is empty or irrelevant to the question, respond with \"No relevant information found in the context.\"\n",
    "\"\"\"\n",
    "\n",
    "# okn: cites template did not really make a difference\n",
    "SYS_PROMPT_2 = \"\"\" \\\n",
    "Context:\n",
    "{context}\n",
    "Based on the context provided above, answer the following question. Do not use any external knowledge.\n",
    "Ensure your response cites the relevant context information for each fact you provide.\"\n",
    "\"\"\"\n",
    "\n",
    "# pt.SYSTEM_TEMPLATE = SYS_PROMPT_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mu, S. Kadavath, F. Wang, E. Dorundo, R. Desai, T. Zhu,\n",
      "S. Parajuli, M. Guo, et al. The many faces of robustness: A critical analysis of out-of-\n",
      "distribution generalization. In Proceedings of the IEEE/CVF International Conference on\n",
      "Computer Vision, pages 8340–8349, 2021.\n",
      "12\n",
      "[35] D. Hendrycks, K. Zhao, S. Basart, J. Steinhardt, and D. Song. Natural adversarial examples.\n",
      "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,\n",
      "pages 15262–15271, 2021.\n",
      "[36] S. Hooker, A. Courville, G. Clark, Y. Dauphin, and A. Frome. What do compressed deep\n",
      "neural networks forget? arXiv preprint arXiv:1911.05248, 2019.\n",
      "[37] S. Hooker, N. Moorosi, G. Clark, S. Bengio, and E. Denton. Characterising bias in compressed\n",
      "models. arXiv preprint arXiv:2010.03058, 2020.\n",
      "[38] H. Hotelling\\nLab/robustness.\n",
      "[25] A. Gholami, S. Kim, Z. Dong, Z. Yao, M. W. Mahoney, and K. Keutzer. A survey of\n",
      "quantization methods for efficient neural network inference. arXiv preprint arXiv:2103.13630,\n",
      "2021.\n",
      "[26] S. Gong, V. N. Boddeti, and A. K. Jain. On the intrinsic dimensionality of image representations.\n",
      "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,\n",
      "pages 3987–3996, 2019.\n",
      "[27] M. Gutmann and A. Hyvärinen. Noise-contrastive estimation: A new estimation principle for\n",
      "unnormalized statistical models. In Proceedings of the thirteenth international conference\n",
      "on artificial intelligence and statistics, pages 297–304. JMLR Workshop and Conference\n",
      "Proceedings, 2010.\n",
      "[28] M. G. Harris and C. D. Giachritsis. Coarse-grained information dominates fine-grained\n",
      "info\\nMatryoshka Representation Learning\n",
      "Aditya Kusupati∗†⋄, Gantavya Bhatt∗†, Aniket Rege∗†,\n",
      "Matthew Wallingford†, Aditya Sinha⋄, Vivek Ramanujan†, William Howard-Snyder†,\n",
      "Kaifeng Chen⋄, Sham Kakade‡, Prateek Jain⋄and Ali Farhadi†\n",
      "†University of Washington, ⋄Google Research, ‡Harvard University\n",
      "{kusupati,ali}@cs.washington.edu, prajain@google.com\n",
      "Abstract\n",
      "Learned representations are a central component in modern ML systems, serv-\n",
      "ing a multitude of downstream tasks. When training such representations, it\n",
      "is often the case that computational and statistical constraints for each down-\n",
      "stream task are unknown. In this context, rigid fixed-capacity representations\n",
      "can be either over or under-accommodating to the task at hand. This leads us\n",
      "to ask: can we design a flexible representation that can ad\\n= {12, 24, 48, 96, 192, 384, 768} as\n",
      "the explicitly optimized nested dimensions respectively. Lastly, we extensively compare the MRL\n",
      "and MRL–E models to independently trained low-dimensional (fixed feature) representations (FF),\n",
      "dimensionality reduction (SVD), sub-net method (slimmable networks [100]) and randomly selected\n",
      "features of the highest capacity FF model.\n",
      "In section 4.2, we evaluate the quality and capacity of the learned representations through linear\n",
      "classification/probe (LP) and 1-nearest neighbour (1-NN) accuracy. Experiments show that MRL\n",
      "models remove the dependence on |M| resource-intensive independently trained models for the\n",
      "coarse-to-fine representations while being as accurate. Lastly, we show that despite optimizing only\n",
      "for |M| dimensions, MRL models diffuse the info\\n unknown. In this context, rigid fixed-capacity representations\n",
      "can be either over or under-accommodating to the task at hand. This leads us\n",
      "to ask: can we design a flexible representation that can adapt to multiple down-\n",
      "stream tasks with varying computational resources? Our main contribution is\n",
      "Matryoshka Representation Learning (MRL) which encodes information at\n",
      "different granularities and allows a single embedding to adapt to the computational\n",
      "constraints of downstream tasks. MRL minimally modifies existing representation\n",
      "learning pipelines and imposes no additional cost during inference and deployment.\n",
      "MRL learns coarse-to-fine representations that are at least as accurate and rich as\n",
      "independently trained low-dimensional representations. The flexibility within the\n",
      "learned Matryoshka \\nrXiv preprint arXiv:1911.05248, 2019.\n",
      "[37] S. Hooker, N. Moorosi, G. Clark, S. Bengio, and E. Denton. Characterising bias in compressed\n",
      "models. arXiv preprint arXiv:2010.03058, 2020.\n",
      "[38] H. Hotelling. Analysis of a complex of statistical variables into principal components. Journal\n",
      "of educational psychology, 24(6):417, 1933.\n",
      "[39] A. G. Howard, M. Zhu, B. Chen, D. Kalenichenko, W. Wang, T. Weyand, M. Andreetto, and\n",
      "H. Adam. Mobilenets: Efficient convolutional neural networks for mobile vision applications.\n",
      "arXiv preprint arXiv:1704.04861, 2017.\n",
      "[40] J. Howard and S. Ruder. Universal language model fine-tuning for text classification. arXiv\n",
      "preprint arXiv:1801.06146, 2018.\n",
      "[41] H. Hu, D. Dey, M. Hebert, and J. A. Bagnell. Learning anytime predictions in neural networks\n",
      "via adaptive loss bal\\nxperiments...\n",
      "(a) Did you include the code, data, and instructions needed to reproduce the main ex-\n",
      "perimental results (either in the supplemental material or as a URL)? [Yes] See sup-\n",
      "plemental material and Appendix A. All the code and public models will be open\n",
      "sourced.\n",
      "(b) Did you specify all the training details (e.g., data splits, hyperparameters, how they\n",
      "were chosen)? [Yes] See Section 4 and Appendix C.\n",
      "(c) Did you report error bars (e.g., with respect to the random seed after running experi-\n",
      "ments multiple times)? [No] We benchmarked on large-scale datasets like ImageNet-\n",
      "1K, JFT-300M and ALIGN data with models like ResNet and ViT making it extremely\n",
      "expensive to run things multiple times.\n",
      "(d) Did you include the total amount of compute and the type of resources used (e.g., type\n",
      "of\\nd K. Grauman. Fast similarity search for learned metrics. IEEE Transactions\n",
      "on Pattern Analysis and Machine Intelligence, 31(12):2143–2157, 2009.\n",
      "13\n",
      "[53] A. Kusupati, M. Singh, K. Bhatia, A. Kumar, P. Jain, and M. Varma. Fastgrnn: A fast, accurate,\n",
      "stable and tiny kilobyte sized gated recurrent neural network. Advances in Neural Information\n",
      "Processing Systems, 31, 2018.\n",
      "[54] A. Kusupati, V. Ramanujan, R. Somani, M. Wortsman, P. Jain, S. Kakade, and A. Farhadi.\n",
      "Soft threshold weight reparameterization for learnable sparsity. In International Conference\n",
      "on Machine Learning, pages 5544–5555. PMLR, 2020.\n",
      "[55] A. Kusupati, M. Wallingford, V. Ramanujan, R. Somani, J. S. Park, K. Pillutla, P. Jain,\n",
      "S. Kakade, and A. Farhadi. Llc: Accurate, multi-purpose learnt low-dimensional binary codes.\n",
      "Advanc\\nce of MRL model on 31-way classification (1 extra class is for reject token) on\n",
      "ImageNet-1K superclasses.\n",
      "Rep. Size\n",
      "8\n",
      "16\n",
      "32\n",
      "64\n",
      "128\n",
      "256\n",
      "512\n",
      "1024\n",
      "2048\n",
      "MRL\n",
      "85.57\n",
      "88.67\n",
      "89.48\n",
      "89.82\n",
      "89.97\n",
      "90.11\n",
      "90.18\n",
      "90.22\n",
      "90.21\n",
      "Matryoshka Representations at Arbitrary Granularities.\n",
      "To train MRL, we used nested di-\n",
      "mensions at logarithmic granularities M = {8, 16, . . . , 1024, 2048} as detailed in Section 3. We\n",
      "made this choice for two empirically-driven reasons: a) The accuracy improvement with increasing\n",
      "representation size was more logarithmic than linear (as shown by FF models in Figure 2). This indi-\n",
      "cated that optimizing for granularities increasing in a non-logarithmic fashion would be sub-optimal\n",
      "both for maximum performance and expected efficiency; b) If we have m arbitrary granularities,\n",
      "the expected\\nan one: Fast and accurate models via ensembles and cascades. arXiv\n",
      "preprint arXiv:2012.01988, 2020.\n",
      "[96] M. Wortsman, G. Ilharco, M. Li, J. W. Kim, H. Hajishirzi, A. Farhadi, H. Namkoong, and\n",
      "L. Schmidt. Robust fine-tuning of zero-shot models. arXiv preprint arXiv:2109.01903, 2021.\n",
      "[97] Z. Wu, Y. Xiong, S. Yu, and D. Lin. Unsupervised feature learning via non-parametric\n",
      "instance-level discrimination. arXiv preprint arXiv:1805.01978, 2018.\n",
      "[98] J. Yosinski, J. Clune, Y. Bengio, and H. Lipson. How transferable are features in deep neural\n",
      "networks? Advances in neural information processing systems, 27, 2014.\n",
      "[99] H.-F. Yu, K. Zhong, J. Zhang, W.-C. Chang, and I. S. Dhillon. Pecos: Prediction for enormous\n",
      "and correlated output spaces. Journal of Machine Learning Research, 23(98):1–32, 2022.\n",
      "[1\\n\n",
      "These experiments show that MRL seamlessly scales to large-scale models and web-scale datasets\n",
      "while providing the otherwise prohibitively expensive multi-granularity in the process. We also\n",
      "have similar observations when pretraining BERT; please see Appendix D.2 for more details. Our\n",
      "experiments also show that post-hoc compression (SVD), linear probe on random features, and\n",
      "sub-net style slimmable networks drastically lose accuracy compared to MRL as the representation\n",
      "size decreases. Finally, Figure 5 shows that, while MRL explicitly optimizes O(log(d)) nested\n",
      "representations – removing the O(d) dependence [73] –, the coarse-to-fine grained information is\n",
      "interpolated across all d dimensions providing highest flexibility for adaptive deployment.\n",
      "5\n",
      "12\n",
      "24\n",
      "48\n",
      "96\n",
      "192\n",
      "384\n",
      "768\n",
      "Representation \\n on top of the existing impact of\n",
      "representation learning. However, a study on the trade-off between representation size\n",
      "and the tendency to encode biases is an interesting future direction along the lines of\n",
      "existing literature [36, 37]. A part of this is already presented in Section 5.\n",
      "(d) Have you read the ethics review guidelines and ensured that your paper conforms to\n",
      "them? [Yes]\n",
      "2. If you are including theoretical results...\n",
      "(a) Did you state the full set of assumptions of all theoretical results? [N/A]\n",
      "(b) Did you include complete proofs of all theoretical results? [N/A]\n",
      "3. If you ran experiments...\n",
      "(a) Did you include the code, data, and instructions needed to reproduce the main ex-\n",
      "perimental results (either in the supplemental material or as a URL)? [Yes] See sup-\n",
      "plemental mater\\nat optimizing for granularities increasing in a non-logarithmic fashion would be sub-optimal\n",
      "both for maximum performance and expected efficiency; b) If we have m arbitrary granularities,\n",
      "the expected cost of the linear classifier to train MRL scales as O(L ∗(m2)) while logarithmic\n",
      "granularities result in O(L ∗2log(d)) space and compute costs.\n",
      "To demonstrate this effect, we learned Matryoshka Representations with uniform (MRL-Uniform)\n",
      "nesting dimensions m\n",
      "∈\n",
      "M\n",
      "=\n",
      "{8, 212, 416, 620, 824, 1028, 1232, 1436, 1640, 1844, 2048}.\n",
      "We\n",
      "evaluated\n",
      "this\n",
      "model\n",
      "at\n",
      "the\n",
      "standard\n",
      "(MRL-log)\n",
      "dimensions\n",
      "m\n",
      "∈\n",
      "M\n",
      "=\n",
      "{8, 16, 32, 64, 128, 256, 512, 1024, 2048} for ease of comparison to reported numbers using 1-NN ac-\n",
      "curacy (%). As shown in Table 29, we observed that while performance interpolated, MRL-Uniform\n",
      "suffered\\n, 32, 64, . . . , 2048}}. To improve reliability of threshold\n",
      "based greedy policy, we use test time augmentation which has been used successfully in the past [82].\n",
      "For inference, we used the remaining held-out 40K samples from the ImageNet-1K validation set. We\n",
      "began with smallest sized representation (m = 8) and compared the computed prediction confidence\n",
      "p8 to learned optimal threshold t∗\n",
      "8. If p8 ≤t∗\n",
      "8, then we increased m = 16, and repeated this\n",
      "procedure until m = d = 2048. To compute the expected dimensions, we performed early stopping\n",
      "at m = {16, 32, 64, . . . 2048} and computed the expectation using the distribution of representation\n",
      "sizes. As shown in Table 3 and Figure 6, we observed that in expectation, we only needed a ∼37\n",
      "sized representation to achieve 76.3% classification ac\\nfitting to experimental setups in recognition? arXiv preprint arXiv:2007.02519,\n",
      "2020.\n",
      "[93] M. Wallingford, H. Li, A. Achille, A. Ravichandran, C. Fowlkes, R. Bhotika, and S. Soatto.\n",
      "Task adaptive parameter sharing for multi-task learning. arXiv preprint arXiv:2203.16708,\n",
      "2022.\n",
      "[94] H. Wang, S. Ge, Z. Lipton, and E. P. Xing. Learning robust global representations by penalizing\n",
      "local predictive power. In Advances in Neural Information Processing Systems, pages 10506–\n",
      "10518, 2019.\n",
      "[95] X. Wang, D. Kondratyuk, K. M. Kitani, Y. Movshovitz-Attias, and E. Eban. Multiple networks\n",
      "are more efficient than one: Fast and accurate models via ensembles and cascades. arXiv\n",
      "preprint arXiv:2012.01988, 2020.\n",
      "[96] M. Wortsman, G. Ilharco, M. Li, J. W. Kim, H. Hajishirzi, A. Farhadi, H. Namkoong, and\n",
      "L. Schmi\\nTable 31. We observed that using a larger shortlist k saturated\n",
      "ImageNet-1K performance at k=200. But using larger shortlists until k = 2048, the maximum value\n",
      "33\n",
      "Table 26: Top-1 classification accuracy (%) on ImageNet-1K of various ResNet50 models which\n",
      "are finetuned on pretrained FF-2048 model. We observed that adding more non-linearities is able to\n",
      "induce nesting to a reasonable extent even if the model was not pretrained with nesting in mind.\n",
      "Rep. Size\n",
      "fc\n",
      "4.2 conv3,\n",
      "fc\n",
      "4.2 conv2,\n",
      "conv3, fc\n",
      "4.2 full,\n",
      "fc\n",
      "All (MRL)\n",
      "8\n",
      "5.15\n",
      "36.11\n",
      "54.78\n",
      "60.02\n",
      "66.63\n",
      "16\n",
      "13.79\n",
      "58.42\n",
      "67.26\n",
      "70.10\n",
      "73.53\n",
      "32\n",
      "32.52\n",
      "67.81\n",
      "71.62\n",
      "72.84\n",
      "75.03\n",
      "64\n",
      "52.66\n",
      "72.42\n",
      "73.61\n",
      "74.29\n",
      "75.82\n",
      "128\n",
      "64.60\n",
      "74.41\n",
      "74.67\n",
      "75.03\n",
      "76.30\n",
      "256\n",
      "69.29\n",
      "75.30\n",
      "75.23\n",
      "75.38\n",
      "76.47\n",
      "512\n",
      "70.51\n",
      "75.96\n",
      "75.47\n",
      "75.64\n",
      "76.65\n",
      "1024\n",
      "70.19\n",
      "76.18\n",
      "75.70\n",
      "75.75\n",
      "76.76\n",
      "2048\n",
      "69.72\n",
      "\\nion set. This policy is based on whether the\n",
      "prediction confidence pi using representation size mi exceeds a learned threshold t∗\n",
      "i . If pi ≥t∗\n",
      "i , we\n",
      "used predictions from representation size mi otherwise, we increased to representation size mi+1. To\n",
      "learn the optimal threshold t∗\n",
      "i , we performed a grid search between 0 and 1 (100 samples). For each\n",
      "threshold tk, we computed the classification accuracy over our 10K image subset. We set t∗\n",
      "i equal\n",
      "to the smallest threshold tk that gave the best accuracy. We use this procedure to obtain thresholds\n",
      "for successive models, i.e., {t∗\n",
      "j | j ∈{8, 16, 32, 64, . . . , 2048}}. To improve reliability of threshold\n",
      "based greedy policy, we use test time augmentation which has been used successfully in the past [82].\n",
      "For inference, we used the remaining\\nodel fine-tuning for text classification. arXiv\n",
      "preprint arXiv:1801.06146, 2018.\n",
      "[41] H. Hu, D. Dey, M. Hebert, and J. A. Bagnell. Learning anytime predictions in neural networks\n",
      "via adaptive loss balancing. In Proceedings of the AAAI Conference on Artificial Intelligence,\n",
      "volume 33, pages 3812–3821, 2019.\n",
      "[42] P. Indyk and R. Motwani. Approximate nearest neighbors: towards removing the curse\n",
      "of dimensionality. In Proceedings of the thirtieth annual ACM symposium on Theory of\n",
      "computing, pages 604–613, 1998.\n",
      "[43] H. Jain, V. Balasubramanian, B. Chunduri, and M. Varma. Slice: Scalable linear extreme\n",
      "classifiers trained on 100 million labels for related searches. In Proceedings of the Twelfth\n",
      "ACM International Conference on Web Search and Data Mining, pages 528–536, 2019.\n",
      "[44] S. Jayaram Subr\\nch\n",
      "using hierarchical navigable small world graphs. IEEE transactions on pattern analysis and\n",
      "machine intelligence, 42(4):824–836, 2018.\n",
      "[63] J. Masci, U. Meier, D. Cire¸san, and J. Schmidhuber. Stacked convolutional auto-encoders for\n",
      "hierarchical feature extraction. In International conference on artificial neural networks, pages\n",
      "52–59. Springer, 2011.\n",
      "[64] P. Mitra, C. Murthy, and S. K. Pal. Unsupervised feature selection using feature similarity.\n",
      "IEEE transactions on pattern analysis and machine intelligence, 24(3):301–312, 2002.\n",
      "[65] V. Nanda, T. Speicher, J. P. Dickerson, S. Feizi, K. P. Gummadi, and A. Weller. Diffused\n",
      "redundancy in pre-trained representations. arXiv preprint arXiv:2306.00183, 2023.\n",
      "[66] P. Nayak. Understanding searches better than ever before. Google AI Blog, 2019. \\nn artificial intelligence and statistics, pages 297–304. JMLR Workshop and Conference\n",
      "Proceedings, 2010.\n",
      "[28] M. G. Harris and C. D. Giachritsis. Coarse-grained information dominates fine-grained\n",
      "information in judgments of time-to-contact from retinal flow. Vision research, 40(6):601–611,\n",
      "2000.\n",
      "[29] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In\n",
      "Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770–\n",
      "778, 2016.\n",
      "[30] K. He, H. Fan, Y. Wu, S. Xie, and R. Girshick. Momentum contrast for unsupervised visual\n",
      "representation learning. In Proceedings of the IEEE/CVF conference on computer vision and\n",
      "pattern recognition, pages 9729–9738, 2020.\n",
      "[31] K. He, X. Chen, S. Xie, Y. Li, P. Dollár, and R. Girshick. Masked autoencoders\\ne distribution, without sacrificing accuracy on other classes (Table 16 in\n",
      "Appendix G). Additionally we find the accuracy between low-dimensional and high-dimensional\n",
      "representations is marginal for pretrain classes. We hypothesize that the higher-dimensional represen-\n",
      "tations are required to differentiate the classes when few training examples of each are known. This\n",
      "results provides further evidence that different tasks require varying capacity based on their difficulty.\n",
      "Disagreement across Dimensions.\n",
      "The information packing in Matryoshka Representations\n",
      "often results in gradual increase of accuracy with increase in capacity. However, we observed that\n",
      "8\n",
      "(a)\n",
      "(b)\n",
      "(c)\n",
      "Figure 9: Grad-CAM [80] progression of predictions in MRL model across 8, 16, 32 and 2048\n",
      "dimensions. (a) 8-dimensional rep\\nations of the ACM, 62(11):44–45, 2019.\n",
      "15\n",
      "[90] P. Viola and M. Jones. Rapid object detection using a boosted cascade of simple features. In\n",
      "Proceedings of the 2001 IEEE computer society conference on computer vision and pattern\n",
      "recognition. CVPR 2001, volume 1, pages I–I. Ieee, 2001.\n",
      "[91] C. Waldburger. As search needs evolve, microsoft makes ai tools for better search available\n",
      "to researchers and developers. Microsoft AI Blog, 2019. URL https://blogs.microsoft.\n",
      "com/ai/bing-vector-search/.\n",
      "[92] M. Wallingford, A. Kusupati, K. Alizadeh-Vahid, A. Walsman, A. Kembhavi, and A. Farhadi.\n",
      "Are we overfitting to experimental setups in recognition? arXiv preprint arXiv:2007.02519,\n",
      "2020.\n",
      "[93] M. Wallingford, H. Li, A. Achille, A. Ravichandran, C. Fowlkes, R. Bhotika, and S. Soatto.\n",
      "Task adaptive para\\nirst m dimensions of FF-2048 for NN lookup, and 2) FF+SVD: performing SVD\n",
      "on the FF-2048 representations at the specified representation size, 3) FF+JL: performing random\n",
      "projection according to the Johnson-Lindenstrauss lemma [48] on the FF-2048 representations at\n",
      "the specified representation size. We also compared against the 1-NN accuracy of slimmable neural\n",
      "nets [100] as an additional baseline. We observed these baseline models to perform very poorly at\n",
      "lower dimensions, as they were not explicitly trained to learn Matryoshka Representations.\n",
      "Table 2: 1-NN accuracy (%) on ImageNet-1K for various ResNet50 models.\n",
      "Rep. Size\n",
      "Rand. FS\n",
      "SVD\n",
      "JL\n",
      "FF\n",
      "Slimmable\n",
      "MRL\n",
      "MRL–E\n",
      "8\n",
      "2.36\n",
      "19.14\n",
      "0.11\n",
      "58.93\n",
      "1.00\n",
      "62.19\n",
      "57.45\n",
      "16\n",
      "12.06\n",
      "46.02\n",
      "0.09\n",
      "66.77\n",
      "5.12\n",
      "67.91\n",
      "67.05\n",
      "32\n",
      "32.91\n",
      "60.78\n",
      "0.06\n",
      "68.84\n",
      "16.95\n",
      "69.46\n",
      "68.6\n",
      "\\nrs.\n",
      "We also found that for both MRL and FF, as the shot number decreased, the required representa-\n",
      "tion size to reach optimal accuracy decreased (Table 15). For example, we observed that 1-shot\n",
      "performance at 32 representation size had equal accuracy to 2048 representation size.\n",
      "FLUID.\n",
      "For the long-tailed setting we evaluated MRL on the FLUID benchmark [92] which\n",
      "contains a mixture of pretrain and new classes. Table 16 shows the evaluation of the learned\n",
      "representation on FLUID. We observed that MRL provided up to 2% higher accuracy on novel\n",
      "classes in the tail of the distribution, without sacrificing accuracy on other classes. Additionally we\n",
      "found the accuracy between low-dimensional and high-dimensional representations was marginal for\n",
      "pretrain classes. For example, the 64-dimensional M\\nhoice learning for training diverse deep ensembles. Advances in Neural\n",
      "Information Processing Systems, 29, 2016.\n",
      "[59] C. Li, H. Farkhoor, R. Liu, and J. Yosinski. Measuring the intrinsic dimension of objective\n",
      "landscapes. arXiv preprint arXiv:1804.08838, 2018.\n",
      "[60] Y. Linde, A. Buzo, and R. Gray. An algorithm for vector quantizer design. IEEE Transactions\n",
      "on communications, 28(1):84–95, 1980.\n",
      "[61] I. Loshchilov and F. Hutter.\n",
      "Decoupled weight decay regularization.\n",
      "arXiv preprint\n",
      "arXiv:1711.05101, 2017.\n",
      "[62] Y. A. Malkov and D. A. Yashunin. Efficient and robust approximate nearest neighbor search\n",
      "using hierarchical navigable small world graphs. IEEE transactions on pattern analysis and\n",
      "machine intelligence, 42(4):824–836, 2018.\n",
      "[63] J. Masci, U. Meier, D. Cire¸san, and J. Schmidhuber. Stack\\n000-way classification layer of FF-2048,\n",
      "with rank = 1000.\n",
      "• Rand. LP: We compared against a linear classifier fit on randomly selected features [30].\n",
      "• Slim. Net: We take pretrained slimmable neural networks [100] which are trained with a flexible\n",
      "width backbone (25%, 50%, 75% and full width). For each representation size, we consider the\n",
      "first k dimensions for classification. Note that training of slimmable neural networks becomes\n",
      "unstable when trained below 25% width due to the hardness in optimization and low complexity of\n",
      "the model.\n",
      "At lower dimensions ( d ≤128), MRL outperforms all baselines significantly, which indicates that\n",
      "pretrained models lack the multifidelity of Matryoshka Representations and are incapable of fitting\n",
      "an accurate linear classifier at low representation sizes.\n",
      "\\n due to the inductive bias of gradient-based training [84], deep learning models tend to diffuse\n",
      "“information” across the entire representation vector. The desired elasticity is usually enabled in the\n",
      "existing flat and fixed representations either through training multiple low-dimensional models [29],\n",
      "jointly optimizing sub-networks of varying capacity [9, 100] or post-hoc compression [38, 60]. Each\n",
      "of these techniques struggle to meet the requirements for adaptive large-scale deployment either\n",
      "∗Equal contribution – AK led the project with extensive support from GB and AR for experimentation.\n",
      "36th Conference on Neural Information Processing Systems (NeurIPS 2022).\n",
      "arXiv:2205.13147v4  [cs.LG]  8 Feb 2024\n",
      "due to training/maintenance overhead, numerous expensive forward passes through all of \\n) utilization\n",
      "of the representation for downstream applications [50, 89]. Compute costs for the latter part of the\n",
      "pipeline scale with the embedding dimensionality as well as the data size (N) and label space (L).\n",
      "At web-scale [15, 85] this utilization cost overshadows the feature computation cost. The rigidity in\n",
      "these representations forces the use of high-dimensional embedding vectors across multiple tasks\n",
      "despite the varying resource and accuracy constraints that require flexibility.\n",
      "Human perception of the natural world has a naturally coarse-to-fine granularity [28, 32]. However,\n",
      "perhaps due to the inductive bias of gradient-based training [84], deep learning models tend to diffuse\n",
      "“information” across the entire representation vector. The desired elasticity is usually enabled in the\\nng, pages 1597–1607.\n",
      "PMLR, 2020.\n",
      "[13] Y. Chen, Z. Liu, H. Xu, T. Darrell, and X. Wang. Meta-baseline: exploring simple meta-\n",
      "learning for few-shot learning. In Proceedings of the IEEE/CVF International Conference on\n",
      "Computer Vision, pages 9062–9071, 2021.\n",
      "[14] M. Datar, N. Immorlica, P. Indyk, and V. S. Mirrokni. Locality-sensitive hashing scheme based\n",
      "on p-stable distributions. In Proceedings of the twentieth annual symposium on Computational\n",
      "geometry, pages 253–262, 2004.\n",
      "[15] J. Dean. Challenges in building large-scale information retrieval systems. In Keynote of the\n",
      "2nd ACM International Conference on Web Search and Data Mining (WSDM), volume 10,\n",
      "2009.\n",
      "[16] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. Imagenet: A large-scale\n",
      "hierarchical image database. In 2009 IEEE co\\nithin the same larger network. However, the weights for each progressively smaller\n",
      "network can be different and often require distinct forward passes to isolate the final representations.\n",
      "This is detrimental for adaptive inference due to the need for re-encoding the entire retrieval database\n",
      "with expensive sub-net forward passes of varying capacities. Several works [23, 26, 65, 59] investigate\n",
      "the notions of intrinsic dimensionality and redundancy of representations and objective spaces pointing\n",
      "to minimum description length [74]. Finally, ordered representations proposed by Rippel et al. [73]\n",
      "use nested dropout in the context of autoencoders to learn nested representations. MRL differentiates\n",
      "itself in formulation by optimizing only for O(log(d)) nesting dimensions instead of O(d). Despit\\ne high yet constant deep featurization costs or the search cost which\n",
      "scales with the size of the label space and data. Efficient neural networks address the first issue\n",
      "through a variety of algorithms [25, 54] and design choices [39, 53, 87]. However, with a strong\n",
      "featurizer, most of the issues with scale are due to the linear dependence on number of labels (L), size\n",
      "of the data (N) and representation size (d), stressing RAM, disk and processor all at the same time.\n",
      "The sub-linear complexity dependence on number of labels has been well studied in context of\n",
      "compute [3, 43, 69] and memory [20] using Approximate Nearest Neighbor Search (ANNS) [62] or\n",
      "leveraging the underlying hierarchy [17, 55]. In case of the representation size, often dimensionality\n",
      "reduction [77, 88], hashing techniques\\nion size for MRL &\n",
      "FF models showing the capture of underlying\n",
      "hierarchy through tight information bottlenecks.\n",
      "8\n",
      "16\n",
      "32\n",
      "64\n",
      "128\n",
      "256\n",
      "512\n",
      "1024\n",
      "2048\n",
      "Representation Size\n",
      "65\n",
      "70\n",
      "75\n",
      "80\n",
      "85\n",
      "90\n",
      "95\n",
      "Top-1 Accuracy (%)\n",
      "measuring device\n",
      "building\n",
      "garment\n",
      "tool\n",
      "nourishment\n",
      "protective covering\n",
      "vessel\n",
      "oscine\n",
      "Figure 11:\n",
      "Diverse per-superclass accuracy\n",
      "trends across representation sizes for ResNet50-\n",
      "MRL on ImageNet-1K.\n",
      "9\n",
      "occurs with both MRL and FF models; MRL is more accurate across dimensions. This shows that\n",
      "tight information bottlenecks while not highly accurate for fine-grained classification, do capture\n",
      "required semantic information for coarser classification that could be leveraged for adaptive routing\n",
      "for retrieval and classification. Mutifidelity of Matryoshka Representation naturally captures the\n",
      "und\\n\n",
      "403\n",
      "26.25\n",
      "49.32\n",
      "59.48\n",
      "14.15\n",
      "11.00\n",
      "9.15\n",
      "7.61\n",
      "20.55\n",
      "18.36\n",
      "16.78\n",
      "15.17\n",
      "192\n",
      "807\n",
      "27.94\n",
      "51.32\n",
      "61.32\n",
      "15.29\n",
      "11.89\n",
      "9.88\n",
      "8.18\n",
      "21.86\n",
      "19.46\n",
      "17.71\n",
      "15.96\n",
      "384\n",
      "1614\n",
      "29.03\n",
      "52.53\n",
      "62.45\n",
      "15.99\n",
      "12.46\n",
      "10.35\n",
      "8.56\n",
      "22.64\n",
      "20.14\n",
      "18.29\n",
      "16.47\n",
      "768\n",
      "3227\n",
      "29.87\n",
      "53.36\n",
      "63.13\n",
      "16.54\n",
      "12.90\n",
      "10.71\n",
      "8.85\n",
      "23.23\n",
      "20.67\n",
      "18.75\n",
      "16.85\n",
      "1536\n",
      "6454\n",
      "30.52\n",
      "54.02\n",
      "63.79\n",
      "16.99\n",
      "13.27\n",
      "11.01\n",
      "9.08\n",
      "23.73\n",
      "21.09\n",
      "19.12\n",
      "17.16\n",
      "large-scale (1000-way) setting. We evaluate for n ∈1, 3, 5, 7, 9 with 9 being the maximum value for\n",
      "n because there are 10 images per class.\n",
      "We observed that MRL had equal performance to FF across all representation sizes and shot numbers.\n",
      "We also found that for both MRL and FF, as the shot number decreased, the required representa-\n",
      "tion size to reach optimal accuracy decreased (Table 15). For example, we observed that 1-shot\n",
      "perfor\\nth a fraction of the MFLOPs.\n",
      "G\n",
      "Few-shot and Sample Efficiency\n",
      "We compared MRL, MRL–E, and FF on various benchmarks to observe the effect of representation\n",
      "size on sample efficiency. We used Nearest Class Means [79] for classification which has been shown\n",
      "to be effective in the few-shot regime [13].\n",
      "ImageNetV2.\n",
      "Representations are evaluated on ImageNetV2 with the n-shot k-way setup. Ima-\n",
      "geNetV2 is a dataset traditionally used to evaluate the robustness of models to natural distribution\n",
      "shifts. For our experiments we evaluate accuracy of the model given n examples from the Ima-\n",
      "geNetV2 distribution. We benchmark representations in the traditional small-scale (10-way) and\n",
      "25\n",
      "Table 9: Retrieve a shortlist of 200-NN with Ds sized representations on ImageNetV2 via exact\n",
      "search with L2 distance \\nBoden, A. Borchers, et al. In-datacenter performance analysis of a tensor processing unit.\n",
      "In Proceedings of the 44th annual international symposium on computer architecture, pages\n",
      "1–12, 2017.\n",
      "[50] T. C. Kaz Sato.\n",
      "Vertex ai matching engine.\n",
      "Microsoft AI Blog, 2021.\n",
      "URL\n",
      "https://cloud.google.com/blog/topics/developers-practitioners/\n",
      "find-anything-blazingly-fast-googles-vector-search-technology.\n",
      "[51] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional\n",
      "neural networks. Advances in neural information processing systems, 25, 2012.\n",
      "[52] B. Kulis, P. Jain, and K. Grauman. Fast similarity search for learned metrics. IEEE Transactions\n",
      "on Pattern Analysis and Machine Intelligence, 31(12):2143–2157, 2009.\n",
      "13\n",
      "[53] A. Kusupati, M. Singh, K. Bhatia, A. Kumar, P.\\nguage applications are built [40] on large language models [8] that are pretrained [68, 75]\n",
      "in a un/self-supervised fashion with masked language modelling [19] or autoregressive training [70].\n",
      "Matryoshka Representation Learning (MRL) is complementary to all these setups and can be\n",
      "adapted with minimal overhead (Section 3). MRL equips representations with multifidelity at no\n",
      "additional cost which enables adaptive deployment based on the data and task (Section 4).\n",
      "Efficient Classification and Retrieval.\n",
      "Efficiency in classification and retrieval during inference\n",
      "can be studied with respect to the high yet constant deep featurization costs or the search cost which\n",
      "scales with the size of the label space and data. Efficient neural networks address the first issue\n",
      "through a variety of algorithm\\ne, and L. Zettlemoyer.\n",
      "Deep contextualized word representations. In Proceedings of the 2018 Conference of the\n",
      "North American Chapter of the Association for Computational Linguistics: Human Language\n",
      "Technologies, Volume 1 (Long Papers), pages 2227–2237, New Orleans, Louisiana, June\n",
      "2018. Association for Computational Linguistics. doi: 10.18653/v1/N18-1202. URL https:\n",
      "//aclanthology.org/N18-1202.\n",
      "[69] Y. Prabhu, A. Kusupati, N. Gupta, and M. Varma. Extreme regression for dynamic search\n",
      "advertising. In Proceedings of the 13th International Conference on Web Search and Data\n",
      "Mining, pages 456–464, 2020.\n",
      "[70] A. Radford, K. Narasimhan, T. Salimans, and I. Sutskever. Improving language understand-\n",
      "ing by generative pre-training. OpenAI Blog, 2018. URL https://openai.com/blog/\n",
      "language-unsupervise\\nrmance of ResNet50 representations on ImageNet-1K across\n",
      "dimensionalities for MRL, MRL–E, FF, slimmable networks along with post-hoc compression\n",
      "of vectors using SVD and random feature selection. Matryoshka Representations are often the\n",
      "most accurate while being up to 3% better than the FF baselines. Similar to classification, post-hoc\n",
      "compression and slimmable network baselines suffer from significant drop-off in retrieval mAP@10\n",
      "with ≤256 dimensions. Appendix E discusses the mAP@10 of the same models on ImageNet-4K.\n",
      "MRL models are capable of performing accurate retrieval at various granularities without the\n",
      "additional expense of multiple model forward passes for the web-scale databases. FF models\n",
      "also generate independent databases which become prohibitively expense to store and switch i\\n36th Conference on Neural Information Processing Systems (NeurIPS 2022).\n",
      "arXiv:2205.13147v4  [cs.LG]  8 Feb 2024\n",
      "due to training/maintenance overhead, numerous expensive forward passes through all of the data,\n",
      "storage and memory cost for multiple copies of encoded data, expensive on-the-fly feature selection\n",
      "or a significant drop in accuracy. By encoding coarse-to-fine-grained representations, which are as\n",
      "accurate as the independently trained counterparts, we learn with minimal overhead a representation\n",
      "that can be deployed adaptively at no additional cost during inference.\n",
      "We introduce\n",
      "Matryoshka Representation Learning (MRL) to induce flexibility in the learned\n",
      "representation. MRL learns representations of varying capacities within the same high-dimensional\n",
      "vector through explicit optim\\n, and signif-\n",
      "icantly for lower ones. This demonstrates that training to learn Matryoshka Representations\n",
      "is feasible and extendable even for extremely large scale datasets.\n",
      "We also demonstrate that\n",
      "Matryoshka Representations are learned at interpolated dimensions for both ALIGN and JFT-\n",
      "ViT, as shown in Table 5, despite not being trained explicitly at these dimensions. Lastly, Table 6\n",
      "shows that MRL training leads to a increase in the cosine similarity span between positive and\n",
      "random image-text pairs.\n",
      "We also evaluated the capability of Matryoshka Representations to extend to other natural language\n",
      "processing via masked language modeling (MLM) with BERT [19], whose results are tabulated\n",
      "in Table 7. Without any hyper-parameter tuning, we observed Matryoshka Representations to be\n",
      "within 0.\\n are within 0.1% of the maximum value achievable without reranking on MRL representations,\n",
      "as seen in Table 10, are bolded.\n",
      "Shortlist Length = 200\n",
      "Ds\n",
      "Dr\n",
      "MFLOPs\n",
      "Top-1\n",
      "mAP@10\n",
      "mAP@25\n",
      "mAP@50\n",
      "mAP@100\n",
      "P@10\n",
      "P@25\n",
      "P@50\n",
      "P@100\n",
      "8\n",
      "16\n",
      "34\n",
      "16.84\n",
      "8.70\n",
      "6.88\n",
      "5.88\n",
      "5.08\n",
      "13.86\n",
      "12.80\n",
      "11.98\n",
      "11.10\n",
      "32\n",
      "20.73\n",
      "10.66\n",
      "8.19\n",
      "6.77\n",
      "5.61\n",
      "16.18\n",
      "14.39\n",
      "13.02\n",
      "11.61\n",
      "64\n",
      "23.11\n",
      "11.91\n",
      "9.03\n",
      "7.36\n",
      "6.00\n",
      "17.56\n",
      "15.34\n",
      "13.67\n",
      "11.99\n",
      "128\n",
      "24.63\n",
      "12.71\n",
      "9.59\n",
      "7.76\n",
      "6.25\n",
      "18.42\n",
      "15.94\n",
      "14.08\n",
      "12.22\n",
      "256\n",
      "25.5\n",
      "13.24\n",
      "9.96\n",
      "8.03\n",
      "6.42\n",
      "19.00\n",
      "16.35\n",
      "14.36\n",
      "12.37\n",
      "512\n",
      "26.07\n",
      "13.59\n",
      "10.21\n",
      "8.20\n",
      "6.53\n",
      "19.37\n",
      "16.62\n",
      "14.54\n",
      "12.46\n",
      "1024\n",
      "26.52\n",
      "13.85\n",
      "10.40\n",
      "8.34\n",
      "6.61\n",
      "19.65\n",
      "16.80\n",
      "14.68\n",
      "12.53\n",
      "2048\n",
      "26.94\n",
      "14.11\n",
      "10.57\n",
      "8.45\n",
      "6.68\n",
      "19.92\n",
      "16.98\n",
      "14.79\n",
      "12.58\n",
      "16\n",
      "32\n",
      "67\n",
      "21.44\n",
      "11.24\n",
      "8.72\n",
      "7.26\n",
      "6.02\n",
      "17.02\n",
      "15.30\n",
      "13.92\n",
      "12.41\n",
      "64\n",
      "24.36\n",
      "12.78\n",
      "9.75\n",
      "7.96\n",
      "6.43\n",
      "18.72\n",
      "16.41\n",
      "14.63\n",
      "12.74\n",
      "128\n",
      "26.08\n",
      "13.70\n",
      "10.39\n",
      "8.3\\nYang, Y. Xia, Y.-T. Chen, Z. Parekh, H. Pham, Q. Le, Y.-H. Sung, Z. Li, and T. Duerig.\n",
      "Scaling up visual and vision-language representation learning with noisy text supervision. In\n",
      "International Conference on Machine Learning, pages 4904–4916. PMLR, 2021.\n",
      "[47] J. Johnson, M. Douze, and H. Jégou. Billion-scale similarity search with GPUs. IEEE\n",
      "Transactions on Big Data, 7(3):535–547, 2019.\n",
      "[48] W. B. Johnson. Extensions of lipschitz mappings into a hilbert space. Contemp. Math., 26:\n",
      "189–206, 1984.\n",
      "[49] N. P. Jouppi, C. Young, N. Patil, D. Patterson, G. Agrawal, R. Bajwa, S. Bates, S. Bhatia,\n",
      "N. Boden, A. Borchers, et al. In-datacenter performance analysis of a tensor processing unit.\n",
      "In Proceedings of the 44th annual international symposium on computer architecture, pages\n",
      "1–12, 2017.\n",
      "[50] T.\\n, 2020.\n",
      "[55] A. Kusupati, M. Wallingford, V. Ramanujan, R. Somani, J. S. Park, K. Pillutla, P. Jain,\n",
      "S. Kakade, and A. Farhadi. Llc: Accurate, multi-purpose learnt low-dimensional binary codes.\n",
      "Advances in Neural Information Processing Systems, 34, 2021.\n",
      "[56] G. Leclerc, A. Ilyas, L. Engstrom, S. M. Park, H. Salman, and A. Madry. ffcv. https:\n",
      "//github.com/libffcv/ffcv/, 2022. commit 607d117.\n",
      "[57] Y. LeCun, Y. Bengio, and G. Hinton. Deep learning. nature, 521(7553):436–444, 2015.\n",
      "[58] S. Lee, S. Purushwalkam Shiva Prakash, M. Cogswell, V. Ranjan, D. Crandall, and D. Batra.\n",
      "Stochastic multiple choice learning for training diverse deep ensembles. Advances in Neural\n",
      "Information Processing Systems, 29, 2016.\n",
      "[59] C. Li, H. Farkhoor, R. Liu, and J. Yosinski. Measuring the intrinsic dimension of \\n16, 32, 64, 128, 256, 512, 1024, 2048} for ease of comparison to reported numbers using 1-NN ac-\n",
      "curacy (%). As shown in Table 29, we observed that while performance interpolated, MRL-Uniform\n",
      "suffered at low dimensions as the logarithmic spacing of MRL-log resulted in tighter packing of\n",
      "information in these initial dimensions. The higher nesting dimensions of MRL-Uniform did not\n",
      "help in significant accuracy improvement due to accuracy saturation, which is often logarithmic in\n",
      "representation size as shown by FF models. Note that the slight improvement at dimensions higher\n",
      "than 512 for MRL-Uniform is due to multiple granularities around them compared to just three for\n",
      "MRL-log, which are not useful in practice for efficiency.\n",
      "Lower Dimensionality.\n",
      "We experimented with training MRL with smalle\\nnts.\n",
      "Acknowledgments\n",
      "We are grateful to Srinadh Bhojanapalli, Lovish Madaan, Raghav Somani, Ludwig Schmidt, and\n",
      "Venkata Sailesh Sanampudi for helpful discussions and feedback. Aditya Kusupati also thanks Tom\n",
      "Duerig and Rahul Sukthankar for their support. Part of the paper’s large-scale experimentation is\n",
      "supported through a research GCP credit award from Google Cloud and Google Research. Gantavya\n",
      "Bhatt is supported in part by the CONIX Research Center, one of six centers in JUMP, a Semicon-\n",
      "ductor Research Corporation (SRC) program sponsored by DARPA. Sham Kakade acknowledges\n",
      "funding from the NSF award CCF-1703574 and ONR N00014-22-1-2377. Ali Farhadi acknowledges\n",
      "funding from the NSF awards IIS 1652052, IIS 17303166, DARPA N66001-19-2-4031, DARPA\n",
      "W911NF-15-1-0543 and gifts from Allen Inst\\nConference on Machine Learning, pages 5389–5400. PMLR,\n",
      "2019.\n",
      "[73] O. Rippel, M. Gelbart, and R. Adams. Learning ordered representations with nested dropout.\n",
      "In International Conference on Machine Learning, pages 1746–1754. PMLR, 2014.\n",
      "[74] J. Rissanen. Modeling by shortest data description. Automatica, 14(5):465–471, 1978.\n",
      "[75] S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf. Transfer learning in natural language\n",
      "processing. In Proceedings of the 2019 conference of the North American chapter of the\n",
      "association for computational linguistics: Tutorials, pages 15–18, 2019.\n",
      "[76] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy,\n",
      "A. Khosla, M. Bernstein, et al. Imagenet large scale visual recognition challenge. International\n",
      "journal of computer vision, 115\\nines significantly, which indicates that\n",
      "pretrained models lack the multifidelity of Matryoshka Representations and are incapable of fitting\n",
      "an accurate linear classifier at low representation sizes.\n",
      "We compared the performance of MRL models at various representation sizes via 1-nearest neighbors\n",
      "(1-NN) image classification accuracy on ImageNet-1K in Table 2 and Figure 3. We provide detailed\n",
      "information regarding the k-NN search pipeline in Appendix E. We compared against a baseline\n",
      "of attempting to enforce nesting to a FF-2048 model by 1) Random Feature Selection (Rand. FS):\n",
      "considering the first m dimensions of FF-2048 for NN lookup, and 2) FF+SVD: performing SVD\n",
      "on the FF-2048 representations at the specified representation size, 3) FF+JL: performing random\n",
      "projection according to the J\\n,\n",
      "(1)\n",
      "where L: RL × [L] →R+ is the multi-class softmax cross-entropy loss function. This is a standard\n",
      "optimization problem that can be solved using sub-gradient descent methods. We set all the impor-\n",
      "tance scales, cm = 1 for all m ∈M; see Section 5 for ablations. Lastly, despite only optimizing\n",
      "for O(log(d)) nested dimensions, MRL results in accurate representations, that interpolate, for\n",
      "dimensions that fall between the chosen granularity of the representations (Section 4.2).\n",
      "We call this formulation as Matryoshka Representation Learning (MRL). A natural way to make\n",
      "this efficient is through weight-tying across all the linear classifiers, i.e., by defining W(m) = W1:m\n",
      "for a set of common weights W ∈RL×d. This would reduce the memory cost due to the linear\n",
      "classifiers by almost half, whic\\nn such scenarios, we\n",
      "observed that smaller representation size models would often get confused due to other objects and fail\n",
      "to extract the object of interest which generated the correct label. We also observed a different nature\n",
      "31\n",
      "Figure 12: Progression of relative per-class accuracy vs MRL-2048. As the dimensionality increases,\n",
      "the spread shrinks while the class marked (x) (Madagascar cat) loses accuracy.\n",
      "Table 22: Percentage of ImageNet-1K validation set that is first correctly predicted using each\n",
      "representation size d. We note that 18.46% of the samples cannot be correctly predicted by any\n",
      "representation size. The remaining 81.54% constitutes the oracle accuracy.\n",
      "Rep. Size\n",
      "8\n",
      "16\n",
      "32\n",
      "64\n",
      "128\n",
      "256\n",
      "512\n",
      "1024\n",
      "2048\n",
      "Always\n",
      "Wrong\n",
      "Correctly\n",
      "Predicted\n",
      "67.46\n",
      "8.78\n",
      "2.58\n",
      "1.35\n",
      "0.64\n",
      "0.31\n",
      "0.20\n",
      "0.12\n",
      "0.06\n",
      "\\nreme\n",
      "classifiers trained on 100 million labels for related searches. In Proceedings of the Twelfth\n",
      "ACM International Conference on Web Search and Data Mining, pages 528–536, 2019.\n",
      "[44] S. Jayaram Subramanya, F. Devvrit, H. V. Simhadri, R. Krishnawamy, and R. Kadekodi.\n",
      "Diskann: Fast accurate billion-point nearest neighbor search on a single node. Advances in\n",
      "Neural Information Processing Systems, 32, 2019.\n",
      "[45] H. Jegou, M. Douze, and C. Schmid. Product quantization for nearest neighbor search. IEEE\n",
      "transactions on pattern analysis and machine intelligence, 33(1):117–128, 2010.\n",
      "[46] C. Jia, Y. Yang, Y. Xia, Y.-T. Chen, Z. Parekh, H. Pham, Q. Le, Y.-H. Sung, Z. Li, and T. Duerig.\n",
      "Scaling up visual and vision-language representation learning with noisy text supervision. In\n",
      "International Confe\\n results in Section 5.1 reveal interesting weaknesses of MRL that would be logical directions\n",
      "for future work. (1) Optimizing the weightings of the nested losses to obtain a Pareto optimal\n",
      "accuracy-vs-efficiency trade-off – a potential solution could emerge from adaptive loss balancing\n",
      "aspects of anytime neural networks [41]. (2) Using different losses at various fidelities aimed at\n",
      "solving a specific aspect of adaptive deployment – e.g. high recall for 8-dimension and robustness\n",
      "for 2048-dimension. (3) Learning a search data-structure, like differentiable k-d tree, on top of\n",
      "Matryoshka Representation to enable dataset and representation aware retrieval. (4) Finally, the\n",
      "joint optimization of multi-objective MRL combined with end-to-end learnable search data-structure\n",
      "to have data-driven a\\n Appendix C ablate over the choice of initial granularity and spacing of the\n",
      "granularites. Table 28 reaffirms the design choice to shun extremely low dimensions that have poor\n",
      "classification accuracy as initial granularity for MRL while Table 29 confirms the effectiveness of\n",
      "logarthmic granularity spacing inspired from the behaviour of accuracy saturation across dimensions\n",
      "over uniform. Lastly, Tables 30 and 31 in Appendix K.2 show that the retrieval performance saturates\n",
      "after a certain shortlist dimension and length depending on the complexity of the dataset.\n",
      "6\n",
      "Discussion and Conclusions\n",
      "The results in Section 5.1 reveal interesting weaknesses of MRL that would be logical directions\n",
      "for future work. (1) Optimizing the weightings of the nested losses to obtain a Pareto optimal\n",
      "accuracy-vs\\ncomputer vision,\n",
      "pages 843–852, 2017.\n",
      "[86] I. Sutskever, J. Martens, G. Dahl, and G. Hinton. On the importance of initialization and\n",
      "momentum in deep learning. In International conference on machine learning, pages 1139–\n",
      "1147. PMLR, 2013.\n",
      "[87] M. Tan and Q. Le. Efficientnet: Rethinking model scaling for convolutional neural networks.\n",
      "In International conference on machine learning, pages 6105–6114. PMLR, 2019.\n",
      "[88] L. Van Der Maaten, E. Postma, J. Van den Herik, et al. Dimensionality reduction: a comparative.\n",
      "J Mach Learn Res, 10(66-71):13, 2009.\n",
      "[89] M. Varma. Extreme classification. Communications of the ACM, 62(11):44–45, 2019.\n",
      "15\n",
      "[90] P. Viola and M. Jones. Rapid object detection using a boosted cascade of simple features. In\n",
      "Proceedings of the 2001 IEEE computer society conference on \\narning. In Proceedings of the IEEE/CVF conference on computer vision and\n",
      "pattern recognition, pages 9729–9738, 2020.\n",
      "[31] K. He, X. Chen, S. Xie, Y. Li, P. Dollár, and R. Girshick. Masked autoencoders are scalable\n",
      "vision learners. arXiv preprint arXiv:2111.06377, 2021.\n",
      "[32] J. Hegdé. Time course of visual perception: coarse-to-fine processing and beyond. Progress in\n",
      "neurobiology, 84(4):405–439, 2008.\n",
      "[33] D. Hendrycks and K. Gimpel. A baseline for detecting misclassified and out-of-distribution\n",
      "examples in neural networks. arXiv preprint arXiv:1610.02136, 2016.\n",
      "[34] D. Hendrycks, S. Basart, N. Mu, S. Kadavath, F. Wang, E. Dorundo, R. Desai, T. Zhu,\n",
      "S. Parajuli, M. Guo, et al. The many faces of robustness: A critical analysis of out-of-\n",
      "distribution generalization. In Proceedings of the IEE\\nand ALIGN data with models like ResNet and ViT making it extremely\n",
      "expensive to run things multiple times.\n",
      "(d) Did you include the total amount of compute and the type of resources used (e.g., type\n",
      "of GPUs, internal cluster, or cloud provider)? [Yes] See Appendix C and Appendix I.\n",
      "4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...\n",
      "(a) If your work uses existing assets, did you cite the creators? [Yes]\n",
      "(b) Did you mention the license of the assets? [No] All the non-proprietary datasets and\n",
      "code used are public under MIT, BSD or CC licenses.\n",
      "(c) Did you include any new assets either in the supplemental material or as a URL? [Yes]\n",
      "We created a new subset of ImageNet-21K for downstream evaluation of retrieval\n",
      "performance at scale. See Section 4.3\\nAppendix J put forward the potential for MRL\n",
      "to be a systematic framework for analyzing the utility and efficiency of information bottlenecks.\n",
      "Superclass Accuracy.\n",
      "As the information bottleneck becomes smaller, the overall accuracy on\n",
      "fine-grained classes decreases rapidly (Figure 3). However, the drop-off is not as significant when\n",
      "evaluated at a superclass level (Table 24 in Appendix J). Figure 10 presents that this phenomenon\n",
      "8\n",
      "16\n",
      "32\n",
      "64\n",
      "128\n",
      "256\n",
      "512\n",
      "1024\n",
      "2048\n",
      "Representation Size\n",
      "84\n",
      "86\n",
      "88\n",
      "90\n",
      "Top-1 Accuracy (%)\n",
      "MRL\n",
      "FF\n",
      "Figure 10: 31-way ImageNet-1K superclass clas-\n",
      "sification across representation size for MRL &\n",
      "FF models showing the capture of underlying\n",
      "hierarchy through tight information bottlenecks.\n",
      "8\n",
      "16\n",
      "32\n",
      "64\n",
      "128\n",
      "256\n",
      "512\n",
      "1024\n",
      "2048\n",
      "Representation Size\n",
      "65\n",
      "70\n",
      "75\n",
      "80\n",
      "85\n",
      "90\n",
      "95\n",
      "Top-1 Accuracy\\n\n"
     ]
    }
   ],
   "source": [
    "context_prompt = \"\"\n",
    "for (score, text) in context:\n",
    "    context_prompt += (text + \"\\\\n\")\n",
    "print(context_prompt)\n",
    "\n",
    "p_sys_ddic = pt.system_prompt(context_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Context information is below.\n",
      "---------------------\n",
      " Mu, S. Kadavath, F. Wang, E. Dorundo, R. Desai, T. Zhu,\n",
      "S. Parajuli, M. Guo, et al. The many faces of robustness: A critical analysis of out-of-\n",
      "distribution generalization. In Proceedings of the IEEE/CVF International Conference on\n",
      "Computer Vision, pages 8340–8349, 2021.\n",
      "12\n",
      "[35] D. Hendrycks, K. Zhao, S. Basart, J. Steinhardt, and D. Song. Natural adversarial examples.\n",
      "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,\n",
      "pages 15262–15271, 2021.\n",
      "[36] S. Hooker, A. Courville, G. Clark, Y. Dauphin, and A. Frome. What do compressed deep\n",
      "neural networks forget? arXiv preprint arXiv:1911.05248, 2019.\n",
      "[37] S. Hooker, N. Moorosi, G. Clark, S. Bengio, and E. Denton. Characterising bias in compressed\n",
      "models. arXiv preprint arXiv:2010.03058, 2020.\n",
      "[38] H. Hotelling\\nLab/robustness.\n",
      "[25] A. Gholami, S. Kim, Z. Dong, Z. Yao, M. W. Mahoney, and K. Keutzer. A survey of\n",
      "quantization methods for efficient neural network inference. arXiv preprint arXiv:2103.13630,\n",
      "2021.\n",
      "[26] S. Gong, V. N. Boddeti, and A. K. Jain. On the intrinsic dimensionality of image representations.\n",
      "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,\n",
      "pages 3987–3996, 2019.\n",
      "[27] M. Gutmann and A. Hyvärinen. Noise-contrastive estimation: A new estimation principle for\n",
      "unnormalized statistical models. In Proceedings of the thirteenth international conference\n",
      "on artificial intelligence and statistics, pages 297–304. JMLR Workshop and Conference\n",
      "Proceedings, 2010.\n",
      "[28] M. G. Harris and C. D. Giachritsis. Coarse-grained information dominates fine-grained\n",
      "info\\nMatryoshka Representation Learning\n",
      "Aditya Kusupati∗†⋄, Gantavya Bhatt∗†, Aniket Rege∗†,\n",
      "Matthew Wallingford†, Aditya Sinha⋄, Vivek Ramanujan†, William Howard-Snyder†,\n",
      "Kaifeng Chen⋄, Sham Kakade‡, Prateek Jain⋄and Ali Farhadi†\n",
      "†University of Washington, ⋄Google Research, ‡Harvard University\n",
      "{kusupati,ali}@cs.washington.edu, prajain@google.com\n",
      "Abstract\n",
      "Learned representations are a central component in modern ML systems, serv-\n",
      "ing a multitude of downstream tasks. When training such representations, it\n",
      "is often the case that computational and statistical constraints for each down-\n",
      "stream task are unknown. In this context, rigid fixed-capacity representations\n",
      "can be either over or under-accommodating to the task at hand. This leads us\n",
      "to ask: can we design a flexible representation that can ad\\n= {12, 24, 48, 96, 192, 384, 768} as\n",
      "the explicitly optimized nested dimensions respectively. Lastly, we extensively compare the MRL\n",
      "and MRL–E models to independently trained low-dimensional (fixed feature) representations (FF),\n",
      "dimensionality reduction (SVD), sub-net method (slimmable networks [100]) and randomly selected\n",
      "features of the highest capacity FF model.\n",
      "In section 4.2, we evaluate the quality and capacity of the learned representations through linear\n",
      "classification/probe (LP) and 1-nearest neighbour (1-NN) accuracy. Experiments show that MRL\n",
      "models remove the dependence on |M| resource-intensive independently trained models for the\n",
      "coarse-to-fine representations while being as accurate. Lastly, we show that despite optimizing only\n",
      "for |M| dimensions, MRL models diffuse the info\\n unknown. In this context, rigid fixed-capacity representations\n",
      "can be either over or under-accommodating to the task at hand. This leads us\n",
      "to ask: can we design a flexible representation that can adapt to multiple down-\n",
      "stream tasks with varying computational resources? Our main contribution is\n",
      "Matryoshka Representation Learning (MRL) which encodes information at\n",
      "different granularities and allows a single embedding to adapt to the computational\n",
      "constraints of downstream tasks. MRL minimally modifies existing representation\n",
      "learning pipelines and imposes no additional cost during inference and deployment.\n",
      "MRL learns coarse-to-fine representations that are at least as accurate and rich as\n",
      "independently trained low-dimensional representations. The flexibility within the\n",
      "learned Matryoshka \\nrXiv preprint arXiv:1911.05248, 2019.\n",
      "[37] S. Hooker, N. Moorosi, G. Clark, S. Bengio, and E. Denton. Characterising bias in compressed\n",
      "models. arXiv preprint arXiv:2010.03058, 2020.\n",
      "[38] H. Hotelling. Analysis of a complex of statistical variables into principal components. Journal\n",
      "of educational psychology, 24(6):417, 1933.\n",
      "[39] A. G. Howard, M. Zhu, B. Chen, D. Kalenichenko, W. Wang, T. Weyand, M. Andreetto, and\n",
      "H. Adam. Mobilenets: Efficient convolutional neural networks for mobile vision applications.\n",
      "arXiv preprint arXiv:1704.04861, 2017.\n",
      "[40] J. Howard and S. Ruder. Universal language model fine-tuning for text classification. arXiv\n",
      "preprint arXiv:1801.06146, 2018.\n",
      "[41] H. Hu, D. Dey, M. Hebert, and J. A. Bagnell. Learning anytime predictions in neural networks\n",
      "via adaptive loss bal\\nxperiments...\n",
      "(a) Did you include the code, data, and instructions needed to reproduce the main ex-\n",
      "perimental results (either in the supplemental material or as a URL)? [Yes] See sup-\n",
      "plemental material and Appendix A. All the code and public models will be open\n",
      "sourced.\n",
      "(b) Did you specify all the training details (e.g., data splits, hyperparameters, how they\n",
      "were chosen)? [Yes] See Section 4 and Appendix C.\n",
      "(c) Did you report error bars (e.g., with respect to the random seed after running experi-\n",
      "ments multiple times)? [No] We benchmarked on large-scale datasets like ImageNet-\n",
      "1K, JFT-300M and ALIGN data with models like ResNet and ViT making it extremely\n",
      "expensive to run things multiple times.\n",
      "(d) Did you include the total amount of compute and the type of resources used (e.g., type\n",
      "of\\nd K. Grauman. Fast similarity search for learned metrics. IEEE Transactions\n",
      "on Pattern Analysis and Machine Intelligence, 31(12):2143–2157, 2009.\n",
      "13\n",
      "[53] A. Kusupati, M. Singh, K. Bhatia, A. Kumar, P. Jain, and M. Varma. Fastgrnn: A fast, accurate,\n",
      "stable and tiny kilobyte sized gated recurrent neural network. Advances in Neural Information\n",
      "Processing Systems, 31, 2018.\n",
      "[54] A. Kusupati, V. Ramanujan, R. Somani, M. Wortsman, P. Jain, S. Kakade, and A. Farhadi.\n",
      "Soft threshold weight reparameterization for learnable sparsity. In International Conference\n",
      "on Machine Learning, pages 5544–5555. PMLR, 2020.\n",
      "[55] A. Kusupati, M. Wallingford, V. Ramanujan, R. Somani, J. S. Park, K. Pillutla, P. Jain,\n",
      "S. Kakade, and A. Farhadi. Llc: Accurate, multi-purpose learnt low-dimensional binary codes.\n",
      "Advanc\\nce of MRL model on 31-way classification (1 extra class is for reject token) on\n",
      "ImageNet-1K superclasses.\n",
      "Rep. Size\n",
      "8\n",
      "16\n",
      "32\n",
      "64\n",
      "128\n",
      "256\n",
      "512\n",
      "1024\n",
      "2048\n",
      "MRL\n",
      "85.57\n",
      "88.67\n",
      "89.48\n",
      "89.82\n",
      "89.97\n",
      "90.11\n",
      "90.18\n",
      "90.22\n",
      "90.21\n",
      "Matryoshka Representations at Arbitrary Granularities.\n",
      "To train MRL, we used nested di-\n",
      "mensions at logarithmic granularities M = {8, 16, . . . , 1024, 2048} as detailed in Section 3. We\n",
      "made this choice for two empirically-driven reasons: a) The accuracy improvement with increasing\n",
      "representation size was more logarithmic than linear (as shown by FF models in Figure 2). This indi-\n",
      "cated that optimizing for granularities increasing in a non-logarithmic fashion would be sub-optimal\n",
      "both for maximum performance and expected efficiency; b) If we have m arbitrary granularities,\n",
      "the expected\\nan one: Fast and accurate models via ensembles and cascades. arXiv\n",
      "preprint arXiv:2012.01988, 2020.\n",
      "[96] M. Wortsman, G. Ilharco, M. Li, J. W. Kim, H. Hajishirzi, A. Farhadi, H. Namkoong, and\n",
      "L. Schmidt. Robust fine-tuning of zero-shot models. arXiv preprint arXiv:2109.01903, 2021.\n",
      "[97] Z. Wu, Y. Xiong, S. Yu, and D. Lin. Unsupervised feature learning via non-parametric\n",
      "instance-level discrimination. arXiv preprint arXiv:1805.01978, 2018.\n",
      "[98] J. Yosinski, J. Clune, Y. Bengio, and H. Lipson. How transferable are features in deep neural\n",
      "networks? Advances in neural information processing systems, 27, 2014.\n",
      "[99] H.-F. Yu, K. Zhong, J. Zhang, W.-C. Chang, and I. S. Dhillon. Pecos: Prediction for enormous\n",
      "and correlated output spaces. Journal of Machine Learning Research, 23(98):1–32, 2022.\n",
      "[1\\n\n",
      "These experiments show that MRL seamlessly scales to large-scale models and web-scale datasets\n",
      "while providing the otherwise prohibitively expensive multi-granularity in the process. We also\n",
      "have similar observations when pretraining BERT; please see Appendix D.2 for more details. Our\n",
      "experiments also show that post-hoc compression (SVD), linear probe on random features, and\n",
      "sub-net style slimmable networks drastically lose accuracy compared to MRL as the representation\n",
      "size decreases. Finally, Figure 5 shows that, while MRL explicitly optimizes O(log(d)) nested\n",
      "representations – removing the O(d) dependence [73] –, the coarse-to-fine grained information is\n",
      "interpolated across all d dimensions providing highest flexibility for adaptive deployment.\n",
      "5\n",
      "12\n",
      "24\n",
      "48\n",
      "96\n",
      "192\n",
      "384\n",
      "768\n",
      "Representation \\n on top of the existing impact of\n",
      "representation learning. However, a study on the trade-off between representation size\n",
      "and the tendency to encode biases is an interesting future direction along the lines of\n",
      "existing literature [36, 37]. A part of this is already presented in Section 5.\n",
      "(d) Have you read the ethics review guidelines and ensured that your paper conforms to\n",
      "them? [Yes]\n",
      "2. If you are including theoretical results...\n",
      "(a) Did you state the full set of assumptions of all theoretical results? [N/A]\n",
      "(b) Did you include complete proofs of all theoretical results? [N/A]\n",
      "3. If you ran experiments...\n",
      "(a) Did you include the code, data, and instructions needed to reproduce the main ex-\n",
      "perimental results (either in the supplemental material or as a URL)? [Yes] See sup-\n",
      "plemental mater\\nat optimizing for granularities increasing in a non-logarithmic fashion would be sub-optimal\n",
      "both for maximum performance and expected efficiency; b) If we have m arbitrary granularities,\n",
      "the expected cost of the linear classifier to train MRL scales as O(L ∗(m2)) while logarithmic\n",
      "granularities result in O(L ∗2log(d)) space and compute costs.\n",
      "To demonstrate this effect, we learned Matryoshka Representations with uniform (MRL-Uniform)\n",
      "nesting dimensions m\n",
      "∈\n",
      "M\n",
      "=\n",
      "{8, 212, 416, 620, 824, 1028, 1232, 1436, 1640, 1844, 2048}.\n",
      "We\n",
      "evaluated\n",
      "this\n",
      "model\n",
      "at\n",
      "the\n",
      "standard\n",
      "(MRL-log)\n",
      "dimensions\n",
      "m\n",
      "∈\n",
      "M\n",
      "=\n",
      "{8, 16, 32, 64, 128, 256, 512, 1024, 2048} for ease of comparison to reported numbers using 1-NN ac-\n",
      "curacy (%). As shown in Table 29, we observed that while performance interpolated, MRL-Uniform\n",
      "suffered\\n, 32, 64, . . . , 2048}}. To improve reliability of threshold\n",
      "based greedy policy, we use test time augmentation which has been used successfully in the past [82].\n",
      "For inference, we used the remaining held-out 40K samples from the ImageNet-1K validation set. We\n",
      "began with smallest sized representation (m = 8) and compared the computed prediction confidence\n",
      "p8 to learned optimal threshold t∗\n",
      "8. If p8 ≤t∗\n",
      "8, then we increased m = 16, and repeated this\n",
      "procedure until m = d = 2048. To compute the expected dimensions, we performed early stopping\n",
      "at m = {16, 32, 64, . . . 2048} and computed the expectation using the distribution of representation\n",
      "sizes. As shown in Table 3 and Figure 6, we observed that in expectation, we only needed a ∼37\n",
      "sized representation to achieve 76.3% classification ac\\nfitting to experimental setups in recognition? arXiv preprint arXiv:2007.02519,\n",
      "2020.\n",
      "[93] M. Wallingford, H. Li, A. Achille, A. Ravichandran, C. Fowlkes, R. Bhotika, and S. Soatto.\n",
      "Task adaptive parameter sharing for multi-task learning. arXiv preprint arXiv:2203.16708,\n",
      "2022.\n",
      "[94] H. Wang, S. Ge, Z. Lipton, and E. P. Xing. Learning robust global representations by penalizing\n",
      "local predictive power. In Advances in Neural Information Processing Systems, pages 10506–\n",
      "10518, 2019.\n",
      "[95] X. Wang, D. Kondratyuk, K. M. Kitani, Y. Movshovitz-Attias, and E. Eban. Multiple networks\n",
      "are more efficient than one: Fast and accurate models via ensembles and cascades. arXiv\n",
      "preprint arXiv:2012.01988, 2020.\n",
      "[96] M. Wortsman, G. Ilharco, M. Li, J. W. Kim, H. Hajishirzi, A. Farhadi, H. Namkoong, and\n",
      "L. Schmi\\nTable 31. We observed that using a larger shortlist k saturated\n",
      "ImageNet-1K performance at k=200. But using larger shortlists until k = 2048, the maximum value\n",
      "33\n",
      "Table 26: Top-1 classification accuracy (%) on ImageNet-1K of various ResNet50 models which\n",
      "are finetuned on pretrained FF-2048 model. We observed that adding more non-linearities is able to\n",
      "induce nesting to a reasonable extent even if the model was not pretrained with nesting in mind.\n",
      "Rep. Size\n",
      "fc\n",
      "4.2 conv3,\n",
      "fc\n",
      "4.2 conv2,\n",
      "conv3, fc\n",
      "4.2 full,\n",
      "fc\n",
      "All (MRL)\n",
      "8\n",
      "5.15\n",
      "36.11\n",
      "54.78\n",
      "60.02\n",
      "66.63\n",
      "16\n",
      "13.79\n",
      "58.42\n",
      "67.26\n",
      "70.10\n",
      "73.53\n",
      "32\n",
      "32.52\n",
      "67.81\n",
      "71.62\n",
      "72.84\n",
      "75.03\n",
      "64\n",
      "52.66\n",
      "72.42\n",
      "73.61\n",
      "74.29\n",
      "75.82\n",
      "128\n",
      "64.60\n",
      "74.41\n",
      "74.67\n",
      "75.03\n",
      "76.30\n",
      "256\n",
      "69.29\n",
      "75.30\n",
      "75.23\n",
      "75.38\n",
      "76.47\n",
      "512\n",
      "70.51\n",
      "75.96\n",
      "75.47\n",
      "75.64\n",
      "76.65\n",
      "1024\n",
      "70.19\n",
      "76.18\n",
      "75.70\n",
      "75.75\n",
      "76.76\n",
      "2048\n",
      "69.72\n",
      "\\nion set. This policy is based on whether the\n",
      "prediction confidence pi using representation size mi exceeds a learned threshold t∗\n",
      "i . If pi ≥t∗\n",
      "i , we\n",
      "used predictions from representation size mi otherwise, we increased to representation size mi+1. To\n",
      "learn the optimal threshold t∗\n",
      "i , we performed a grid search between 0 and 1 (100 samples). For each\n",
      "threshold tk, we computed the classification accuracy over our 10K image subset. We set t∗\n",
      "i equal\n",
      "to the smallest threshold tk that gave the best accuracy. We use this procedure to obtain thresholds\n",
      "for successive models, i.e., {t∗\n",
      "j | j ∈{8, 16, 32, 64, . . . , 2048}}. To improve reliability of threshold\n",
      "based greedy policy, we use test time augmentation which has been used successfully in the past [82].\n",
      "For inference, we used the remaining\\nodel fine-tuning for text classification. arXiv\n",
      "preprint arXiv:1801.06146, 2018.\n",
      "[41] H. Hu, D. Dey, M. Hebert, and J. A. Bagnell. Learning anytime predictions in neural networks\n",
      "via adaptive loss balancing. In Proceedings of the AAAI Conference on Artificial Intelligence,\n",
      "volume 33, pages 3812–3821, 2019.\n",
      "[42] P. Indyk and R. Motwani. Approximate nearest neighbors: towards removing the curse\n",
      "of dimensionality. In Proceedings of the thirtieth annual ACM symposium on Theory of\n",
      "computing, pages 604–613, 1998.\n",
      "[43] H. Jain, V. Balasubramanian, B. Chunduri, and M. Varma. Slice: Scalable linear extreme\n",
      "classifiers trained on 100 million labels for related searches. In Proceedings of the Twelfth\n",
      "ACM International Conference on Web Search and Data Mining, pages 528–536, 2019.\n",
      "[44] S. Jayaram Subr\\nch\n",
      "using hierarchical navigable small world graphs. IEEE transactions on pattern analysis and\n",
      "machine intelligence, 42(4):824–836, 2018.\n",
      "[63] J. Masci, U. Meier, D. Cire¸san, and J. Schmidhuber. Stacked convolutional auto-encoders for\n",
      "hierarchical feature extraction. In International conference on artificial neural networks, pages\n",
      "52–59. Springer, 2011.\n",
      "[64] P. Mitra, C. Murthy, and S. K. Pal. Unsupervised feature selection using feature similarity.\n",
      "IEEE transactions on pattern analysis and machine intelligence, 24(3):301–312, 2002.\n",
      "[65] V. Nanda, T. Speicher, J. P. Dickerson, S. Feizi, K. P. Gummadi, and A. Weller. Diffused\n",
      "redundancy in pre-trained representations. arXiv preprint arXiv:2306.00183, 2023.\n",
      "[66] P. Nayak. Understanding searches better than ever before. Google AI Blog, 2019. \\nn artificial intelligence and statistics, pages 297–304. JMLR Workshop and Conference\n",
      "Proceedings, 2010.\n",
      "[28] M. G. Harris and C. D. Giachritsis. Coarse-grained information dominates fine-grained\n",
      "information in judgments of time-to-contact from retinal flow. Vision research, 40(6):601–611,\n",
      "2000.\n",
      "[29] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In\n",
      "Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770–\n",
      "778, 2016.\n",
      "[30] K. He, H. Fan, Y. Wu, S. Xie, and R. Girshick. Momentum contrast for unsupervised visual\n",
      "representation learning. In Proceedings of the IEEE/CVF conference on computer vision and\n",
      "pattern recognition, pages 9729–9738, 2020.\n",
      "[31] K. He, X. Chen, S. Xie, Y. Li, P. Dollár, and R. Girshick. Masked autoencoders\\ne distribution, without sacrificing accuracy on other classes (Table 16 in\n",
      "Appendix G). Additionally we find the accuracy between low-dimensional and high-dimensional\n",
      "representations is marginal for pretrain classes. We hypothesize that the higher-dimensional represen-\n",
      "tations are required to differentiate the classes when few training examples of each are known. This\n",
      "results provides further evidence that different tasks require varying capacity based on their difficulty.\n",
      "Disagreement across Dimensions.\n",
      "The information packing in Matryoshka Representations\n",
      "often results in gradual increase of accuracy with increase in capacity. However, we observed that\n",
      "8\n",
      "(a)\n",
      "(b)\n",
      "(c)\n",
      "Figure 9: Grad-CAM [80] progression of predictions in MRL model across 8, 16, 32 and 2048\n",
      "dimensions. (a) 8-dimensional rep\\nations of the ACM, 62(11):44–45, 2019.\n",
      "15\n",
      "[90] P. Viola and M. Jones. Rapid object detection using a boosted cascade of simple features. In\n",
      "Proceedings of the 2001 IEEE computer society conference on computer vision and pattern\n",
      "recognition. CVPR 2001, volume 1, pages I–I. Ieee, 2001.\n",
      "[91] C. Waldburger. As search needs evolve, microsoft makes ai tools for better search available\n",
      "to researchers and developers. Microsoft AI Blog, 2019. URL https://blogs.microsoft.\n",
      "com/ai/bing-vector-search/.\n",
      "[92] M. Wallingford, A. Kusupati, K. Alizadeh-Vahid, A. Walsman, A. Kembhavi, and A. Farhadi.\n",
      "Are we overfitting to experimental setups in recognition? arXiv preprint arXiv:2007.02519,\n",
      "2020.\n",
      "[93] M. Wallingford, H. Li, A. Achille, A. Ravichandran, C. Fowlkes, R. Bhotika, and S. Soatto.\n",
      "Task adaptive para\\nirst m dimensions of FF-2048 for NN lookup, and 2) FF+SVD: performing SVD\n",
      "on the FF-2048 representations at the specified representation size, 3) FF+JL: performing random\n",
      "projection according to the Johnson-Lindenstrauss lemma [48] on the FF-2048 representations at\n",
      "the specified representation size. We also compared against the 1-NN accuracy of slimmable neural\n",
      "nets [100] as an additional baseline. We observed these baseline models to perform very poorly at\n",
      "lower dimensions, as they were not explicitly trained to learn Matryoshka Representations.\n",
      "Table 2: 1-NN accuracy (%) on ImageNet-1K for various ResNet50 models.\n",
      "Rep. Size\n",
      "Rand. FS\n",
      "SVD\n",
      "JL\n",
      "FF\n",
      "Slimmable\n",
      "MRL\n",
      "MRL–E\n",
      "8\n",
      "2.36\n",
      "19.14\n",
      "0.11\n",
      "58.93\n",
      "1.00\n",
      "62.19\n",
      "57.45\n",
      "16\n",
      "12.06\n",
      "46.02\n",
      "0.09\n",
      "66.77\n",
      "5.12\n",
      "67.91\n",
      "67.05\n",
      "32\n",
      "32.91\n",
      "60.78\n",
      "0.06\n",
      "68.84\n",
      "16.95\n",
      "69.46\n",
      "68.6\n",
      "\\nrs.\n",
      "We also found that for both MRL and FF, as the shot number decreased, the required representa-\n",
      "tion size to reach optimal accuracy decreased (Table 15). For example, we observed that 1-shot\n",
      "performance at 32 representation size had equal accuracy to 2048 representation size.\n",
      "FLUID.\n",
      "For the long-tailed setting we evaluated MRL on the FLUID benchmark [92] which\n",
      "contains a mixture of pretrain and new classes. Table 16 shows the evaluation of the learned\n",
      "representation on FLUID. We observed that MRL provided up to 2% higher accuracy on novel\n",
      "classes in the tail of the distribution, without sacrificing accuracy on other classes. Additionally we\n",
      "found the accuracy between low-dimensional and high-dimensional representations was marginal for\n",
      "pretrain classes. For example, the 64-dimensional M\\nhoice learning for training diverse deep ensembles. Advances in Neural\n",
      "Information Processing Systems, 29, 2016.\n",
      "[59] C. Li, H. Farkhoor, R. Liu, and J. Yosinski. Measuring the intrinsic dimension of objective\n",
      "landscapes. arXiv preprint arXiv:1804.08838, 2018.\n",
      "[60] Y. Linde, A. Buzo, and R. Gray. An algorithm for vector quantizer design. IEEE Transactions\n",
      "on communications, 28(1):84–95, 1980.\n",
      "[61] I. Loshchilov and F. Hutter.\n",
      "Decoupled weight decay regularization.\n",
      "arXiv preprint\n",
      "arXiv:1711.05101, 2017.\n",
      "[62] Y. A. Malkov and D. A. Yashunin. Efficient and robust approximate nearest neighbor search\n",
      "using hierarchical navigable small world graphs. IEEE transactions on pattern analysis and\n",
      "machine intelligence, 42(4):824–836, 2018.\n",
      "[63] J. Masci, U. Meier, D. Cire¸san, and J. Schmidhuber. Stack\\n000-way classification layer of FF-2048,\n",
      "with rank = 1000.\n",
      "• Rand. LP: We compared against a linear classifier fit on randomly selected features [30].\n",
      "• Slim. Net: We take pretrained slimmable neural networks [100] which are trained with a flexible\n",
      "width backbone (25%, 50%, 75% and full width). For each representation size, we consider the\n",
      "first k dimensions for classification. Note that training of slimmable neural networks becomes\n",
      "unstable when trained below 25% width due to the hardness in optimization and low complexity of\n",
      "the model.\n",
      "At lower dimensions ( d ≤128), MRL outperforms all baselines significantly, which indicates that\n",
      "pretrained models lack the multifidelity of Matryoshka Representations and are incapable of fitting\n",
      "an accurate linear classifier at low representation sizes.\n",
      "\\n due to the inductive bias of gradient-based training [84], deep learning models tend to diffuse\n",
      "“information” across the entire representation vector. The desired elasticity is usually enabled in the\n",
      "existing flat and fixed representations either through training multiple low-dimensional models [29],\n",
      "jointly optimizing sub-networks of varying capacity [9, 100] or post-hoc compression [38, 60]. Each\n",
      "of these techniques struggle to meet the requirements for adaptive large-scale deployment either\n",
      "∗Equal contribution – AK led the project with extensive support from GB and AR for experimentation.\n",
      "36th Conference on Neural Information Processing Systems (NeurIPS 2022).\n",
      "arXiv:2205.13147v4  [cs.LG]  8 Feb 2024\n",
      "due to training/maintenance overhead, numerous expensive forward passes through all of \\n) utilization\n",
      "of the representation for downstream applications [50, 89]. Compute costs for the latter part of the\n",
      "pipeline scale with the embedding dimensionality as well as the data size (N) and label space (L).\n",
      "At web-scale [15, 85] this utilization cost overshadows the feature computation cost. The rigidity in\n",
      "these representations forces the use of high-dimensional embedding vectors across multiple tasks\n",
      "despite the varying resource and accuracy constraints that require flexibility.\n",
      "Human perception of the natural world has a naturally coarse-to-fine granularity [28, 32]. However,\n",
      "perhaps due to the inductive bias of gradient-based training [84], deep learning models tend to diffuse\n",
      "“information” across the entire representation vector. The desired elasticity is usually enabled in the\\nng, pages 1597–1607.\n",
      "PMLR, 2020.\n",
      "[13] Y. Chen, Z. Liu, H. Xu, T. Darrell, and X. Wang. Meta-baseline: exploring simple meta-\n",
      "learning for few-shot learning. In Proceedings of the IEEE/CVF International Conference on\n",
      "Computer Vision, pages 9062–9071, 2021.\n",
      "[14] M. Datar, N. Immorlica, P. Indyk, and V. S. Mirrokni. Locality-sensitive hashing scheme based\n",
      "on p-stable distributions. In Proceedings of the twentieth annual symposium on Computational\n",
      "geometry, pages 253–262, 2004.\n",
      "[15] J. Dean. Challenges in building large-scale information retrieval systems. In Keynote of the\n",
      "2nd ACM International Conference on Web Search and Data Mining (WSDM), volume 10,\n",
      "2009.\n",
      "[16] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. Imagenet: A large-scale\n",
      "hierarchical image database. In 2009 IEEE co\\nithin the same larger network. However, the weights for each progressively smaller\n",
      "network can be different and often require distinct forward passes to isolate the final representations.\n",
      "This is detrimental for adaptive inference due to the need for re-encoding the entire retrieval database\n",
      "with expensive sub-net forward passes of varying capacities. Several works [23, 26, 65, 59] investigate\n",
      "the notions of intrinsic dimensionality and redundancy of representations and objective spaces pointing\n",
      "to minimum description length [74]. Finally, ordered representations proposed by Rippel et al. [73]\n",
      "use nested dropout in the context of autoencoders to learn nested representations. MRL differentiates\n",
      "itself in formulation by optimizing only for O(log(d)) nesting dimensions instead of O(d). Despit\\ne high yet constant deep featurization costs or the search cost which\n",
      "scales with the size of the label space and data. Efficient neural networks address the first issue\n",
      "through a variety of algorithms [25, 54] and design choices [39, 53, 87]. However, with a strong\n",
      "featurizer, most of the issues with scale are due to the linear dependence on number of labels (L), size\n",
      "of the data (N) and representation size (d), stressing RAM, disk and processor all at the same time.\n",
      "The sub-linear complexity dependence on number of labels has been well studied in context of\n",
      "compute [3, 43, 69] and memory [20] using Approximate Nearest Neighbor Search (ANNS) [62] or\n",
      "leveraging the underlying hierarchy [17, 55]. In case of the representation size, often dimensionality\n",
      "reduction [77, 88], hashing techniques\\nion size for MRL &\n",
      "FF models showing the capture of underlying\n",
      "hierarchy through tight information bottlenecks.\n",
      "8\n",
      "16\n",
      "32\n",
      "64\n",
      "128\n",
      "256\n",
      "512\n",
      "1024\n",
      "2048\n",
      "Representation Size\n",
      "65\n",
      "70\n",
      "75\n",
      "80\n",
      "85\n",
      "90\n",
      "95\n",
      "Top-1 Accuracy (%)\n",
      "measuring device\n",
      "building\n",
      "garment\n",
      "tool\n",
      "nourishment\n",
      "protective covering\n",
      "vessel\n",
      "oscine\n",
      "Figure 11:\n",
      "Diverse per-superclass accuracy\n",
      "trends across representation sizes for ResNet50-\n",
      "MRL on ImageNet-1K.\n",
      "9\n",
      "occurs with both MRL and FF models; MRL is more accurate across dimensions. This shows that\n",
      "tight information bottlenecks while not highly accurate for fine-grained classification, do capture\n",
      "required semantic information for coarser classification that could be leveraged for adaptive routing\n",
      "for retrieval and classification. Mutifidelity of Matryoshka Representation naturally captures the\n",
      "und\\n\n",
      "403\n",
      "26.25\n",
      "49.32\n",
      "59.48\n",
      "14.15\n",
      "11.00\n",
      "9.15\n",
      "7.61\n",
      "20.55\n",
      "18.36\n",
      "16.78\n",
      "15.17\n",
      "192\n",
      "807\n",
      "27.94\n",
      "51.32\n",
      "61.32\n",
      "15.29\n",
      "11.89\n",
      "9.88\n",
      "8.18\n",
      "21.86\n",
      "19.46\n",
      "17.71\n",
      "15.96\n",
      "384\n",
      "1614\n",
      "29.03\n",
      "52.53\n",
      "62.45\n",
      "15.99\n",
      "12.46\n",
      "10.35\n",
      "8.56\n",
      "22.64\n",
      "20.14\n",
      "18.29\n",
      "16.47\n",
      "768\n",
      "3227\n",
      "29.87\n",
      "53.36\n",
      "63.13\n",
      "16.54\n",
      "12.90\n",
      "10.71\n",
      "8.85\n",
      "23.23\n",
      "20.67\n",
      "18.75\n",
      "16.85\n",
      "1536\n",
      "6454\n",
      "30.52\n",
      "54.02\n",
      "63.79\n",
      "16.99\n",
      "13.27\n",
      "11.01\n",
      "9.08\n",
      "23.73\n",
      "21.09\n",
      "19.12\n",
      "17.16\n",
      "large-scale (1000-way) setting. We evaluate for n ∈1, 3, 5, 7, 9 with 9 being the maximum value for\n",
      "n because there are 10 images per class.\n",
      "We observed that MRL had equal performance to FF across all representation sizes and shot numbers.\n",
      "We also found that for both MRL and FF, as the shot number decreased, the required representa-\n",
      "tion size to reach optimal accuracy decreased (Table 15). For example, we observed that 1-shot\n",
      "perfor\\nth a fraction of the MFLOPs.\n",
      "G\n",
      "Few-shot and Sample Efficiency\n",
      "We compared MRL, MRL–E, and FF on various benchmarks to observe the effect of representation\n",
      "size on sample efficiency. We used Nearest Class Means [79] for classification which has been shown\n",
      "to be effective in the few-shot regime [13].\n",
      "ImageNetV2.\n",
      "Representations are evaluated on ImageNetV2 with the n-shot k-way setup. Ima-\n",
      "geNetV2 is a dataset traditionally used to evaluate the robustness of models to natural distribution\n",
      "shifts. For our experiments we evaluate accuracy of the model given n examples from the Ima-\n",
      "geNetV2 distribution. We benchmark representations in the traditional small-scale (10-way) and\n",
      "25\n",
      "Table 9: Retrieve a shortlist of 200-NN with Ds sized representations on ImageNetV2 via exact\n",
      "search with L2 distance \\nBoden, A. Borchers, et al. In-datacenter performance analysis of a tensor processing unit.\n",
      "In Proceedings of the 44th annual international symposium on computer architecture, pages\n",
      "1–12, 2017.\n",
      "[50] T. C. Kaz Sato.\n",
      "Vertex ai matching engine.\n",
      "Microsoft AI Blog, 2021.\n",
      "URL\n",
      "https://cloud.google.com/blog/topics/developers-practitioners/\n",
      "find-anything-blazingly-fast-googles-vector-search-technology.\n",
      "[51] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional\n",
      "neural networks. Advances in neural information processing systems, 25, 2012.\n",
      "[52] B. Kulis, P. Jain, and K. Grauman. Fast similarity search for learned metrics. IEEE Transactions\n",
      "on Pattern Analysis and Machine Intelligence, 31(12):2143–2157, 2009.\n",
      "13\n",
      "[53] A. Kusupati, M. Singh, K. Bhatia, A. Kumar, P.\\nguage applications are built [40] on large language models [8] that are pretrained [68, 75]\n",
      "in a un/self-supervised fashion with masked language modelling [19] or autoregressive training [70].\n",
      "Matryoshka Representation Learning (MRL) is complementary to all these setups and can be\n",
      "adapted with minimal overhead (Section 3). MRL equips representations with multifidelity at no\n",
      "additional cost which enables adaptive deployment based on the data and task (Section 4).\n",
      "Efficient Classification and Retrieval.\n",
      "Efficiency in classification and retrieval during inference\n",
      "can be studied with respect to the high yet constant deep featurization costs or the search cost which\n",
      "scales with the size of the label space and data. Efficient neural networks address the first issue\n",
      "through a variety of algorithm\\ne, and L. Zettlemoyer.\n",
      "Deep contextualized word representations. In Proceedings of the 2018 Conference of the\n",
      "North American Chapter of the Association for Computational Linguistics: Human Language\n",
      "Technologies, Volume 1 (Long Papers), pages 2227–2237, New Orleans, Louisiana, June\n",
      "2018. Association for Computational Linguistics. doi: 10.18653/v1/N18-1202. URL https:\n",
      "//aclanthology.org/N18-1202.\n",
      "[69] Y. Prabhu, A. Kusupati, N. Gupta, and M. Varma. Extreme regression for dynamic search\n",
      "advertising. In Proceedings of the 13th International Conference on Web Search and Data\n",
      "Mining, pages 456–464, 2020.\n",
      "[70] A. Radford, K. Narasimhan, T. Salimans, and I. Sutskever. Improving language understand-\n",
      "ing by generative pre-training. OpenAI Blog, 2018. URL https://openai.com/blog/\n",
      "language-unsupervise\\nrmance of ResNet50 representations on ImageNet-1K across\n",
      "dimensionalities for MRL, MRL–E, FF, slimmable networks along with post-hoc compression\n",
      "of vectors using SVD and random feature selection. Matryoshka Representations are often the\n",
      "most accurate while being up to 3% better than the FF baselines. Similar to classification, post-hoc\n",
      "compression and slimmable network baselines suffer from significant drop-off in retrieval mAP@10\n",
      "with ≤256 dimensions. Appendix E discusses the mAP@10 of the same models on ImageNet-4K.\n",
      "MRL models are capable of performing accurate retrieval at various granularities without the\n",
      "additional expense of multiple model forward passes for the web-scale databases. FF models\n",
      "also generate independent databases which become prohibitively expense to store and switch i\\n36th Conference on Neural Information Processing Systems (NeurIPS 2022).\n",
      "arXiv:2205.13147v4  [cs.LG]  8 Feb 2024\n",
      "due to training/maintenance overhead, numerous expensive forward passes through all of the data,\n",
      "storage and memory cost for multiple copies of encoded data, expensive on-the-fly feature selection\n",
      "or a significant drop in accuracy. By encoding coarse-to-fine-grained representations, which are as\n",
      "accurate as the independently trained counterparts, we learn with minimal overhead a representation\n",
      "that can be deployed adaptively at no additional cost during inference.\n",
      "We introduce\n",
      "Matryoshka Representation Learning (MRL) to induce flexibility in the learned\n",
      "representation. MRL learns representations of varying capacities within the same high-dimensional\n",
      "vector through explicit optim\\n, and signif-\n",
      "icantly for lower ones. This demonstrates that training to learn Matryoshka Representations\n",
      "is feasible and extendable even for extremely large scale datasets.\n",
      "We also demonstrate that\n",
      "Matryoshka Representations are learned at interpolated dimensions for both ALIGN and JFT-\n",
      "ViT, as shown in Table 5, despite not being trained explicitly at these dimensions. Lastly, Table 6\n",
      "shows that MRL training leads to a increase in the cosine similarity span between positive and\n",
      "random image-text pairs.\n",
      "We also evaluated the capability of Matryoshka Representations to extend to other natural language\n",
      "processing via masked language modeling (MLM) with BERT [19], whose results are tabulated\n",
      "in Table 7. Without any hyper-parameter tuning, we observed Matryoshka Representations to be\n",
      "within 0.\\n are within 0.1% of the maximum value achievable without reranking on MRL representations,\n",
      "as seen in Table 10, are bolded.\n",
      "Shortlist Length = 200\n",
      "Ds\n",
      "Dr\n",
      "MFLOPs\n",
      "Top-1\n",
      "mAP@10\n",
      "mAP@25\n",
      "mAP@50\n",
      "mAP@100\n",
      "P@10\n",
      "P@25\n",
      "P@50\n",
      "P@100\n",
      "8\n",
      "16\n",
      "34\n",
      "16.84\n",
      "8.70\n",
      "6.88\n",
      "5.88\n",
      "5.08\n",
      "13.86\n",
      "12.80\n",
      "11.98\n",
      "11.10\n",
      "32\n",
      "20.73\n",
      "10.66\n",
      "8.19\n",
      "6.77\n",
      "5.61\n",
      "16.18\n",
      "14.39\n",
      "13.02\n",
      "11.61\n",
      "64\n",
      "23.11\n",
      "11.91\n",
      "9.03\n",
      "7.36\n",
      "6.00\n",
      "17.56\n",
      "15.34\n",
      "13.67\n",
      "11.99\n",
      "128\n",
      "24.63\n",
      "12.71\n",
      "9.59\n",
      "7.76\n",
      "6.25\n",
      "18.42\n",
      "15.94\n",
      "14.08\n",
      "12.22\n",
      "256\n",
      "25.5\n",
      "13.24\n",
      "9.96\n",
      "8.03\n",
      "6.42\n",
      "19.00\n",
      "16.35\n",
      "14.36\n",
      "12.37\n",
      "512\n",
      "26.07\n",
      "13.59\n",
      "10.21\n",
      "8.20\n",
      "6.53\n",
      "19.37\n",
      "16.62\n",
      "14.54\n",
      "12.46\n",
      "1024\n",
      "26.52\n",
      "13.85\n",
      "10.40\n",
      "8.34\n",
      "6.61\n",
      "19.65\n",
      "16.80\n",
      "14.68\n",
      "12.53\n",
      "2048\n",
      "26.94\n",
      "14.11\n",
      "10.57\n",
      "8.45\n",
      "6.68\n",
      "19.92\n",
      "16.98\n",
      "14.79\n",
      "12.58\n",
      "16\n",
      "32\n",
      "67\n",
      "21.44\n",
      "11.24\n",
      "8.72\n",
      "7.26\n",
      "6.02\n",
      "17.02\n",
      "15.30\n",
      "13.92\n",
      "12.41\n",
      "64\n",
      "24.36\n",
      "12.78\n",
      "9.75\n",
      "7.96\n",
      "6.43\n",
      "18.72\n",
      "16.41\n",
      "14.63\n",
      "12.74\n",
      "128\n",
      "26.08\n",
      "13.70\n",
      "10.39\n",
      "8.3\\nYang, Y. Xia, Y.-T. Chen, Z. Parekh, H. Pham, Q. Le, Y.-H. Sung, Z. Li, and T. Duerig.\n",
      "Scaling up visual and vision-language representation learning with noisy text supervision. In\n",
      "International Conference on Machine Learning, pages 4904–4916. PMLR, 2021.\n",
      "[47] J. Johnson, M. Douze, and H. Jégou. Billion-scale similarity search with GPUs. IEEE\n",
      "Transactions on Big Data, 7(3):535–547, 2019.\n",
      "[48] W. B. Johnson. Extensions of lipschitz mappings into a hilbert space. Contemp. Math., 26:\n",
      "189–206, 1984.\n",
      "[49] N. P. Jouppi, C. Young, N. Patil, D. Patterson, G. Agrawal, R. Bajwa, S. Bates, S. Bhatia,\n",
      "N. Boden, A. Borchers, et al. In-datacenter performance analysis of a tensor processing unit.\n",
      "In Proceedings of the 44th annual international symposium on computer architecture, pages\n",
      "1–12, 2017.\n",
      "[50] T.\\n, 2020.\n",
      "[55] A. Kusupati, M. Wallingford, V. Ramanujan, R. Somani, J. S. Park, K. Pillutla, P. Jain,\n",
      "S. Kakade, and A. Farhadi. Llc: Accurate, multi-purpose learnt low-dimensional binary codes.\n",
      "Advances in Neural Information Processing Systems, 34, 2021.\n",
      "[56] G. Leclerc, A. Ilyas, L. Engstrom, S. M. Park, H. Salman, and A. Madry. ffcv. https:\n",
      "//github.com/libffcv/ffcv/, 2022. commit 607d117.\n",
      "[57] Y. LeCun, Y. Bengio, and G. Hinton. Deep learning. nature, 521(7553):436–444, 2015.\n",
      "[58] S. Lee, S. Purushwalkam Shiva Prakash, M. Cogswell, V. Ranjan, D. Crandall, and D. Batra.\n",
      "Stochastic multiple choice learning for training diverse deep ensembles. Advances in Neural\n",
      "Information Processing Systems, 29, 2016.\n",
      "[59] C. Li, H. Farkhoor, R. Liu, and J. Yosinski. Measuring the intrinsic dimension of \\n16, 32, 64, 128, 256, 512, 1024, 2048} for ease of comparison to reported numbers using 1-NN ac-\n",
      "curacy (%). As shown in Table 29, we observed that while performance interpolated, MRL-Uniform\n",
      "suffered at low dimensions as the logarithmic spacing of MRL-log resulted in tighter packing of\n",
      "information in these initial dimensions. The higher nesting dimensions of MRL-Uniform did not\n",
      "help in significant accuracy improvement due to accuracy saturation, which is often logarithmic in\n",
      "representation size as shown by FF models. Note that the slight improvement at dimensions higher\n",
      "than 512 for MRL-Uniform is due to multiple granularities around them compared to just three for\n",
      "MRL-log, which are not useful in practice for efficiency.\n",
      "Lower Dimensionality.\n",
      "We experimented with training MRL with smalle\\nnts.\n",
      "Acknowledgments\n",
      "We are grateful to Srinadh Bhojanapalli, Lovish Madaan, Raghav Somani, Ludwig Schmidt, and\n",
      "Venkata Sailesh Sanampudi for helpful discussions and feedback. Aditya Kusupati also thanks Tom\n",
      "Duerig and Rahul Sukthankar for their support. Part of the paper’s large-scale experimentation is\n",
      "supported through a research GCP credit award from Google Cloud and Google Research. Gantavya\n",
      "Bhatt is supported in part by the CONIX Research Center, one of six centers in JUMP, a Semicon-\n",
      "ductor Research Corporation (SRC) program sponsored by DARPA. Sham Kakade acknowledges\n",
      "funding from the NSF award CCF-1703574 and ONR N00014-22-1-2377. Ali Farhadi acknowledges\n",
      "funding from the NSF awards IIS 1652052, IIS 17303166, DARPA N66001-19-2-4031, DARPA\n",
      "W911NF-15-1-0543 and gifts from Allen Inst\\nConference on Machine Learning, pages 5389–5400. PMLR,\n",
      "2019.\n",
      "[73] O. Rippel, M. Gelbart, and R. Adams. Learning ordered representations with nested dropout.\n",
      "In International Conference on Machine Learning, pages 1746–1754. PMLR, 2014.\n",
      "[74] J. Rissanen. Modeling by shortest data description. Automatica, 14(5):465–471, 1978.\n",
      "[75] S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf. Transfer learning in natural language\n",
      "processing. In Proceedings of the 2019 conference of the North American chapter of the\n",
      "association for computational linguistics: Tutorials, pages 15–18, 2019.\n",
      "[76] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy,\n",
      "A. Khosla, M. Bernstein, et al. Imagenet large scale visual recognition challenge. International\n",
      "journal of computer vision, 115\\nines significantly, which indicates that\n",
      "pretrained models lack the multifidelity of Matryoshka Representations and are incapable of fitting\n",
      "an accurate linear classifier at low representation sizes.\n",
      "We compared the performance of MRL models at various representation sizes via 1-nearest neighbors\n",
      "(1-NN) image classification accuracy on ImageNet-1K in Table 2 and Figure 3. We provide detailed\n",
      "information regarding the k-NN search pipeline in Appendix E. We compared against a baseline\n",
      "of attempting to enforce nesting to a FF-2048 model by 1) Random Feature Selection (Rand. FS):\n",
      "considering the first m dimensions of FF-2048 for NN lookup, and 2) FF+SVD: performing SVD\n",
      "on the FF-2048 representations at the specified representation size, 3) FF+JL: performing random\n",
      "projection according to the J\\n,\n",
      "(1)\n",
      "where L: RL × [L] →R+ is the multi-class softmax cross-entropy loss function. This is a standard\n",
      "optimization problem that can be solved using sub-gradient descent methods. We set all the impor-\n",
      "tance scales, cm = 1 for all m ∈M; see Section 5 for ablations. Lastly, despite only optimizing\n",
      "for O(log(d)) nested dimensions, MRL results in accurate representations, that interpolate, for\n",
      "dimensions that fall between the chosen granularity of the representations (Section 4.2).\n",
      "We call this formulation as Matryoshka Representation Learning (MRL). A natural way to make\n",
      "this efficient is through weight-tying across all the linear classifiers, i.e., by defining W(m) = W1:m\n",
      "for a set of common weights W ∈RL×d. This would reduce the memory cost due to the linear\n",
      "classifiers by almost half, whic\\nn such scenarios, we\n",
      "observed that smaller representation size models would often get confused due to other objects and fail\n",
      "to extract the object of interest which generated the correct label. We also observed a different nature\n",
      "31\n",
      "Figure 12: Progression of relative per-class accuracy vs MRL-2048. As the dimensionality increases,\n",
      "the spread shrinks while the class marked (x) (Madagascar cat) loses accuracy.\n",
      "Table 22: Percentage of ImageNet-1K validation set that is first correctly predicted using each\n",
      "representation size d. We note that 18.46% of the samples cannot be correctly predicted by any\n",
      "representation size. The remaining 81.54% constitutes the oracle accuracy.\n",
      "Rep. Size\n",
      "8\n",
      "16\n",
      "32\n",
      "64\n",
      "128\n",
      "256\n",
      "512\n",
      "1024\n",
      "2048\n",
      "Always\n",
      "Wrong\n",
      "Correctly\n",
      "Predicted\n",
      "67.46\n",
      "8.78\n",
      "2.58\n",
      "1.35\n",
      "0.64\n",
      "0.31\n",
      "0.20\n",
      "0.12\n",
      "0.06\n",
      "\\nreme\n",
      "classifiers trained on 100 million labels for related searches. In Proceedings of the Twelfth\n",
      "ACM International Conference on Web Search and Data Mining, pages 528–536, 2019.\n",
      "[44] S. Jayaram Subramanya, F. Devvrit, H. V. Simhadri, R. Krishnawamy, and R. Kadekodi.\n",
      "Diskann: Fast accurate billion-point nearest neighbor search on a single node. Advances in\n",
      "Neural Information Processing Systems, 32, 2019.\n",
      "[45] H. Jegou, M. Douze, and C. Schmid. Product quantization for nearest neighbor search. IEEE\n",
      "transactions on pattern analysis and machine intelligence, 33(1):117–128, 2010.\n",
      "[46] C. Jia, Y. Yang, Y. Xia, Y.-T. Chen, Z. Parekh, H. Pham, Q. Le, Y.-H. Sung, Z. Li, and T. Duerig.\n",
      "Scaling up visual and vision-language representation learning with noisy text supervision. In\n",
      "International Confe\\n results in Section 5.1 reveal interesting weaknesses of MRL that would be logical directions\n",
      "for future work. (1) Optimizing the weightings of the nested losses to obtain a Pareto optimal\n",
      "accuracy-vs-efficiency trade-off – a potential solution could emerge from adaptive loss balancing\n",
      "aspects of anytime neural networks [41]. (2) Using different losses at various fidelities aimed at\n",
      "solving a specific aspect of adaptive deployment – e.g. high recall for 8-dimension and robustness\n",
      "for 2048-dimension. (3) Learning a search data-structure, like differentiable k-d tree, on top of\n",
      "Matryoshka Representation to enable dataset and representation aware retrieval. (4) Finally, the\n",
      "joint optimization of multi-objective MRL combined with end-to-end learnable search data-structure\n",
      "to have data-driven a\\n Appendix C ablate over the choice of initial granularity and spacing of the\n",
      "granularites. Table 28 reaffirms the design choice to shun extremely low dimensions that have poor\n",
      "classification accuracy as initial granularity for MRL while Table 29 confirms the effectiveness of\n",
      "logarthmic granularity spacing inspired from the behaviour of accuracy saturation across dimensions\n",
      "over uniform. Lastly, Tables 30 and 31 in Appendix K.2 show that the retrieval performance saturates\n",
      "after a certain shortlist dimension and length depending on the complexity of the dataset.\n",
      "6\n",
      "Discussion and Conclusions\n",
      "The results in Section 5.1 reveal interesting weaknesses of MRL that would be logical directions\n",
      "for future work. (1) Optimizing the weightings of the nested losses to obtain a Pareto optimal\n",
      "accuracy-vs\\ncomputer vision,\n",
      "pages 843–852, 2017.\n",
      "[86] I. Sutskever, J. Martens, G. Dahl, and G. Hinton. On the importance of initialization and\n",
      "momentum in deep learning. In International conference on machine learning, pages 1139–\n",
      "1147. PMLR, 2013.\n",
      "[87] M. Tan and Q. Le. Efficientnet: Rethinking model scaling for convolutional neural networks.\n",
      "In International conference on machine learning, pages 6105–6114. PMLR, 2019.\n",
      "[88] L. Van Der Maaten, E. Postma, J. Van den Herik, et al. Dimensionality reduction: a comparative.\n",
      "J Mach Learn Res, 10(66-71):13, 2009.\n",
      "[89] M. Varma. Extreme classification. Communications of the ACM, 62(11):44–45, 2019.\n",
      "15\n",
      "[90] P. Viola and M. Jones. Rapid object detection using a boosted cascade of simple features. In\n",
      "Proceedings of the 2001 IEEE computer society conference on \\narning. In Proceedings of the IEEE/CVF conference on computer vision and\n",
      "pattern recognition, pages 9729–9738, 2020.\n",
      "[31] K. He, X. Chen, S. Xie, Y. Li, P. Dollár, and R. Girshick. Masked autoencoders are scalable\n",
      "vision learners. arXiv preprint arXiv:2111.06377, 2021.\n",
      "[32] J. Hegdé. Time course of visual perception: coarse-to-fine processing and beyond. Progress in\n",
      "neurobiology, 84(4):405–439, 2008.\n",
      "[33] D. Hendrycks and K. Gimpel. A baseline for detecting misclassified and out-of-distribution\n",
      "examples in neural networks. arXiv preprint arXiv:1610.02136, 2016.\n",
      "[34] D. Hendrycks, S. Basart, N. Mu, S. Kadavath, F. Wang, E. Dorundo, R. Desai, T. Zhu,\n",
      "S. Parajuli, M. Guo, et al. The many faces of robustness: A critical analysis of out-of-\n",
      "distribution generalization. In Proceedings of the IEE\\nand ALIGN data with models like ResNet and ViT making it extremely\n",
      "expensive to run things multiple times.\n",
      "(d) Did you include the total amount of compute and the type of resources used (e.g., type\n",
      "of GPUs, internal cluster, or cloud provider)? [Yes] See Appendix C and Appendix I.\n",
      "4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...\n",
      "(a) If your work uses existing assets, did you cite the creators? [Yes]\n",
      "(b) Did you mention the license of the assets? [No] All the non-proprietary datasets and\n",
      "code used are public under MIT, BSD or CC licenses.\n",
      "(c) Did you include any new assets either in the supplemental material or as a URL? [Yes]\n",
      "We created a new subset of ImageNet-21K for downstream evaluation of retrieval\n",
      "performance at scale. See Section 4.3\\nAppendix J put forward the potential for MRL\n",
      "to be a systematic framework for analyzing the utility and efficiency of information bottlenecks.\n",
      "Superclass Accuracy.\n",
      "As the information bottleneck becomes smaller, the overall accuracy on\n",
      "fine-grained classes decreases rapidly (Figure 3). However, the drop-off is not as significant when\n",
      "evaluated at a superclass level (Table 24 in Appendix J). Figure 10 presents that this phenomenon\n",
      "8\n",
      "16\n",
      "32\n",
      "64\n",
      "128\n",
      "256\n",
      "512\n",
      "1024\n",
      "2048\n",
      "Representation Size\n",
      "84\n",
      "86\n",
      "88\n",
      "90\n",
      "Top-1 Accuracy (%)\n",
      "MRL\n",
      "FF\n",
      "Figure 10: 31-way ImageNet-1K superclass clas-\n",
      "sification across representation size for MRL &\n",
      "FF models showing the capture of underlying\n",
      "hierarchy through tight information bottlenecks.\n",
      "8\n",
      "16\n",
      "32\n",
      "64\n",
      "128\n",
      "256\n",
      "512\n",
      "1024\n",
      "2048\n",
      "Representation Size\n",
      "65\n",
      "70\n",
      "75\n",
      "80\n",
      "85\n",
      "90\n",
      "95\n",
      "Top-1 Accuracy\\n\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "If you do not find the answer in the context information, then say exactly \"Ich weiss es nicht\" and nothing else.\n",
      "If the context is not related to the question, then say exactly: \"Dazu habe ich keine Information\" and nothing else:\n",
      "Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view the full sy prompt comntent\n",
    "print(p_sys_ddic['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_user_ddic = pt.user_prompt(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Query: \n",
      "Are there computational and statistical constraints?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view the full sy prompt comntent\n",
    "print(p_user_ddic['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': ' Context information is below.\\n---------------------\\n Mu, S. Kadavath, F. Wang, E. Dorundo, R. Desai, T. Zhu,\\nS. Parajuli, M. Guo, et al. The many faces of robustness: A critical analysis of out-of-\\ndistribution generalization. In Proceedings of the IEEE/CVF International Conference on\\nComputer Vision, pages 8340–8349, 2021.\\n12\\n[35] D. Hendrycks, K. Zhao, S. Basart, J. Steinhardt, and D. Song. Natural adversarial examples.\\nIn Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,\\npages 15262–15271, 2021.\\n[36] S. Hooker, A. Courville, G. Clark, Y. Dauphin, and A. Frome. What do compressed deep\\nneural networks forget? arXiv preprint arXiv:1911.05248, 2019.\\n[37] S. Hooker, N. Moorosi, G. Clark, S. Bengio, and E. Denton. Characterising bias in compressed\\nmodels. arXiv preprint arXiv:2010.03058, 2020.\\n[38] H. Hotelling\\\\nLab/robustness.\\n[25] A. Gholami, S. Kim, Z. Dong, Z. Yao, M. W. Mahoney, and K. Keutzer. A survey of\\nquantization methods for efficient neural network inference. arXiv preprint arXiv:2103.13630,\\n2021.\\n[26] S. Gong, V. N. Boddeti, and A. K. Jain. On the intrinsic dimensionality of image representations.\\nIn Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,\\npages 3987–3996, 2019.\\n[27] M. Gutmann and A. Hyvärinen. Noise-contrastive estimation: A new estimation principle for\\nunnormalized statistical models. In Proceedings of the thirteenth international conference\\non artificial intelligence and statistics, pages 297–304. JMLR Workshop and Conference\\nProceedings, 2010.\\n[28] M. G. Harris and C. D. Giachritsis. Coarse-grained information dominates fine-grained\\ninfo\\\\nMatryoshka Representation Learning\\nAditya Kusupati∗†⋄, Gantavya Bhatt∗†, Aniket Rege∗†,\\nMatthew Wallingford†, Aditya Sinha⋄, Vivek Ramanujan†, William Howard-Snyder†,\\nKaifeng Chen⋄, Sham Kakade‡, Prateek Jain⋄and Ali Farhadi†\\n†University of Washington, ⋄Google Research, ‡Harvard University\\n{kusupati,ali}@cs.washington.edu, prajain@google.com\\nAbstract\\nLearned representations are a central component in modern ML systems, serv-\\ning a multitude of downstream tasks. When training such representations, it\\nis often the case that computational and statistical constraints for each down-\\nstream task are unknown. In this context, rigid fixed-capacity representations\\ncan be either over or under-accommodating to the task at hand. This leads us\\nto ask: can we design a flexible representation that can ad\\\\n= {12, 24, 48, 96, 192, 384, 768} as\\nthe explicitly optimized nested dimensions respectively. Lastly, we extensively compare the MRL\\nand MRL–E models to independently trained low-dimensional (fixed feature) representations (FF),\\ndimensionality reduction (SVD), sub-net method (slimmable networks [100]) and randomly selected\\nfeatures of the highest capacity FF model.\\nIn section 4.2, we evaluate the quality and capacity of the learned representations through linear\\nclassification/probe (LP) and 1-nearest neighbour (1-NN) accuracy. Experiments show that MRL\\nmodels remove the dependence on |M| resource-intensive independently trained models for the\\ncoarse-to-fine representations while being as accurate. Lastly, we show that despite optimizing only\\nfor |M| dimensions, MRL models diffuse the info\\\\n unknown. In this context, rigid fixed-capacity representations\\ncan be either over or under-accommodating to the task at hand. This leads us\\nto ask: can we design a flexible representation that can adapt to multiple down-\\nstream tasks with varying computational resources? Our main contribution is\\nMatryoshka Representation Learning (MRL) which encodes information at\\ndifferent granularities and allows a single embedding to adapt to the computational\\nconstraints of downstream tasks. MRL minimally modifies existing representation\\nlearning pipelines and imposes no additional cost during inference and deployment.\\nMRL learns coarse-to-fine representations that are at least as accurate and rich as\\nindependently trained low-dimensional representations. The flexibility within the\\nlearned Matryoshka \\\\nrXiv preprint arXiv:1911.05248, 2019.\\n[37] S. Hooker, N. Moorosi, G. Clark, S. Bengio, and E. Denton. Characterising bias in compressed\\nmodels. arXiv preprint arXiv:2010.03058, 2020.\\n[38] H. Hotelling. Analysis of a complex of statistical variables into principal components. Journal\\nof educational psychology, 24(6):417, 1933.\\n[39] A. G. Howard, M. Zhu, B. Chen, D. Kalenichenko, W. Wang, T. Weyand, M. Andreetto, and\\nH. Adam. Mobilenets: Efficient convolutional neural networks for mobile vision applications.\\narXiv preprint arXiv:1704.04861, 2017.\\n[40] J. Howard and S. Ruder. Universal language model fine-tuning for text classification. arXiv\\npreprint arXiv:1801.06146, 2018.\\n[41] H. Hu, D. Dey, M. Hebert, and J. A. Bagnell. Learning anytime predictions in neural networks\\nvia adaptive loss bal\\\\nxperiments...\\n(a) Did you include the code, data, and instructions needed to reproduce the main ex-\\nperimental results (either in the supplemental material or as a URL)? [Yes] See sup-\\nplemental material and Appendix A. All the code and public models will be open\\nsourced.\\n(b) Did you specify all the training details (e.g., data splits, hyperparameters, how they\\nwere chosen)? [Yes] See Section 4 and Appendix C.\\n(c) Did you report error bars (e.g., with respect to the random seed after running experi-\\nments multiple times)? [No] We benchmarked on large-scale datasets like ImageNet-\\n1K, JFT-300M and ALIGN data with models like ResNet and ViT making it extremely\\nexpensive to run things multiple times.\\n(d) Did you include the total amount of compute and the type of resources used (e.g., type\\nof\\\\nd K. Grauman. Fast similarity search for learned metrics. IEEE Transactions\\non Pattern Analysis and Machine Intelligence, 31(12):2143–2157, 2009.\\n13\\n[53] A. Kusupati, M. Singh, K. Bhatia, A. Kumar, P. Jain, and M. Varma. Fastgrnn: A fast, accurate,\\nstable and tiny kilobyte sized gated recurrent neural network. Advances in Neural Information\\nProcessing Systems, 31, 2018.\\n[54] A. Kusupati, V. Ramanujan, R. Somani, M. Wortsman, P. Jain, S. Kakade, and A. Farhadi.\\nSoft threshold weight reparameterization for learnable sparsity. In International Conference\\non Machine Learning, pages 5544–5555. PMLR, 2020.\\n[55] A. Kusupati, M. Wallingford, V. Ramanujan, R. Somani, J. S. Park, K. Pillutla, P. Jain,\\nS. Kakade, and A. Farhadi. Llc: Accurate, multi-purpose learnt low-dimensional binary codes.\\nAdvanc\\\\nce of MRL model on 31-way classification (1 extra class is for reject token) on\\nImageNet-1K superclasses.\\nRep. Size\\n8\\n16\\n32\\n64\\n128\\n256\\n512\\n1024\\n2048\\nMRL\\n85.57\\n88.67\\n89.48\\n89.82\\n89.97\\n90.11\\n90.18\\n90.22\\n90.21\\nMatryoshka Representations at Arbitrary Granularities.\\nTo train MRL, we used nested di-\\nmensions at logarithmic granularities M = {8, 16, . . . , 1024, 2048} as detailed in Section 3. We\\nmade this choice for two empirically-driven reasons: a) The accuracy improvement with increasing\\nrepresentation size was more logarithmic than linear (as shown by FF models in Figure 2). This indi-\\ncated that optimizing for granularities increasing in a non-logarithmic fashion would be sub-optimal\\nboth for maximum performance and expected efficiency; b) If we have m arbitrary granularities,\\nthe expected\\\\nan one: Fast and accurate models via ensembles and cascades. arXiv\\npreprint arXiv:2012.01988, 2020.\\n[96] M. Wortsman, G. Ilharco, M. Li, J. W. Kim, H. Hajishirzi, A. Farhadi, H. Namkoong, and\\nL. Schmidt. Robust fine-tuning of zero-shot models. arXiv preprint arXiv:2109.01903, 2021.\\n[97] Z. Wu, Y. Xiong, S. Yu, and D. Lin. Unsupervised feature learning via non-parametric\\ninstance-level discrimination. arXiv preprint arXiv:1805.01978, 2018.\\n[98] J. Yosinski, J. Clune, Y. Bengio, and H. Lipson. How transferable are features in deep neural\\nnetworks? Advances in neural information processing systems, 27, 2014.\\n[99] H.-F. Yu, K. Zhong, J. Zhang, W.-C. Chang, and I. S. Dhillon. Pecos: Prediction for enormous\\nand correlated output spaces. Journal of Machine Learning Research, 23(98):1–32, 2022.\\n[1\\\\n\\nThese experiments show that MRL seamlessly scales to large-scale models and web-scale datasets\\nwhile providing the otherwise prohibitively expensive multi-granularity in the process. We also\\nhave similar observations when pretraining BERT; please see Appendix D.2 for more details. Our\\nexperiments also show that post-hoc compression (SVD), linear probe on random features, and\\nsub-net style slimmable networks drastically lose accuracy compared to MRL as the representation\\nsize decreases. Finally, Figure 5 shows that, while MRL explicitly optimizes O(log(d)) nested\\nrepresentations – removing the O(d) dependence [73] –, the coarse-to-fine grained information is\\ninterpolated across all d dimensions providing highest flexibility for adaptive deployment.\\n5\\n12\\n24\\n48\\n96\\n192\\n384\\n768\\nRepresentation \\\\n on top of the existing impact of\\nrepresentation learning. However, a study on the trade-off between representation size\\nand the tendency to encode biases is an interesting future direction along the lines of\\nexisting literature [36, 37]. A part of this is already presented in Section 5.\\n(d) Have you read the ethics review guidelines and ensured that your paper conforms to\\nthem? [Yes]\\n2. If you are including theoretical results...\\n(a) Did you state the full set of assumptions of all theoretical results? [N/A]\\n(b) Did you include complete proofs of all theoretical results? [N/A]\\n3. If you ran experiments...\\n(a) Did you include the code, data, and instructions needed to reproduce the main ex-\\nperimental results (either in the supplemental material or as a URL)? [Yes] See sup-\\nplemental mater\\\\nat optimizing for granularities increasing in a non-logarithmic fashion would be sub-optimal\\nboth for maximum performance and expected efficiency; b) If we have m arbitrary granularities,\\nthe expected cost of the linear classifier to train MRL scales as O(L ∗(m2)) while logarithmic\\ngranularities result in O(L ∗2log(d)) space and compute costs.\\nTo demonstrate this effect, we learned Matryoshka Representations with uniform (MRL-Uniform)\\nnesting dimensions m\\n∈\\nM\\n=\\n{8, 212, 416, 620, 824, 1028, 1232, 1436, 1640, 1844, 2048}.\\nWe\\nevaluated\\nthis\\nmodel\\nat\\nthe\\nstandard\\n(MRL-log)\\ndimensions\\nm\\n∈\\nM\\n=\\n{8, 16, 32, 64, 128, 256, 512, 1024, 2048} for ease of comparison to reported numbers using 1-NN ac-\\ncuracy (%). As shown in Table 29, we observed that while performance interpolated, MRL-Uniform\\nsuffered\\\\n, 32, 64, . . . , 2048}}. To improve reliability of threshold\\nbased greedy policy, we use test time augmentation which has been used successfully in the past [82].\\nFor inference, we used the remaining held-out 40K samples from the ImageNet-1K validation set. We\\nbegan with smallest sized representation (m = 8) and compared the computed prediction confidence\\np8 to learned optimal threshold t∗\\n8. If p8 ≤t∗\\n8, then we increased m = 16, and repeated this\\nprocedure until m = d = 2048. To compute the expected dimensions, we performed early stopping\\nat m = {16, 32, 64, . . . 2048} and computed the expectation using the distribution of representation\\nsizes. As shown in Table 3 and Figure 6, we observed that in expectation, we only needed a ∼37\\nsized representation to achieve 76.3% classification ac\\\\nfitting to experimental setups in recognition? arXiv preprint arXiv:2007.02519,\\n2020.\\n[93] M. Wallingford, H. Li, A. Achille, A. Ravichandran, C. Fowlkes, R. Bhotika, and S. Soatto.\\nTask adaptive parameter sharing for multi-task learning. arXiv preprint arXiv:2203.16708,\\n2022.\\n[94] H. Wang, S. Ge, Z. Lipton, and E. P. Xing. Learning robust global representations by penalizing\\nlocal predictive power. In Advances in Neural Information Processing Systems, pages 10506–\\n10518, 2019.\\n[95] X. Wang, D. Kondratyuk, K. M. Kitani, Y. Movshovitz-Attias, and E. Eban. Multiple networks\\nare more efficient than one: Fast and accurate models via ensembles and cascades. arXiv\\npreprint arXiv:2012.01988, 2020.\\n[96] M. Wortsman, G. Ilharco, M. Li, J. W. Kim, H. Hajishirzi, A. Farhadi, H. Namkoong, and\\nL. Schmi\\\\nTable 31. We observed that using a larger shortlist k saturated\\nImageNet-1K performance at k=200. But using larger shortlists until k = 2048, the maximum value\\n33\\nTable 26: Top-1 classification accuracy (%) on ImageNet-1K of various ResNet50 models which\\nare finetuned on pretrained FF-2048 model. We observed that adding more non-linearities is able to\\ninduce nesting to a reasonable extent even if the model was not pretrained with nesting in mind.\\nRep. Size\\nfc\\n4.2 conv3,\\nfc\\n4.2 conv2,\\nconv3, fc\\n4.2 full,\\nfc\\nAll (MRL)\\n8\\n5.15\\n36.11\\n54.78\\n60.02\\n66.63\\n16\\n13.79\\n58.42\\n67.26\\n70.10\\n73.53\\n32\\n32.52\\n67.81\\n71.62\\n72.84\\n75.03\\n64\\n52.66\\n72.42\\n73.61\\n74.29\\n75.82\\n128\\n64.60\\n74.41\\n74.67\\n75.03\\n76.30\\n256\\n69.29\\n75.30\\n75.23\\n75.38\\n76.47\\n512\\n70.51\\n75.96\\n75.47\\n75.64\\n76.65\\n1024\\n70.19\\n76.18\\n75.70\\n75.75\\n76.76\\n2048\\n69.72\\n\\\\nion set. This policy is based on whether the\\nprediction confidence pi using representation size mi exceeds a learned threshold t∗\\ni . If pi ≥t∗\\ni , we\\nused predictions from representation size mi otherwise, we increased to representation size mi+1. To\\nlearn the optimal threshold t∗\\ni , we performed a grid search between 0 and 1 (100 samples). For each\\nthreshold tk, we computed the classification accuracy over our 10K image subset. We set t∗\\ni equal\\nto the smallest threshold tk that gave the best accuracy. We use this procedure to obtain thresholds\\nfor successive models, i.e., {t∗\\nj | j ∈{8, 16, 32, 64, . . . , 2048}}. To improve reliability of threshold\\nbased greedy policy, we use test time augmentation which has been used successfully in the past [82].\\nFor inference, we used the remaining\\\\nodel fine-tuning for text classification. arXiv\\npreprint arXiv:1801.06146, 2018.\\n[41] H. Hu, D. Dey, M. Hebert, and J. A. Bagnell. Learning anytime predictions in neural networks\\nvia adaptive loss balancing. In Proceedings of the AAAI Conference on Artificial Intelligence,\\nvolume 33, pages 3812–3821, 2019.\\n[42] P. Indyk and R. Motwani. Approximate nearest neighbors: towards removing the curse\\nof dimensionality. In Proceedings of the thirtieth annual ACM symposium on Theory of\\ncomputing, pages 604–613, 1998.\\n[43] H. Jain, V. Balasubramanian, B. Chunduri, and M. Varma. Slice: Scalable linear extreme\\nclassifiers trained on 100 million labels for related searches. In Proceedings of the Twelfth\\nACM International Conference on Web Search and Data Mining, pages 528–536, 2019.\\n[44] S. Jayaram Subr\\\\nch\\nusing hierarchical navigable small world graphs. IEEE transactions on pattern analysis and\\nmachine intelligence, 42(4):824–836, 2018.\\n[63] J. Masci, U. Meier, D. Cire¸san, and J. Schmidhuber. Stacked convolutional auto-encoders for\\nhierarchical feature extraction. In International conference on artificial neural networks, pages\\n52–59. Springer, 2011.\\n[64] P. Mitra, C. Murthy, and S. K. Pal. Unsupervised feature selection using feature similarity.\\nIEEE transactions on pattern analysis and machine intelligence, 24(3):301–312, 2002.\\n[65] V. Nanda, T. Speicher, J. P. Dickerson, S. Feizi, K. P. Gummadi, and A. Weller. Diffused\\nredundancy in pre-trained representations. arXiv preprint arXiv:2306.00183, 2023.\\n[66] P. Nayak. Understanding searches better than ever before. Google AI Blog, 2019. \\\\nn artificial intelligence and statistics, pages 297–304. JMLR Workshop and Conference\\nProceedings, 2010.\\n[28] M. G. Harris and C. D. Giachritsis. Coarse-grained information dominates fine-grained\\ninformation in judgments of time-to-contact from retinal flow. Vision research, 40(6):601–611,\\n2000.\\n[29] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In\\nProceedings of the IEEE conference on computer vision and pattern recognition, pages 770–\\n778, 2016.\\n[30] K. He, H. Fan, Y. Wu, S. Xie, and R. Girshick. Momentum contrast for unsupervised visual\\nrepresentation learning. In Proceedings of the IEEE/CVF conference on computer vision and\\npattern recognition, pages 9729–9738, 2020.\\n[31] K. He, X. Chen, S. Xie, Y. Li, P. Dollár, and R. Girshick. Masked autoencoders\\\\ne distribution, without sacrificing accuracy on other classes (Table 16 in\\nAppendix G). Additionally we find the accuracy between low-dimensional and high-dimensional\\nrepresentations is marginal for pretrain classes. We hypothesize that the higher-dimensional represen-\\ntations are required to differentiate the classes when few training examples of each are known. This\\nresults provides further evidence that different tasks require varying capacity based on their difficulty.\\nDisagreement across Dimensions.\\nThe information packing in Matryoshka Representations\\noften results in gradual increase of accuracy with increase in capacity. However, we observed that\\n8\\n(a)\\n(b)\\n(c)\\nFigure 9: Grad-CAM [80] progression of predictions in MRL model across 8, 16, 32 and 2048\\ndimensions. (a) 8-dimensional rep\\\\nations of the ACM, 62(11):44–45, 2019.\\n15\\n[90] P. Viola and M. Jones. Rapid object detection using a boosted cascade of simple features. In\\nProceedings of the 2001 IEEE computer society conference on computer vision and pattern\\nrecognition. CVPR 2001, volume 1, pages I–I. Ieee, 2001.\\n[91] C. Waldburger. As search needs evolve, microsoft makes ai tools for better search available\\nto researchers and developers. Microsoft AI Blog, 2019. URL https://blogs.microsoft.\\ncom/ai/bing-vector-search/.\\n[92] M. Wallingford, A. Kusupati, K. Alizadeh-Vahid, A. Walsman, A. Kembhavi, and A. Farhadi.\\nAre we overfitting to experimental setups in recognition? arXiv preprint arXiv:2007.02519,\\n2020.\\n[93] M. Wallingford, H. Li, A. Achille, A. Ravichandran, C. Fowlkes, R. Bhotika, and S. Soatto.\\nTask adaptive para\\\\nirst m dimensions of FF-2048 for NN lookup, and 2) FF+SVD: performing SVD\\non the FF-2048 representations at the specified representation size, 3) FF+JL: performing random\\nprojection according to the Johnson-Lindenstrauss lemma [48] on the FF-2048 representations at\\nthe specified representation size. We also compared against the 1-NN accuracy of slimmable neural\\nnets [100] as an additional baseline. We observed these baseline models to perform very poorly at\\nlower dimensions, as they were not explicitly trained to learn Matryoshka Representations.\\nTable 2: 1-NN accuracy (%) on ImageNet-1K for various ResNet50 models.\\nRep. Size\\nRand. FS\\nSVD\\nJL\\nFF\\nSlimmable\\nMRL\\nMRL–E\\n8\\n2.36\\n19.14\\n0.11\\n58.93\\n1.00\\n62.19\\n57.45\\n16\\n12.06\\n46.02\\n0.09\\n66.77\\n5.12\\n67.91\\n67.05\\n32\\n32.91\\n60.78\\n0.06\\n68.84\\n16.95\\n69.46\\n68.6\\n\\\\nrs.\\nWe also found that for both MRL and FF, as the shot number decreased, the required representa-\\ntion size to reach optimal accuracy decreased (Table 15). For example, we observed that 1-shot\\nperformance at 32 representation size had equal accuracy to 2048 representation size.\\nFLUID.\\nFor the long-tailed setting we evaluated MRL on the FLUID benchmark [92] which\\ncontains a mixture of pretrain and new classes. Table 16 shows the evaluation of the learned\\nrepresentation on FLUID. We observed that MRL provided up to 2% higher accuracy on novel\\nclasses in the tail of the distribution, without sacrificing accuracy on other classes. Additionally we\\nfound the accuracy between low-dimensional and high-dimensional representations was marginal for\\npretrain classes. For example, the 64-dimensional M\\\\nhoice learning for training diverse deep ensembles. Advances in Neural\\nInformation Processing Systems, 29, 2016.\\n[59] C. Li, H. Farkhoor, R. Liu, and J. Yosinski. Measuring the intrinsic dimension of objective\\nlandscapes. arXiv preprint arXiv:1804.08838, 2018.\\n[60] Y. Linde, A. Buzo, and R. Gray. An algorithm for vector quantizer design. IEEE Transactions\\non communications, 28(1):84–95, 1980.\\n[61] I. Loshchilov and F. Hutter.\\nDecoupled weight decay regularization.\\narXiv preprint\\narXiv:1711.05101, 2017.\\n[62] Y. A. Malkov and D. A. Yashunin. Efficient and robust approximate nearest neighbor search\\nusing hierarchical navigable small world graphs. IEEE transactions on pattern analysis and\\nmachine intelligence, 42(4):824–836, 2018.\\n[63] J. Masci, U. Meier, D. Cire¸san, and J. Schmidhuber. Stack\\\\n000-way classification layer of FF-2048,\\nwith rank = 1000.\\n• Rand. LP: We compared against a linear classifier fit on randomly selected features [30].\\n• Slim. Net: We take pretrained slimmable neural networks [100] which are trained with a flexible\\nwidth backbone (25%, 50%, 75% and full width). For each representation size, we consider the\\nfirst k dimensions for classification. Note that training of slimmable neural networks becomes\\nunstable when trained below 25% width due to the hardness in optimization and low complexity of\\nthe model.\\nAt lower dimensions ( d ≤128), MRL outperforms all baselines significantly, which indicates that\\npretrained models lack the multifidelity of Matryoshka Representations and are incapable of fitting\\nan accurate linear classifier at low representation sizes.\\n\\\\n due to the inductive bias of gradient-based training [84], deep learning models tend to diffuse\\n“information” across the entire representation vector. The desired elasticity is usually enabled in the\\nexisting flat and fixed representations either through training multiple low-dimensional models [29],\\njointly optimizing sub-networks of varying capacity [9, 100] or post-hoc compression [38, 60]. Each\\nof these techniques struggle to meet the requirements for adaptive large-scale deployment either\\n∗Equal contribution – AK led the project with extensive support from GB and AR for experimentation.\\n36th Conference on Neural Information Processing Systems (NeurIPS 2022).\\narXiv:2205.13147v4  [cs.LG]  8 Feb 2024\\ndue to training/maintenance overhead, numerous expensive forward passes through all of \\\\n) utilization\\nof the representation for downstream applications [50, 89]. Compute costs for the latter part of the\\npipeline scale with the embedding dimensionality as well as the data size (N) and label space (L).\\nAt web-scale [15, 85] this utilization cost overshadows the feature computation cost. The rigidity in\\nthese representations forces the use of high-dimensional embedding vectors across multiple tasks\\ndespite the varying resource and accuracy constraints that require flexibility.\\nHuman perception of the natural world has a naturally coarse-to-fine granularity [28, 32]. However,\\nperhaps due to the inductive bias of gradient-based training [84], deep learning models tend to diffuse\\n“information” across the entire representation vector. The desired elasticity is usually enabled in the\\\\nng, pages 1597–1607.\\nPMLR, 2020.\\n[13] Y. Chen, Z. Liu, H. Xu, T. Darrell, and X. Wang. Meta-baseline: exploring simple meta-\\nlearning for few-shot learning. In Proceedings of the IEEE/CVF International Conference on\\nComputer Vision, pages 9062–9071, 2021.\\n[14] M. Datar, N. Immorlica, P. Indyk, and V. S. Mirrokni. Locality-sensitive hashing scheme based\\non p-stable distributions. In Proceedings of the twentieth annual symposium on Computational\\ngeometry, pages 253–262, 2004.\\n[15] J. Dean. Challenges in building large-scale information retrieval systems. In Keynote of the\\n2nd ACM International Conference on Web Search and Data Mining (WSDM), volume 10,\\n2009.\\n[16] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. Imagenet: A large-scale\\nhierarchical image database. In 2009 IEEE co\\\\nithin the same larger network. However, the weights for each progressively smaller\\nnetwork can be different and often require distinct forward passes to isolate the final representations.\\nThis is detrimental for adaptive inference due to the need for re-encoding the entire retrieval database\\nwith expensive sub-net forward passes of varying capacities. Several works [23, 26, 65, 59] investigate\\nthe notions of intrinsic dimensionality and redundancy of representations and objective spaces pointing\\nto minimum description length [74]. Finally, ordered representations proposed by Rippel et al. [73]\\nuse nested dropout in the context of autoencoders to learn nested representations. MRL differentiates\\nitself in formulation by optimizing only for O(log(d)) nesting dimensions instead of O(d). Despit\\\\ne high yet constant deep featurization costs or the search cost which\\nscales with the size of the label space and data. Efficient neural networks address the first issue\\nthrough a variety of algorithms [25, 54] and design choices [39, 53, 87]. However, with a strong\\nfeaturizer, most of the issues with scale are due to the linear dependence on number of labels (L), size\\nof the data (N) and representation size (d), stressing RAM, disk and processor all at the same time.\\nThe sub-linear complexity dependence on number of labels has been well studied in context of\\ncompute [3, 43, 69] and memory [20] using Approximate Nearest Neighbor Search (ANNS) [62] or\\nleveraging the underlying hierarchy [17, 55]. In case of the representation size, often dimensionality\\nreduction [77, 88], hashing techniques\\\\nion size for MRL &\\nFF models showing the capture of underlying\\nhierarchy through tight information bottlenecks.\\n8\\n16\\n32\\n64\\n128\\n256\\n512\\n1024\\n2048\\nRepresentation Size\\n65\\n70\\n75\\n80\\n85\\n90\\n95\\nTop-1 Accuracy (%)\\nmeasuring device\\nbuilding\\ngarment\\ntool\\nnourishment\\nprotective covering\\nvessel\\noscine\\nFigure 11:\\nDiverse per-superclass accuracy\\ntrends across representation sizes for ResNet50-\\nMRL on ImageNet-1K.\\n9\\noccurs with both MRL and FF models; MRL is more accurate across dimensions. This shows that\\ntight information bottlenecks while not highly accurate for fine-grained classification, do capture\\nrequired semantic information for coarser classification that could be leveraged for adaptive routing\\nfor retrieval and classification. Mutifidelity of Matryoshka Representation naturally captures the\\nund\\\\n\\n403\\n26.25\\n49.32\\n59.48\\n14.15\\n11.00\\n9.15\\n7.61\\n20.55\\n18.36\\n16.78\\n15.17\\n192\\n807\\n27.94\\n51.32\\n61.32\\n15.29\\n11.89\\n9.88\\n8.18\\n21.86\\n19.46\\n17.71\\n15.96\\n384\\n1614\\n29.03\\n52.53\\n62.45\\n15.99\\n12.46\\n10.35\\n8.56\\n22.64\\n20.14\\n18.29\\n16.47\\n768\\n3227\\n29.87\\n53.36\\n63.13\\n16.54\\n12.90\\n10.71\\n8.85\\n23.23\\n20.67\\n18.75\\n16.85\\n1536\\n6454\\n30.52\\n54.02\\n63.79\\n16.99\\n13.27\\n11.01\\n9.08\\n23.73\\n21.09\\n19.12\\n17.16\\nlarge-scale (1000-way) setting. We evaluate for n ∈1, 3, 5, 7, 9 with 9 being the maximum value for\\nn because there are 10 images per class.\\nWe observed that MRL had equal performance to FF across all representation sizes and shot numbers.\\nWe also found that for both MRL and FF, as the shot number decreased, the required representa-\\ntion size to reach optimal accuracy decreased (Table 15). For example, we observed that 1-shot\\nperfor\\\\nth a fraction of the MFLOPs.\\nG\\nFew-shot and Sample Efficiency\\nWe compared MRL, MRL–E, and FF on various benchmarks to observe the effect of representation\\nsize on sample efficiency. We used Nearest Class Means [79] for classification which has been shown\\nto be effective in the few-shot regime [13].\\nImageNetV2.\\nRepresentations are evaluated on ImageNetV2 with the n-shot k-way setup. Ima-\\ngeNetV2 is a dataset traditionally used to evaluate the robustness of models to natural distribution\\nshifts. For our experiments we evaluate accuracy of the model given n examples from the Ima-\\ngeNetV2 distribution. We benchmark representations in the traditional small-scale (10-way) and\\n25\\nTable 9: Retrieve a shortlist of 200-NN with Ds sized representations on ImageNetV2 via exact\\nsearch with L2 distance \\\\nBoden, A. Borchers, et al. In-datacenter performance analysis of a tensor processing unit.\\nIn Proceedings of the 44th annual international symposium on computer architecture, pages\\n1–12, 2017.\\n[50] T. C. Kaz Sato.\\nVertex ai matching engine.\\nMicrosoft AI Blog, 2021.\\nURL\\nhttps://cloud.google.com/blog/topics/developers-practitioners/\\nfind-anything-blazingly-fast-googles-vector-search-technology.\\n[51] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional\\nneural networks. Advances in neural information processing systems, 25, 2012.\\n[52] B. Kulis, P. Jain, and K. Grauman. Fast similarity search for learned metrics. IEEE Transactions\\non Pattern Analysis and Machine Intelligence, 31(12):2143–2157, 2009.\\n13\\n[53] A. Kusupati, M. Singh, K. Bhatia, A. Kumar, P.\\\\nguage applications are built [40] on large language models [8] that are pretrained [68, 75]\\nin a un/self-supervised fashion with masked language modelling [19] or autoregressive training [70].\\nMatryoshka Representation Learning (MRL) is complementary to all these setups and can be\\nadapted with minimal overhead (Section 3). MRL equips representations with multifidelity at no\\nadditional cost which enables adaptive deployment based on the data and task (Section 4).\\nEfficient Classification and Retrieval.\\nEfficiency in classification and retrieval during inference\\ncan be studied with respect to the high yet constant deep featurization costs or the search cost which\\nscales with the size of the label space and data. Efficient neural networks address the first issue\\nthrough a variety of algorithm\\\\ne, and L. Zettlemoyer.\\nDeep contextualized word representations. In Proceedings of the 2018 Conference of the\\nNorth American Chapter of the Association for Computational Linguistics: Human Language\\nTechnologies, Volume 1 (Long Papers), pages 2227–2237, New Orleans, Louisiana, June\\n2018. Association for Computational Linguistics. doi: 10.18653/v1/N18-1202. URL https:\\n//aclanthology.org/N18-1202.\\n[69] Y. Prabhu, A. Kusupati, N. Gupta, and M. Varma. Extreme regression for dynamic search\\nadvertising. In Proceedings of the 13th International Conference on Web Search and Data\\nMining, pages 456–464, 2020.\\n[70] A. Radford, K. Narasimhan, T. Salimans, and I. Sutskever. Improving language understand-\\ning by generative pre-training. OpenAI Blog, 2018. URL https://openai.com/blog/\\nlanguage-unsupervise\\\\nrmance of ResNet50 representations on ImageNet-1K across\\ndimensionalities for MRL, MRL–E, FF, slimmable networks along with post-hoc compression\\nof vectors using SVD and random feature selection. Matryoshka Representations are often the\\nmost accurate while being up to 3% better than the FF baselines. Similar to classification, post-hoc\\ncompression and slimmable network baselines suffer from significant drop-off in retrieval mAP@10\\nwith ≤256 dimensions. Appendix E discusses the mAP@10 of the same models on ImageNet-4K.\\nMRL models are capable of performing accurate retrieval at various granularities without the\\nadditional expense of multiple model forward passes for the web-scale databases. FF models\\nalso generate independent databases which become prohibitively expense to store and switch i\\\\n36th Conference on Neural Information Processing Systems (NeurIPS 2022).\\narXiv:2205.13147v4  [cs.LG]  8 Feb 2024\\ndue to training/maintenance overhead, numerous expensive forward passes through all of the data,\\nstorage and memory cost for multiple copies of encoded data, expensive on-the-fly feature selection\\nor a significant drop in accuracy. By encoding coarse-to-fine-grained representations, which are as\\naccurate as the independently trained counterparts, we learn with minimal overhead a representation\\nthat can be deployed adaptively at no additional cost during inference.\\nWe introduce\\nMatryoshka Representation Learning (MRL) to induce flexibility in the learned\\nrepresentation. MRL learns representations of varying capacities within the same high-dimensional\\nvector through explicit optim\\\\n, and signif-\\nicantly for lower ones. This demonstrates that training to learn Matryoshka Representations\\nis feasible and extendable even for extremely large scale datasets.\\nWe also demonstrate that\\nMatryoshka Representations are learned at interpolated dimensions for both ALIGN and JFT-\\nViT, as shown in Table 5, despite not being trained explicitly at these dimensions. Lastly, Table 6\\nshows that MRL training leads to a increase in the cosine similarity span between positive and\\nrandom image-text pairs.\\nWe also evaluated the capability of Matryoshka Representations to extend to other natural language\\nprocessing via masked language modeling (MLM) with BERT [19], whose results are tabulated\\nin Table 7. Without any hyper-parameter tuning, we observed Matryoshka Representations to be\\nwithin 0.\\\\n are within 0.1% of the maximum value achievable without reranking on MRL representations,\\nas seen in Table 10, are bolded.\\nShortlist Length = 200\\nDs\\nDr\\nMFLOPs\\nTop-1\\nmAP@10\\nmAP@25\\nmAP@50\\nmAP@100\\nP@10\\nP@25\\nP@50\\nP@100\\n8\\n16\\n34\\n16.84\\n8.70\\n6.88\\n5.88\\n5.08\\n13.86\\n12.80\\n11.98\\n11.10\\n32\\n20.73\\n10.66\\n8.19\\n6.77\\n5.61\\n16.18\\n14.39\\n13.02\\n11.61\\n64\\n23.11\\n11.91\\n9.03\\n7.36\\n6.00\\n17.56\\n15.34\\n13.67\\n11.99\\n128\\n24.63\\n12.71\\n9.59\\n7.76\\n6.25\\n18.42\\n15.94\\n14.08\\n12.22\\n256\\n25.5\\n13.24\\n9.96\\n8.03\\n6.42\\n19.00\\n16.35\\n14.36\\n12.37\\n512\\n26.07\\n13.59\\n10.21\\n8.20\\n6.53\\n19.37\\n16.62\\n14.54\\n12.46\\n1024\\n26.52\\n13.85\\n10.40\\n8.34\\n6.61\\n19.65\\n16.80\\n14.68\\n12.53\\n2048\\n26.94\\n14.11\\n10.57\\n8.45\\n6.68\\n19.92\\n16.98\\n14.79\\n12.58\\n16\\n32\\n67\\n21.44\\n11.24\\n8.72\\n7.26\\n6.02\\n17.02\\n15.30\\n13.92\\n12.41\\n64\\n24.36\\n12.78\\n9.75\\n7.96\\n6.43\\n18.72\\n16.41\\n14.63\\n12.74\\n128\\n26.08\\n13.70\\n10.39\\n8.3\\\\nYang, Y. Xia, Y.-T. Chen, Z. Parekh, H. Pham, Q. Le, Y.-H. Sung, Z. Li, and T. Duerig.\\nScaling up visual and vision-language representation learning with noisy text supervision. In\\nInternational Conference on Machine Learning, pages 4904–4916. PMLR, 2021.\\n[47] J. Johnson, M. Douze, and H. Jégou. Billion-scale similarity search with GPUs. IEEE\\nTransactions on Big Data, 7(3):535–547, 2019.\\n[48] W. B. Johnson. Extensions of lipschitz mappings into a hilbert space. Contemp. Math., 26:\\n189–206, 1984.\\n[49] N. P. Jouppi, C. Young, N. Patil, D. Patterson, G. Agrawal, R. Bajwa, S. Bates, S. Bhatia,\\nN. Boden, A. Borchers, et al. In-datacenter performance analysis of a tensor processing unit.\\nIn Proceedings of the 44th annual international symposium on computer architecture, pages\\n1–12, 2017.\\n[50] T.\\\\n, 2020.\\n[55] A. Kusupati, M. Wallingford, V. Ramanujan, R. Somani, J. S. Park, K. Pillutla, P. Jain,\\nS. Kakade, and A. Farhadi. Llc: Accurate, multi-purpose learnt low-dimensional binary codes.\\nAdvances in Neural Information Processing Systems, 34, 2021.\\n[56] G. Leclerc, A. Ilyas, L. Engstrom, S. M. Park, H. Salman, and A. Madry. ffcv. https:\\n//github.com/libffcv/ffcv/, 2022. commit 607d117.\\n[57] Y. LeCun, Y. Bengio, and G. Hinton. Deep learning. nature, 521(7553):436–444, 2015.\\n[58] S. Lee, S. Purushwalkam Shiva Prakash, M. Cogswell, V. Ranjan, D. Crandall, and D. Batra.\\nStochastic multiple choice learning for training diverse deep ensembles. Advances in Neural\\nInformation Processing Systems, 29, 2016.\\n[59] C. Li, H. Farkhoor, R. Liu, and J. Yosinski. Measuring the intrinsic dimension of \\\\n16, 32, 64, 128, 256, 512, 1024, 2048} for ease of comparison to reported numbers using 1-NN ac-\\ncuracy (%). As shown in Table 29, we observed that while performance interpolated, MRL-Uniform\\nsuffered at low dimensions as the logarithmic spacing of MRL-log resulted in tighter packing of\\ninformation in these initial dimensions. The higher nesting dimensions of MRL-Uniform did not\\nhelp in significant accuracy improvement due to accuracy saturation, which is often logarithmic in\\nrepresentation size as shown by FF models. Note that the slight improvement at dimensions higher\\nthan 512 for MRL-Uniform is due to multiple granularities around them compared to just three for\\nMRL-log, which are not useful in practice for efficiency.\\nLower Dimensionality.\\nWe experimented with training MRL with smalle\\\\nnts.\\nAcknowledgments\\nWe are grateful to Srinadh Bhojanapalli, Lovish Madaan, Raghav Somani, Ludwig Schmidt, and\\nVenkata Sailesh Sanampudi for helpful discussions and feedback. Aditya Kusupati also thanks Tom\\nDuerig and Rahul Sukthankar for their support. Part of the paper’s large-scale experimentation is\\nsupported through a research GCP credit award from Google Cloud and Google Research. Gantavya\\nBhatt is supported in part by the CONIX Research Center, one of six centers in JUMP, a Semicon-\\nductor Research Corporation (SRC) program sponsored by DARPA. Sham Kakade acknowledges\\nfunding from the NSF award CCF-1703574 and ONR N00014-22-1-2377. Ali Farhadi acknowledges\\nfunding from the NSF awards IIS 1652052, IIS 17303166, DARPA N66001-19-2-4031, DARPA\\nW911NF-15-1-0543 and gifts from Allen Inst\\\\nConference on Machine Learning, pages 5389–5400. PMLR,\\n2019.\\n[73] O. Rippel, M. Gelbart, and R. Adams. Learning ordered representations with nested dropout.\\nIn International Conference on Machine Learning, pages 1746–1754. PMLR, 2014.\\n[74] J. Rissanen. Modeling by shortest data description. Automatica, 14(5):465–471, 1978.\\n[75] S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf. Transfer learning in natural language\\nprocessing. In Proceedings of the 2019 conference of the North American chapter of the\\nassociation for computational linguistics: Tutorials, pages 15–18, 2019.\\n[76] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy,\\nA. Khosla, M. Bernstein, et al. Imagenet large scale visual recognition challenge. International\\njournal of computer vision, 115\\\\nines significantly, which indicates that\\npretrained models lack the multifidelity of Matryoshka Representations and are incapable of fitting\\nan accurate linear classifier at low representation sizes.\\nWe compared the performance of MRL models at various representation sizes via 1-nearest neighbors\\n(1-NN) image classification accuracy on ImageNet-1K in Table 2 and Figure 3. We provide detailed\\ninformation regarding the k-NN search pipeline in Appendix E. We compared against a baseline\\nof attempting to enforce nesting to a FF-2048 model by 1) Random Feature Selection (Rand. FS):\\nconsidering the first m dimensions of FF-2048 for NN lookup, and 2) FF+SVD: performing SVD\\non the FF-2048 representations at the specified representation size, 3) FF+JL: performing random\\nprojection according to the J\\\\n,\\n(1)\\nwhere L: RL × [L] →R+ is the multi-class softmax cross-entropy loss function. This is a standard\\noptimization problem that can be solved using sub-gradient descent methods. We set all the impor-\\ntance scales, cm = 1 for all m ∈M; see Section 5 for ablations. Lastly, despite only optimizing\\nfor O(log(d)) nested dimensions, MRL results in accurate representations, that interpolate, for\\ndimensions that fall between the chosen granularity of the representations (Section 4.2).\\nWe call this formulation as Matryoshka Representation Learning (MRL). A natural way to make\\nthis efficient is through weight-tying across all the linear classifiers, i.e., by defining W(m) = W1:m\\nfor a set of common weights W ∈RL×d. This would reduce the memory cost due to the linear\\nclassifiers by almost half, whic\\\\nn such scenarios, we\\nobserved that smaller representation size models would often get confused due to other objects and fail\\nto extract the object of interest which generated the correct label. We also observed a different nature\\n31\\nFigure 12: Progression of relative per-class accuracy vs MRL-2048. As the dimensionality increases,\\nthe spread shrinks while the class marked (x) (Madagascar cat) loses accuracy.\\nTable 22: Percentage of ImageNet-1K validation set that is first correctly predicted using each\\nrepresentation size d. We note that 18.46% of the samples cannot be correctly predicted by any\\nrepresentation size. The remaining 81.54% constitutes the oracle accuracy.\\nRep. Size\\n8\\n16\\n32\\n64\\n128\\n256\\n512\\n1024\\n2048\\nAlways\\nWrong\\nCorrectly\\nPredicted\\n67.46\\n8.78\\n2.58\\n1.35\\n0.64\\n0.31\\n0.20\\n0.12\\n0.06\\n\\\\nreme\\nclassifiers trained on 100 million labels for related searches. In Proceedings of the Twelfth\\nACM International Conference on Web Search and Data Mining, pages 528–536, 2019.\\n[44] S. Jayaram Subramanya, F. Devvrit, H. V. Simhadri, R. Krishnawamy, and R. Kadekodi.\\nDiskann: Fast accurate billion-point nearest neighbor search on a single node. Advances in\\nNeural Information Processing Systems, 32, 2019.\\n[45] H. Jegou, M. Douze, and C. Schmid. Product quantization for nearest neighbor search. IEEE\\ntransactions on pattern analysis and machine intelligence, 33(1):117–128, 2010.\\n[46] C. Jia, Y. Yang, Y. Xia, Y.-T. Chen, Z. Parekh, H. Pham, Q. Le, Y.-H. Sung, Z. Li, and T. Duerig.\\nScaling up visual and vision-language representation learning with noisy text supervision. In\\nInternational Confe\\\\n results in Section 5.1 reveal interesting weaknesses of MRL that would be logical directions\\nfor future work. (1) Optimizing the weightings of the nested losses to obtain a Pareto optimal\\naccuracy-vs-efficiency trade-off – a potential solution could emerge from adaptive loss balancing\\naspects of anytime neural networks [41]. (2) Using different losses at various fidelities aimed at\\nsolving a specific aspect of adaptive deployment – e.g. high recall for 8-dimension and robustness\\nfor 2048-dimension. (3) Learning a search data-structure, like differentiable k-d tree, on top of\\nMatryoshka Representation to enable dataset and representation aware retrieval. (4) Finally, the\\njoint optimization of multi-objective MRL combined with end-to-end learnable search data-structure\\nto have data-driven a\\\\n Appendix C ablate over the choice of initial granularity and spacing of the\\ngranularites. Table 28 reaffirms the design choice to shun extremely low dimensions that have poor\\nclassification accuracy as initial granularity for MRL while Table 29 confirms the effectiveness of\\nlogarthmic granularity spacing inspired from the behaviour of accuracy saturation across dimensions\\nover uniform. Lastly, Tables 30 and 31 in Appendix K.2 show that the retrieval performance saturates\\nafter a certain shortlist dimension and length depending on the complexity of the dataset.\\n6\\nDiscussion and Conclusions\\nThe results in Section 5.1 reveal interesting weaknesses of MRL that would be logical directions\\nfor future work. (1) Optimizing the weightings of the nested losses to obtain a Pareto optimal\\naccuracy-vs\\\\ncomputer vision,\\npages 843–852, 2017.\\n[86] I. Sutskever, J. Martens, G. Dahl, and G. Hinton. On the importance of initialization and\\nmomentum in deep learning. In International conference on machine learning, pages 1139–\\n1147. PMLR, 2013.\\n[87] M. Tan and Q. Le. Efficientnet: Rethinking model scaling for convolutional neural networks.\\nIn International conference on machine learning, pages 6105–6114. PMLR, 2019.\\n[88] L. Van Der Maaten, E. Postma, J. Van den Herik, et al. Dimensionality reduction: a comparative.\\nJ Mach Learn Res, 10(66-71):13, 2009.\\n[89] M. Varma. Extreme classification. Communications of the ACM, 62(11):44–45, 2019.\\n15\\n[90] P. Viola and M. Jones. Rapid object detection using a boosted cascade of simple features. In\\nProceedings of the 2001 IEEE computer society conference on \\\\narning. In Proceedings of the IEEE/CVF conference on computer vision and\\npattern recognition, pages 9729–9738, 2020.\\n[31] K. He, X. Chen, S. Xie, Y. Li, P. Dollár, and R. Girshick. Masked autoencoders are scalable\\nvision learners. arXiv preprint arXiv:2111.06377, 2021.\\n[32] J. Hegdé. Time course of visual perception: coarse-to-fine processing and beyond. Progress in\\nneurobiology, 84(4):405–439, 2008.\\n[33] D. Hendrycks and K. Gimpel. A baseline for detecting misclassified and out-of-distribution\\nexamples in neural networks. arXiv preprint arXiv:1610.02136, 2016.\\n[34] D. Hendrycks, S. Basart, N. Mu, S. Kadavath, F. Wang, E. Dorundo, R. Desai, T. Zhu,\\nS. Parajuli, M. Guo, et al. The many faces of robustness: A critical analysis of out-of-\\ndistribution generalization. In Proceedings of the IEE\\\\nand ALIGN data with models like ResNet and ViT making it extremely\\nexpensive to run things multiple times.\\n(d) Did you include the total amount of compute and the type of resources used (e.g., type\\nof GPUs, internal cluster, or cloud provider)? [Yes] See Appendix C and Appendix I.\\n4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...\\n(a) If your work uses existing assets, did you cite the creators? [Yes]\\n(b) Did you mention the license of the assets? [No] All the non-proprietary datasets and\\ncode used are public under MIT, BSD or CC licenses.\\n(c) Did you include any new assets either in the supplemental material or as a URL? [Yes]\\nWe created a new subset of ImageNet-21K for downstream evaluation of retrieval\\nperformance at scale. See Section 4.3\\\\nAppendix J put forward the potential for MRL\\nto be a systematic framework for analyzing the utility and efficiency of information bottlenecks.\\nSuperclass Accuracy.\\nAs the information bottleneck becomes smaller, the overall accuracy on\\nfine-grained classes decreases rapidly (Figure 3). However, the drop-off is not as significant when\\nevaluated at a superclass level (Table 24 in Appendix J). Figure 10 presents that this phenomenon\\n8\\n16\\n32\\n64\\n128\\n256\\n512\\n1024\\n2048\\nRepresentation Size\\n84\\n86\\n88\\n90\\nTop-1 Accuracy (%)\\nMRL\\nFF\\nFigure 10: 31-way ImageNet-1K superclass clas-\\nsification across representation size for MRL &\\nFF models showing the capture of underlying\\nhierarchy through tight information bottlenecks.\\n8\\n16\\n32\\n64\\n128\\n256\\n512\\n1024\\n2048\\nRepresentation Size\\n65\\n70\\n75\\n80\\n85\\n90\\n95\\nTop-1 Accuracy\\\\n\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nIf you do not find the answer in the context information, then say exactly \"Ich weiss es nicht\" and nothing else.\\nIf the context is not related to the question, then say exactly: \"Dazu habe ich keine Information\" and nothing else:\\nAnswer:\\n'}, {'role': 'user', 'content': ' Query: \\nAre there computational and statistical constraints?\\n\\n'}]\n"
     ]
    }
   ],
   "source": [
    "# create list of system and user prompt dictionary\n",
    "list_of_prompts = [\n",
    "    pt.system_prompt(context_prompt),\n",
    "    # pt.user_prompt(user_query + \"\\nProvide the context used for your explanations.\")\n",
    "    pt.user_prompt(user_query)\n",
    "]\n",
    "\n",
    "print(list_of_prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation\n",
    "\n",
    "Let us generate a response using the augmented prompt.\n",
    "\n",
    "First, initialize the generation model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructor here\n"
     ]
    }
   ],
   "source": [
    "from py4ragTools.generation_tools import GenerationTools\n",
    "#gt = GenerationTools(generation_model='llama3.1:8b')\n",
    "gt = GenerationTools(generation_model='llama3.1:8b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, there are several computational and statistical constraints that can impact the reliability and validity of a study's findings. Here are some examples:\\n\\n**Computational Constraints:**\\n\\n1. **Computational power:** As data sizes increase, computational power requirements also grow exponentially. This can make it difficult to perform complex analyses or simulations on large datasets.\\n2. **Algorithmic limitations:** The choice of algorithm or programming language can introduce limitations in terms of scalability, accuracy, or interpretability.\\n3. **Data storage and preprocessing:** Managing and preprocessing large datasets can be computationally expensive and require significant resources.\\n\\n**Statistical Constraints:**\\n\\n1. **Sampling bias:** Sampling errors or biases can occur due to inadequate sampling techniques, which can limit the generalizability of findings.\\n2. **Type I and Type II errors:** Failing to reject a false null hypothesis (Type I error) or accepting a true alternative hypothesis (Type II error) can impact conclusions about significance and effect sizes.\\n3. **Confounding variables:** Uncontrolled confounding variables can introduce biases and lead to incorrect inferences about the relationships between variables.\\n4. **Data quality issues:** Incomplete, missing, or erroneous data can compromise analysis validity and reliability.\\n5. **Multiple testing corrections:** Failure to adjust for multiple testing (e.g., p-hacking) can increase the risk of Type I errors.\\n\\nTo mitigate these constraints, researchers should:\\n\\n1. **Use robust statistical methods** that account for potential biases.\\n2. **Perform exploratory analyses** to identify relationships and patterns in data.\\n3. **Validate findings using multiple lines of evidence**, such as independent samples, sensitivity analyses, or replications.\\n4. **Employ computational tools and techniques**, such as random forest modeling or Monte Carlo simulations, when necessary.\\n5. **Follow established best practices**, including documentation of methods, presentation of robustness and limitation sections in reports.\\n\\nThe constraints mentioned above can be addressed through careful consideration of:\\n\\n1. **Statistical power** to detect meaningful effects.\\n2. **Data quality** measures and controls for errors or missing data.\\n3. **Algorithmic choices**, selecting the most suitable approach given the problem's constraints.\\n4. **Research design**, ensuring adequate sampling, representation, and control over confounding variables.\\n\\nWould you like me to elaborate on any of these points?\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = gt.get_response(list_of_prompts) \n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, there are several computational and statistical constraints that can impact the reliability and validity of a study's findings. Here are some examples:\n",
      "\n",
      "**Computational Constraints:**\n",
      "\n",
      "1. **Computational power:** As data sizes increase, computational power requirements also grow exponentially. This can make it difficult to perform complex analyses or simulations on large datasets.\n",
      "2. **Algorithmic limitations:** The choice of algorithm or programming language can introduce limitations in terms of scalability, accuracy, or interpretability.\n",
      "3. **Data storage and preprocessing:** Managing and preprocessing large datasets can be computationally expensive and require significant resources.\n",
      "\n",
      "**Statistical Constraints:**\n",
      "\n",
      "1. **Sampling bias:** Sampling errors or biases can occur due to inadequate sampling techniques, which can limit the generalizability of findings.\n",
      "2. **Type I and Type II errors:** Failing to reject a false null hypothesis (Type I error) or accepting a true alternative hypothesis (Type II error) can impact conclusions about significance and effect sizes.\n",
      "3. **Confounding variables:** Uncontrolled confounding variables can introduce biases and lead to incorrect inferences about the relationships between variables.\n",
      "4. **Data quality issues:** Incomplete, missing, or erroneous data can compromise analysis validity and reliability.\n",
      "5. **Multiple testing corrections:** Failure to adjust for multiple testing (e.g., p-hacking) can increase the risk of Type I errors.\n",
      "\n",
      "To mitigate these constraints, researchers should:\n",
      "\n",
      "1. **Use robust statistical methods** that account for potential biases.\n",
      "2. **Perform exploratory analyses** to identify relationships and patterns in data.\n",
      "3. **Validate findings using multiple lines of evidence**, such as independent samples, sensitivity analyses, or replications.\n",
      "4. **Employ computational tools and techniques**, such as random forest modeling or Monte Carlo simulations, when necessary.\n",
      "5. **Follow established best practices**, including documentation of methods, presentation of robustness and limitation sections in reports.\n",
      "\n",
      "The constraints mentioned above can be addressed through careful consideration of:\n",
      "\n",
      "1. **Statistical power** to detect meaningful effects.\n",
      "2. **Data quality** measures and controls for errors or missing data.\n",
      "3. **Algorithmic choices**, selecting the most suitable approach given the problem's constraints.\n",
      "4. **Research design**, ensuring adequate sampling, representation, and control over confounding variables.\n",
      "\n",
      "Would you like me to elaborate on any of these points?\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aie-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
